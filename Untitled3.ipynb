{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6265f97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 1s 4ms/step - loss: 0.0185\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0107\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0099\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0096\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0096\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0096\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0095\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0095\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0095\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0096\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0095\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0094\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0094\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0094\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0093\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0093\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0093\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0091\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0089\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0088\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0089\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0087\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0086\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0088\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0086\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0085\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0086\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0083\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0083\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0081\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0080\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0079\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0087\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0090\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0086\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0083\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0082\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0081\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0081\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0079\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0085\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0082\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0079\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0078\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0077\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0076\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0075\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0075\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0074\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0073\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0076\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0077\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0076\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0076\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0075\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0075\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0074\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0073\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0072\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0072\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0072\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0069\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0069\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0071\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0070\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0071\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0073\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0075\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0078\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0077\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0074\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0075\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0081\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0075\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0073\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0071\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0069\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0068\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0067\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0067\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0067\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0066\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0066\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0068\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0069\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0068\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0066\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0065\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0065\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0065\n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0067\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0069\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0068\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0066\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0065\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0064\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0065\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0064\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0063\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0063\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0063\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0062\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0067\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0066\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0064\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0063\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0062\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0063\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0063\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0067\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0065\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0066\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0066\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0065\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0061\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0060\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0059\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0058\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0055\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0055\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0055\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0059\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0055\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0056\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0065\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0059\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0064\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0061\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0060\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0056\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0054\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0054\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0052\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0050\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0049\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0051\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0054\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0055\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0052\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0050\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0050\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0049\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0048\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0048\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0048\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0046\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0047\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0047\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0045\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0047\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0048\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0058\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0067\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0071\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0065\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0067\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0060\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0063\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0050\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0048\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0048\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0045\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0045\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0043\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0046\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0043\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0047\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0046\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0053\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "30/30 [==============================] - 0s 9ms/step\n",
      "(300000, 400)\n",
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0271\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0208\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0136\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0133\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0124\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0116\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0114\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0111\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0110\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0109\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0108\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0108\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0108\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0108\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0107\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0107\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0107\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0107\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0107\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0106\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0106\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0106\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0106\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0106\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0106\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0106\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0106\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0106\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0105\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0105\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0104\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0103\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0103\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0101\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0099\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0098\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0097\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0094\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0095\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0094\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0099\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0095\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0092\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0093\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0091\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0087\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0088\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0087\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0083\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0086\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0083\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0085\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0082\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0080\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0081\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0080\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0082\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0078\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0080\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0074\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0076\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0074\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0076\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0071\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0071\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0069\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0067\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0066\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0065\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0062\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0062\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0060\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0057\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0055\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0053\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0051\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0050\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0049\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0048\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0046\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0046\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0045\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0044\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0043\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0044\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0041\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0040\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0041\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0041\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0037\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0049\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0048\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0051\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0051\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0045\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0050\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0043\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0043\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0042\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0040\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0034\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0033\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0033\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0031\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0029\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0029\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0025\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0024\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0026\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0026\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0023\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0022\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0019\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0019\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0020\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0017\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0018\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5730e-04\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2875e-04\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7627e-04\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0470e-04\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.3255e-04\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.4967e-04\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.7447e-04\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.4138e-04\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8677e-04\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.4451e-04\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.0099e-04\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.5962e-04\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4433e-04\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.9257e-04\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7398e-04\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5034e-04\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3055e-04\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0952e-04\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5361e-05\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9370e-05\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.8732e-05\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.8911e-05\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.3375e-05\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.5009e-05\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9945e-05\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4392e-05\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.2027e-05\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.6774e-05\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5218e-05\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2077e-05\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0291e-05\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8645e-05\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7339e-05\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6070e-05\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4885e-05\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4010e-05\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3105e-05\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2325e-05\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1900e-05\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.1121e-05\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.0603e-05\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9733e-06\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.8257e-06\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2505e-06\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9460e-06\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.6601e-06\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2864e-06\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.9516e-06\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.8252e-06\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.4618e-06\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.3797e-06\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1071e-06\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.7990e-06\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.5870e-06\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4171e-06\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.1678e-06\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.0051e-06\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.8331e-06\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.6613e-06\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.4906e-06\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.3598e-06\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2078e-06\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.0584e-06\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.9433e-06\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.7748e-06\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.5936e-06\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.5017e-06\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3315e-06\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1420e-06\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.0927e-06\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.8870e-06\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7556e-06\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.6181e-06\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.5128e-06\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.3518e-06\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.2932e-06\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "30/30 [==============================] - 1s 16ms/step\n",
      "(300000, 400)\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.0069\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.0059\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0059\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0056\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0054\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0053\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0052\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0051\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0051\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0049\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0048\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0047\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0047\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0046\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0046\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0045\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0044\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0044\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0044\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0044\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0043\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0043\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0042\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0042\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0042\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0042\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0041\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0041\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0040\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0040\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0040\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0039\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0039\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0039\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0038\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0038\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0037\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0037\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0036\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0036\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0036\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0035\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0035\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0034\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0034\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0034\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0033\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0033\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0032\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "30/30 [==============================] - 0s 9ms/step\n",
      "(300000, 400)\n",
      "Epoch 1/50\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.0056\n",
      "Epoch 2/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0047\n",
      "Epoch 3/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0043\n",
      "Epoch 4/50\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0041\n",
      "Epoch 5/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0039\n",
      "Epoch 6/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0037\n",
      "Epoch 7/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0035\n",
      "Epoch 8/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0034\n",
      "Epoch 9/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0037\n",
      "Epoch 10/50\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0042\n",
      "Epoch 11/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0036\n",
      "Epoch 12/50\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0034\n",
      "Epoch 13/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0033\n",
      "Epoch 14/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0033\n",
      "Epoch 15/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0033\n",
      "Epoch 16/50\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0033\n",
      "Epoch 17/50\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0032\n",
      "Epoch 18/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0032\n",
      "Epoch 19/50\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0032\n",
      "Epoch 20/50\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0031\n",
      "Epoch 21/50\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0031\n",
      "Epoch 22/50\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0031\n",
      "Epoch 23/50\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0031\n",
      "Epoch 24/50\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0031\n",
      "Epoch 25/50\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0031\n",
      "Epoch 26/50\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0030\n",
      "Epoch 27/50\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0030\n",
      "Epoch 28/50\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0030\n",
      "Epoch 29/50\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0030\n",
      "Epoch 30/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0030\n",
      "Epoch 31/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0030\n",
      "Epoch 32/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0029\n",
      "Epoch 33/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0029\n",
      "Epoch 34/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0029\n",
      "Epoch 35/50\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 0.0029\n",
      "Epoch 36/50\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.0029\n",
      "Epoch 37/50\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.0028\n",
      "Epoch 38/50\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.0028\n",
      "Epoch 39/50\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.0028\n",
      "Epoch 40/50\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.0028\n",
      "Epoch 41/50\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.0028\n",
      "Epoch 42/50\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.0027\n",
      "Epoch 43/50\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.0027\n",
      "Epoch 44/50\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.0027\n",
      "Epoch 45/50\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.0027\n",
      "Epoch 46/50\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.0026\n",
      "Epoch 47/50\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.0026\n",
      "Epoch 48/50\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.0026\n",
      "Epoch 49/50\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.0026\n",
      "Epoch 50/50\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.0026\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "30/30 [==============================] - 1s 14ms/step\n",
      "(300000, 400)\n",
      "Epoch 1/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0039\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0033\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 3s 16ms/step - loss: 0.0030\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.0031\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.0029\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0027\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0027\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0026\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.0025\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0024\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0023\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0023\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.0022\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.0021\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.0021\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.0021\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.0020\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.0020\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.0020\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 4s 24ms/step - loss: 0.0021\n",
      "33/33 [==============================] - 1s 16ms/step\n",
      "30/30 [==============================] - 1s 25ms/step\n",
      "(300000, 400)\n",
      "1 2025-04-11 11:06:27.459558\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "30/30 [==============================] - 0s 14ms/step\n",
      "(300000, 400)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "30/30 [==============================] - 1s 18ms/step\n",
      "(300000, 400)\n",
      "3/3 [==============================] - 0s 151ms/step\n",
      "30/30 [==============================] - 1s 15ms/step\n",
      "(300000, 400)\n",
      "6/6 [==============================] - 0s 51ms/step\n",
      "30/30 [==============================] - 0s 9ms/step\n",
      "(300000, 400)\n",
      "33/33 [==============================] - 1s 16ms/step\n",
      "30/30 [==============================] - 1s 15ms/step\n",
      "(300000, 400)\n",
      "2 2025-04-11 11:07:10.132480\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "30/30 [==============================] - 1s 16ms/step\n",
      "(300000, 400)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "30/30 [==============================] - 0s 15ms/step\n",
      "(300000, 400)\n",
      "3/3 [==============================] - 0s 65ms/step\n",
      "30/30 [==============================] - 1s 19ms/step\n",
      "(300000, 400)\n",
      "6/6 [==============================] - 0s 72ms/step\n",
      "30/30 [==============================] - 1s 16ms/step\n",
      "(300000, 400)\n",
      "33/33 [==============================] - 1s 16ms/step\n",
      "30/30 [==============================] - 1s 13ms/step\n",
      "(300000, 400)\n",
      "3 2025-04-11 11:07:49.467591\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "30/30 [==============================] - 1s 17ms/step\n",
      "(300000, 400)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "30/30 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "tf.random.set_seed(2025)\n",
    "np.random.seed(2025)\n",
    "import datetime \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:  # gpu가 있다면, 용량 한도를 5GB로 설정\n",
    "  tf.config.experimental.set_virtual_device_configuration(gpus[0], \n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=6*1024)])\n",
    "\n",
    "# x , y, 데이터 가져오기 \n",
    "x = pd.DataFrame(np.load('ppp/open/datas/data_14/all_pca_400_x.npy'))\n",
    "y = pd.read_csv('ppp/open/datas/data_14/all_pca_400_y.csv')[\"Segment\"]\n",
    "\n",
    "\n",
    "# 오토인코더 모델 정의\n",
    "def build_autoencoder(input_dim):\n",
    "    input_layer = layers.Input(shape=(input_dim,))\n",
    "    \n",
    "    # 인코더\n",
    "    encoded = layers.Dense(1024, activation='relu')(input_layer)\n",
    "    encoded = layers.Dense(1024, activation='relu')(encoded)\n",
    "    encoded = layers.Dense(1024, activation='relu')(encoded)\n",
    "    latent_space = layers.Dense(200, activation='relu')(encoded)  # 잠재 공간 벡터\n",
    "    \n",
    "    # 디코더\n",
    "    decoded = layers.Dense(1024, activation='relu')(latent_space)\n",
    "    decoded = layers.Dense(1024, activation='relu')(decoded)\n",
    "    decoded = layers.Dense(1024, activation='relu')(decoded)\n",
    "    output_layer = layers.Dense(input_dim, activation='sigmoid')(decoded)  # 원본 차원으로 복원\n",
    "    \n",
    "    autoencoder = models.Model(input_layer, output_layer)\n",
    "    encoder = models.Model(input_layer, latent_space)  # 인코더 부분만 별도 모델로\n",
    "    \n",
    "    autoencoder.compile(optimizer='adam', loss='mse')  \n",
    "    \n",
    "    return autoencoder, encoder\n",
    "def decoders(autoencoder):\n",
    "    decoder_input = layers.Input(shape=(200,))  \n",
    "    decoder_layer = autoencoder.layers[-4](decoder_input)\n",
    "    decoder_layer = autoencoder.layers[-3](decoder_layer)  \n",
    "    decoder_layer = autoencoder.layers[-2](decoder_layer)  \n",
    "    decoder_layer = autoencoder.layers[-1](decoder_layer)  \n",
    "    decoder = models.Model(decoder_input, decoder_layer)\n",
    "    return decoder\n",
    "\n",
    "aek=0\n",
    "auto_list=[]\n",
    "\n",
    "\n",
    "#os.mkdir(\"ppp/open/AE_data_01_07m_400\")\n",
    "#os.mkdir(\"ppp/open/AE_data_01_07m_400/AE_x\")\n",
    "#os.mkdir(\"ppp/open/AE_data_01_07m_400/AE_y\")\n",
    "#os.mkdir(\"ppp/open/AE_data_01_07m_400/AE_model\")\n",
    "fname=\"AE_data_01_07m_400\"\n",
    "u=os.listdir(\"ppp/open/AE_data_01_07m_400/AE_x/\")\n",
    "if u :\n",
    "    start=max(list(map(lambda x : int(x.split(\"_\")[-2]),u)))+1\n",
    "else:\n",
    "    start=1\n",
    "for jkl in range(start,start+50):\n",
    "\n",
    "    xaep=[]\n",
    "    yaep=[]\n",
    "    # 모델 빌드\n",
    "    for i in range(5):\n",
    "    \n",
    "        xxx=x.loc[y[y==i].index]#[:10000]\n",
    "        ep=[200,200,50,50,20][i]\n",
    "        bh=[20,16,256,512,2048][i]\n",
    "        nn=300000 # kj-len(xxx)\n",
    "    \n",
    "        input_dim = xxx.shape[1]  # 데이터의 열 수\n",
    "        X_train = xxx.values \n",
    "        with tf.device('/cpu:0'):\n",
    "               X_train = tf.convert_to_tensor(X_train, np.float32)\n",
    "        if aek==0:\n",
    "            \n",
    "            autoencoder, encoder = build_autoencoder(input_dim)     \n",
    "            \n",
    "            auto_list.append([autoencoder, encoder])\n",
    "            # 오토인코더 학습\n",
    "            auto_list[i][0].fit(X_train, X_train, epochs=ep, batch_size=bh)\n",
    "            #autoencoder.fit(X_train, X_train, epochs=ep, batch_size=bh)\n",
    "        # 잠재 공간에서 샘플링\n",
    "        \n",
    "                \n",
    "        latent_vectors = auto_list[i][1].predict(X_train,batch_size=10000)\n",
    "        del X_train\n",
    "        # 약간의 노이즈를 추가하여 새로운 샘플 생성\n",
    "   \n",
    "        noise_factor = 0.1\n",
    "        nf=str( noise_factor).replace(\".\", \"\")\n",
    "        def generate_new_samples(latent_vectors, num_samples):\n",
    "        \n",
    "            noise_factor = 0.1\n",
    "\n",
    "            if i==0:\n",
    "                noise_factor=0.1\n",
    "            elif i==1:\n",
    "                noise_factor=0.1\n",
    "            elif i==2:\n",
    "                noise_factor=0.1  \n",
    "            elif i==3:\n",
    "                noise_factor=0.1\n",
    "            elif i==4:\n",
    "                noise_factor=0.1\n",
    "\n",
    "        \n",
    "            noise = np.random.normal(0, noise_factor, (num_samples,latent_vectors.shape[1]))\n",
    "            new_latent_vectors = latent_vectors[np.random.choice(latent_vectors.shape[0], num_samples)]+noise\n",
    "        \n",
    "            return new_latent_vectors\n",
    "    \n",
    "        new_latent_vectors=generate_new_samples(latent_vectors,nn)\n",
    "        # 디코더 부분만 따로 모델로 정의\n",
    "        '''\n",
    "        decoder_input = layers.Input(shape=(200,))  \n",
    "        decoder_layer = autoencoder.layers[-4](decoder_input)\n",
    "        decoder_layer = autoencoder.layers[-3](decoder_layer)  \n",
    "        decoder_layer = autoencoder.layers[-2](decoder_layer)  \n",
    "        decoder_layer = autoencoder.layers[-1](decoder_layer)  \n",
    "        decoder = models.Model(decoder_input, decoder_layer)\n",
    "        '''\n",
    "        decoder=decoders(auto_list[i][0])\n",
    "        #\n",
    "        with tf.device('/cpu:0'):\n",
    "               new_latent_vectors = tf.convert_to_tensor(new_latent_vectors, np.float32)\n",
    "               #a_y = tf.convert_to_tensor(a_y, np.float32)\n",
    "            \n",
    "        augmented_data = decoder.predict(new_latent_vectors,batch_size=10000)\n",
    "        del new_latent_vectors\n",
    "        # 중복된 데이터 제거\n",
    "        augmented_data_unique = np.unique(augmented_data, axis=0)  # 중복 제거\n",
    "        print(augmented_data_unique.shape)\n",
    "        xaep.append(augmented_data_unique)\n",
    "        yaep+=[i]*nn\n",
    "    aek=1\n",
    "    tr=np.vstack(xaep)#.shape\n",
    "\n",
    "    np.save(f'ppp/open/{fname}/AE_x/all_pca_40_AE_{nf}_{jkl}_x.npy', tr)\n",
    "    np.save(f'ppp/open/{fname}/AE_y/all_pca_40_AE_{nf}_{jkl}_y.npy', np.array(yaep))\n",
    "    print( jkl, datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7e3a180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.05600013,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f3609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 68\n",
      "all_pca_40_AE_01_0_x.npy\n",
      "all_pca_40_AE_01_0_y.npy\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "import datetime \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# x , y, 데이터 가져오기 \n",
    "x = pd.DataFrame(np.load('ppp/open/datas/data_6/all_pca_40_x.npy'))\n",
    "y = pd.read_csv('ppp/open/datas/data_6/all_pca_40_y.csv')[\"Segment\"]\n",
    "\n",
    "# x,y 가져오기 \n",
    "\n",
    "#model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=20, random_state = 312,tree_method=\"hist\", device=\"cuda\")#verbosity=2, verbosity\n",
    "\n",
    "x_file = os.listdir(f'ppp/open/AE_data_01/AE_x/')\n",
    "y_file = os.listdir(f'ppp/open/AE_data_01/AE_y/')\n",
    "\n",
    "su=1\n",
    "print(len( x_file),len( y_file))\n",
    "for xx, yy in zip(x_file, y_file):\n",
    "    \n",
    "    a_x = np.load(f'ppp/open/AE_data_01/AE_x/{xx}')\n",
    "    a_y = np.load(f'ppp/open/AE_data_01/AE_y/{yy}')\n",
    "    print(xx)\n",
    "    print(yy)\n",
    "    '''\n",
    "    if su==1:\n",
    "        \n",
    "        model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=20, random_state = 312,tree_method=\"hist\", device=\"cuda\",)#verbosity=2, verbosity\n",
    "    else:\n",
    "        model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=20, random_state = 312,tree_method=\"hist\", device=\"cuda\",xgb_model=model)#verbosity=2, verbosity\n",
    "    '''\n",
    "    if su==1:\n",
    "        \n",
    "        model = XGBClassifier(n_estimators=200,\n",
    "                              learning_rate=0.01,\n",
    "                              max_depth=10,\n",
    "                              random_state = 312,\n",
    "                              tree_method=\"hist\",\n",
    "                              device=\"cuda\",\n",
    "                              n_jobs=-1,\n",
    "                              subsample=0.6,\n",
    "                              colsample_bytree=0.8,\n",
    "                              reg_alpha=0.6,\n",
    "                              )#verbosity=2, verbosity\n",
    "        model.fit(a_x, a_y)\n",
    "    else:\n",
    "        #model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=10, random_state = 312,tree_method=\"hist\", device=\"cuda\")#verbosity=2, verbosity\n",
    "        model.fit(a_x, a_y,xgb_model=model)\n",
    "        \n",
    "    #model.fit(a_x, a_y)\n",
    "    y_pred = model.predict(x) \n",
    "    gp=int(f1_score(y, y_pred,average='macro')*100)\n",
    "    print(f1_score(y,y_pred, average=None))\n",
    "    print(confusion_matrix(y,y_pred ))\n",
    "    \n",
    "    model.save_model(f\"ppp/open/AE_data_01/AE_model/xgb_200_6_all_pca_40_f1_{gp}_op_{su}.model\")\n",
    "    su+=1\n",
    "    print(f\" num : {su}, f1_score : {gp}, time : {datetime.datetime.now()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b58484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20\n",
      "all_pca_40_AE_005_10_x.npy\n",
      "all_pca_40_AE_005_10_y.npy\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "import datetime \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "# 경고창 숨기기\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "# x , y, 데이터 가져오기 \n",
    "x = pd.DataFrame(np.load('ppp/open/datas/data_6/all_pca_40_x.npy'))\n",
    "y = pd.read_csv('ppp/open/datas/data_6/all_pca_40_y.csv')[\"Segment\"]\n",
    "\n",
    "# x,y 가져오기 \n",
    "\n",
    "#model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=20, random_state = 312,tree_method=\"hist\", device=\"cuda\")#verbosity=2, verbosity\n",
    "model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=10, random_state = 312,tree_method=\"hist\", device=\"cuda\",verbosity=2 ,)#verbose = True, verbosity\n",
    "model.load_model(f\"ppp/open/AE_data_01/AE_model/xgb_200_6_all_pca_40_f1_67_op_32.model\")\n",
    "x_file = os.listdir(f'ppp/open/AE_data_005/AE_x/')\n",
    "y_file = os.listdir(f'ppp/open/AE_data_005/AE_y/')\n",
    "\n",
    "su=1\n",
    "print(len( x_file),len( y_file))\n",
    "for xx, yy in zip(x_file, y_file):\n",
    "    \n",
    "    a_x = np.load(f'ppp/open/AE_data_005/AE_x/{xx}')\n",
    "    a_y = np.load(f'ppp/open/AE_data_005/AE_y/{yy}')\n",
    "    print(xx)\n",
    "    print(yy)\n",
    "    '''\n",
    "    if su==1:\n",
    "        \n",
    "        model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=20, random_state = 312,tree_method=\"hist\", device=\"cuda\",)#verbosity=2, verbosity\n",
    "    else:\n",
    "        model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=20, random_state = 312,tree_method=\"hist\", device=\"cuda\",xgb_model=model)#verbosity=2, verbosity\n",
    "    '''\n",
    "    if su==1:\n",
    "        '''\n",
    "        model = XGBClassifier(n_estimators=200,\n",
    "                              learning_rate=0.01,\n",
    "                              max_depth=10,\n",
    "                              random_state = 312,\n",
    "                              tree_method=\"hist\",\n",
    "                              device=\"cuda\",\n",
    "                              n_jobs=-1,\n",
    "                              subsample=0.6,\n",
    "                              colsample_bytree=0.8,\n",
    "                              reg_alpha=0.6,\n",
    "                              )#verbosity=2, verbosity\n",
    "        '''\n",
    "        model.fit(a_x, a_y,xgb_model=model)\n",
    "    else:\n",
    "        #model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=10, random_state = 312,tree_method=\"hist\", device=\"cuda\")#verbosity=2, verbosity\n",
    "        model.fit(a_x, a_y,xgb_model=model)\n",
    "        \n",
    "    #model.fit(a_x, a_y)\n",
    "    y_pred = model.predict(x) \n",
    "    gp=int(f1_score(y, y_pred,average='macro')*100)\n",
    "    print(f1_score(y,y_pred, average=None))\n",
    "    print(confusion_matrix(y,y_pred ))\n",
    "    \n",
    "    model.save_model(f\"ppp/open/AE_data_005/AE_model/xgb_200_6_all_pca_40_f1_{gp}_op_{su}01_67_32.model\")\n",
    "    su+=1\n",
    "    print(f\" num : {su}, f1_score : {gp}, time : {datetime.datetime.now()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baad2072",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_pca_40_AE_01_1_x.npy\n",
      "all_pca_40_AE_01_1_y.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:09:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11019284 0.00963275 0.2198827  0.14799662 0.14137859]\n",
      "[[    20     10    127      5      0]\n",
      " [     0     24      0      0      0]\n",
      " [    72    664  16552   3963     14]\n",
      " [    56   1421  34399  22138    193]\n",
      " [    53   2840  78210 214856  24383]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:09:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num : 2, f1_score : 12, time : 2025-04-11 11:09:52.973507\n",
      "\n",
      "all_pca_40_AE_01_2_x.npy\n",
      "all_pca_40_AE_01_2_y.npy\n",
      "[0.15075377 0.02528978 0.2276732  0.14323418 0.10550337]\n",
      "[[    15      3    142      2      0]\n",
      " [     0     24      0      0      0]\n",
      " [    15    309  17598   3336      7]\n",
      " [     4    622  35630  21844    107]\n",
      " [     3    916  79955 221622  17846]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:10:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num : 3, f1_score : 13, time : 2025-04-11 11:10:38.396508\n",
      "\n",
      "all_pca_40_AE_01_3_x.npy\n",
      "all_pca_40_AE_01_3_y.npy\n",
      "[0.11049724 0.07986689 0.23548133 0.14006307 0.08765192]\n",
      "[[    10      3    147      2      0]\n",
      " [     0     24      0      0      0]\n",
      " [     7    134  18054   3062      8]\n",
      " [     1    219  36140  21763     84]\n",
      " [     1    197  77731 227726  14687]]\n",
      " num : 4, f1_score : 13, time : 2025-04-11 11:11:22.220389\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:11:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "import datetime \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# x , y, 데이터 가져오기 \n",
    "x = pd.DataFrame(np.load('ppp/open/datas/data_14/all_pca_400_x.npy'))\n",
    "y = pd.read_csv('ppp/open/datas/data_14/all_pca_400_y.csv')[\"Segment\"].values\n",
    "\n",
    "\n",
    "# x,y 가져오기 \n",
    "\n",
    "#model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=20, random_state = 312,tree_method=\"hist\", device=\"cuda\")#verbosity=2, verbosity\n",
    "fna=\"AE_data_01_07m_400\"\n",
    "x_file = os.listdir(f'ppp/open/{fna}/AE_x/')[-3:]\n",
    "y_file = os.listdir(f'ppp/open/{fna}/AE_y/')[-3:]\n",
    "\n",
    "su=1\n",
    "for xx, yy in zip(x_file, y_file):\n",
    "    a_x = np.load(f'ppp/open/{fna}/AE_x/{xx}')\n",
    "    a_y = np.load(f'ppp/open/{fna}/AE_y/{yy}')\n",
    "    print(xx)\n",
    "    print(yy)\n",
    "    #x1, x_te, y1, y_te = train_test_split(x,y,test_size=0.95,shuffle=True,stratify =y)\n",
    "\n",
    "    #a_x=np.vstack([x1,a_x])\n",
    "    #a_y=np.hstack([y1,a_y])\n",
    "    if su==1:\n",
    "        \n",
    "        model = XGBClassifier(n_estimators=50, learning_rate=0.1, max_depth=5, random_state = 312,tree_method=\"hist\", device=\"cuda\",n_jobs=-1,subsample=0.5)#verbosity=2, verbosity\n",
    "        model.fit(a_x, a_y)\n",
    "    else:\n",
    "        #model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=10, random_state = 312,tree_method=\"hist\", device=\"cuda\")#verbosity=2, verbosity\n",
    "        model.fit(a_x, a_y,xgb_model=model)\n",
    "    y_pred = model.predict(x) \n",
    "    print(f1_score(y,y_pred, average=None))\n",
    "    print(confusion_matrix(y,y_pred ))\n",
    "\n",
    "    gp=int(f1_score(y, y_pred,average='macro')*100)\n",
    "    model.save_model(f\"ppp/open/{fna}/AE_model/xgb_50_5_all_pca_40_f1_{gp}_{su}_01_shuffle.model\")\n",
    "    su+=1\n",
    "    print(f\" num : {su}, f1_score : {gp}, time : {datetime.datetime.now()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3807bde3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_pca_40_AE_00005_10_x.npy\n",
      "all_pca_40_AE_00005_10_y.npy\n",
      "[0.16814797 0.06744557 0.3388082  0.42098169 0.83103471]\n",
      "[[   1050      10      71       3       0]\n",
      " [     21     127      20       0       0]\n",
      " [   8408    2615   65092   65394    7346]\n",
      " [   1364     612   82344  262360   60769]\n",
      " [    512     234   87859  511214 1642575]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:15:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num : 2, f1_score : 36, time : 2025-04-10 18:15:33.884590\n",
      "\n",
      "all_pca_40_AE_00005_11_x.npy\n",
      "all_pca_40_AE_00005_11_y.npy\n",
      "[0.23039271 0.19455253 0.35024813 0.44891176 0.83266623]\n",
      "[[   1012       2     109      11       0]\n",
      " [     22     125      21       0       0]\n",
      " [   5629     852   54310   81385    6679]\n",
      " [    699      88   52608  299008   55046]\n",
      " [    289      50   54220  544293 1643542]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:15:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num : 3, f1_score : 41, time : 2025-04-10 18:15:54.994653\n",
      "\n",
      "all_pca_40_AE_0005_10_x.npy\n",
      "all_pca_40_AE_0005_10_y.npy\n",
      "[0.27531735 0.28324324 0.33930696 0.42645687 0.89050863]\n",
      "[[    976       3     111       9      35]\n",
      " [      0     131      20       7      10]\n",
      " [   4103     549   57738   62014   24451]\n",
      " [    613      47   69379  192947  144463]\n",
      " [    264      27   64226  242458 1935419]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:16:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num : 4, f1_score : 44, time : 2025-04-10 18:16:20.544260\n",
      "\n",
      "all_pca_40_AE_0005_11_x.npy\n",
      "all_pca_40_AE_0005_11_y.npy\n",
      "[0.3306222  0.46415094 0.36258613 0.35845823 0.88286452]\n",
      "[[    813       2     291      27       1]\n",
      " [      3     123      39       2       1]\n",
      " [   2484     208  103510   32467   10186]\n",
      " [    323      12  169564  149250   88300]\n",
      " [    161      17  148695  243538 1849983]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:16:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num : 5, f1_score : 47, time : 2025-04-10 18:16:48.257875\n",
      "\n",
      "all_pca_40_AE_005_10_x.npy\n",
      "all_pca_40_AE_005_10_y.npy\n",
      "[0.37866109 0.67213115 0.40379485 0.3989105  0.88581092]\n",
      "[[    905       1     223       2       3]\n",
      " [      5     123      39       1       0]\n",
      " [   2326      65   99064   35635   11765]\n",
      " [    277       1  135967  177432   93772]\n",
      " [    133       8  106517  269064 1866672]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:17:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num : 6, f1_score : 54, time : 2025-04-10 18:17:18.172440\n",
      "\n",
      "all_pca_40_AE_005_11_x.npy\n",
      "all_pca_40_AE_005_11_y.npy\n",
      "[0.42730409 0.72435897 0.39156328 0.37834611 0.88611527]\n",
      "[[    867       0     264       1       2]\n",
      " [      2     113      52       1       0]\n",
      " [   1743      24  105726   29982   11380]\n",
      " [    220       0  155816  159712   91701]\n",
      " [     92       7  129307  247119 1865869]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:17:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num : 7, f1_score : 56, time : 2025-04-10 18:17:50.330629\n",
      "\n",
      "all_pca_40_AE_01_0_x.npy\n",
      "all_pca_40_AE_01_0_y.npy\n",
      "[0.37596976 0.75882353 0.46431416 0.46292773 0.90481714]\n",
      "[[    945       1     183       2       3]\n",
      " [      6     129      33       0       0]\n",
      " [   2473      35   80744   48249   17354]\n",
      " [    336       0   74714  205723  126676]\n",
      " [    133       7   43270  227368 1971616]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:18:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num : 8, f1_score : 59, time : 2025-04-10 18:18:26.079211\n",
      "\n",
      "all_pca_40_AE_01_10_x.npy\n",
      "all_pca_40_AE_01_10_y.npy\n",
      "[0.27006562 0.75482094 0.46513909 0.45722709 0.90457191]\n",
      "[[   1070       0      62       1       1]\n",
      " [      4     137      27       0       0]\n",
      " [   4610      49   78255   46603   19338]\n",
      " [    822       1   69880  200519  136227]\n",
      " [    284       8   39401  222537 1980164]]\n",
      " num : 9, f1_score : 57, time : 2025-04-10 18:19:04.220745\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:19:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "import datetime \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# x , y, 데이터 가져오기 \n",
    "x = pd.DataFrame(np.load('ppp/open/datas/data_6/all_pca_40_x.npy'))\n",
    "y = pd.read_csv('ppp/open/datas/data_6/all_pca_40_y.csv')[\"Segment\"].values\n",
    "\n",
    "\n",
    "# x,y 가져오기 \n",
    "\n",
    "#model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=20, random_state = 312,tree_method=\"hist\", device=\"cuda\")#verbosity=2, verbosity\n",
    "su=1\n",
    "ffiles=list(filter(lambda x:\"AE\" in x ,os.listdir(f'ppp/open/')))\n",
    "fna=\"AE_data_00005\"\n",
    "for fna in ffiles:\n",
    "    x_file = os.listdir(f'ppp/open/{fna}/AE_x/')\n",
    "    y_file = os.listdir(f'ppp/open/{fna}/AE_y/')\n",
    "\n",
    "    \n",
    "    for xx, yy in list(zip(x_file, y_file))[:2]:\n",
    "        a_x = np.load(f'ppp/open/{fna}/AE_x/{xx}')\n",
    "        a_y = np.load(f'ppp/open/{fna}/AE_y/{yy}')\n",
    "        print(xx)\n",
    "        print(yy)\n",
    "        #x1, x_te, y1, y_te = train_test_split(x,y,test_size=0.95,shuffle=True,stratify =y)\n",
    "\n",
    "        #a_x=np.vstack([x1,a_x])\n",
    "        #a_y=np.hstack([y1,a_y])\n",
    "        if su==1:\n",
    "\n",
    "            model = XGBClassifier(n_estimators=50, learning_rate=0.1, max_depth=5, random_state = 312,tree_method=\"hist\", device=\"cuda\",n_jobs=-1,subsample=0.5)#verbosity=2, verbosity\n",
    "            model.fit(a_x, a_y)\n",
    "        else:\n",
    "            #model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=10, random_state = 312,tree_method=\"hist\", device=\"cuda\")#verbosity=2, verbosity\n",
    "            model.fit(a_x, a_y,xgb_model=model)\n",
    "        y_pred = model.predict(x) \n",
    "        print(f1_score(y,y_pred, average=None))\n",
    "        print(confusion_matrix(y,y_pred ))\n",
    "\n",
    "        gp=int(f1_score(y, y_pred,average='macro')*100)\n",
    "        model.save_model(f\"ppp/open/models/xgb_50_5_all_pca_40_f1_{gp}_{su}_01_shuffle_subsample05.model\")\n",
    "        su+=1\n",
    "        print(f\" num : {su}, f1_score : {gp}, time : {datetime.datetime.now()}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce33743f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.67560231e-03 3.80791361e-05 2.31072121e-02 0.00000000e+00\n",
      " 0.00000000e+00]\n",
      "[[   1131       3       0       0       0]\n",
      " [    163       5       0       0       0]\n",
      " [ 102733   18476   27646       0       0]\n",
      " [ 123586   98236  185627       0       0]\n",
      " [  65953  145723 2030718       0       0]]\n",
      "[0.00842304 0.         0.02446099 0.         0.        ]\n",
      "[[   1133       1       0       0       0]\n",
      " [    168       0       0       0       0]\n",
      " [  99466   20163   29226       0       0]\n",
      " [ 107106  113380  186963       0       0]\n",
      " [  60017  157820 2024557       0       0]]\n",
      "[0.00862138 0.         0.02390999 0.         0.        ]\n",
      "[[   1123      10       1       0       0]\n",
      " [    168       0       0       0       0]\n",
      " [  95547   24839   28469       0       0]\n",
      " [ 102377  121741  183331       0       0]\n",
      " [  60166  161536 2020692       0       0]]\n",
      "[8.42591413e-03 6.31372920e-06 2.33850399e-02 0.00000000e+00\n",
      " 0.00000000e+00]\n",
      "[[   1091      43       0       0       0]\n",
      " [    167       1       0       0       0]\n",
      " [  92536   28556   27763       0       0]\n",
      " [ 101910  125443  180096       0       0]\n",
      " [  62125  162559 2017710       0       0]]\n",
      "[7.92092340e-03 1.28137774e-05 2.28525793e-02 0.00000000e+00\n",
      " 0.00000000e+00]\n",
      "[[   1075      59       0       0       0]\n",
      " [    166       2       0       0       0]\n",
      " [  93327   28487   27041       0       0]\n",
      " [ 107447  122810  177192       0       0]\n",
      " [  68284  160638 2013472       0       0]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "import datetime \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# x , y, 데이터 가져오기 \n",
    "x = pd.DataFrame(np.load('ppp/open/datas/data_6/all_pca_40_x.npy'))\n",
    "y = pd.read_csv('ppp/open/datas/data_6/all_pca_40_y.csv')[\"Segment\"].values\n",
    "\n",
    "\n",
    "#pd.DataFrame(np.load(\"ppp/open/AE_data_01/AE_y/all_pca_40_AE_01_0_y.npy\"))[:2000000]\n",
    "'''\n",
    "a=np.load(\"ppp/open/AE_data_01/AE_x/all_pca_40_AE_01_14_x.npy\")[:1000000]\n",
    "b=np.load(\"ppp/open/AE_data_01/AE_x/all_pca_40_AE_01_14_x.npy\")[1000000:2000000]\n",
    "c=np.load(\"ppp/open/AE_data_01/AE_x/all_pca_40_AE_01_14_x.npy\")[2000000:3000000]\n",
    "d=np.load(\"ppp/open/AE_data_01/AE_x/all_pca_40_AE_01_14_x.npy\")[3000000:4000000]\n",
    "e=np.load(\"ppp/open/AE_data_00005/AE_x/all_pca_40_AE_00005_10_x.npy\")[4000000:]\n",
    "xx=np.vstack([a,b,c,d,e])\n",
    "yy=np.load(\"ppp/open/AE_data_01/AE_y/all_pca_40_AE_01_14_y.npy\")\n",
    "#x0=pd.concat([x,pd.DataFrame(np.load(\"ppp/open/AE_data_01/AE_x/all_pca_40_AE_01_14_x.npy\"))[:2000000]])\n",
    "#y0=pd.concat([pd.DataFrame(y),pd.DataFrame(np.load(\"ppp/open/AE_data_01/AE_y/all_pca_40_AE_01_14_y.npy\"))[:2000000]])\n",
    "'''\n",
    "fl=os.listdir(\"ppp/open/AE_data_01/AE_x/\")\n",
    "fl2=os.listdir(\"ppp/open/AE_data_00005/AE_x/\")\n",
    "\n",
    "fl3=os.listdir(\"ppp/open/AE_data_005/AE_x/\")\n",
    "fl4=os.listdir(\"ppp/open/AE_data_0005/AE_x/\")\n",
    "fl5=os.listdir(\"ppp/open/ae_data_fck/AE_x//\")\n",
    "yy=[]\n",
    "for su,ss in enumerate(zip(fl,fl2,fl3,fl4,fl5)):\n",
    "    yy=[]\n",
    "    #a=np.load(f\"ppp/open/AE_data_01/AE_x/{ss[0]}\")[:1000000]\n",
    "    #yy+=[0]*1000000\n",
    "    #b=np.load(f\"ppp/open/AE_data_01/AE_x/{ss[0]}\")[1000000:2000000]\n",
    "    #yy+=[1]*1000000\n",
    "    c=np.load(f\"ppp/open/AE_data_01/AE_x/{ss[0]}\")[2000000:3000000]\n",
    "    yy+=[0]*1000000\n",
    "    d=np.load(f\"ppp/open/AE_data_01/AE_x/{ss[0]}\")[3000000:4000000]\n",
    "    yy+=[1]*1000000\n",
    "    e=np.load(f\"ppp/open/AE_data_01/AE_x/{ss[0]}\")[4000000:]\n",
    "    yy+=[2]*1000000\n",
    "    xx=np.vstack([c,d,e])\n",
    "    \n",
    "    yy=np.array(yy)\n",
    "    if su==0:\n",
    "        model = XGBClassifier(n_estimators=50, learning_rate=0.1, max_depth=5, random_state = 312,tree_method=\"hist\", device=\"cuda\",n_jobs=-1,subsample=0.5)#verbosity=2, verbosity\n",
    "        model.fit(xx, yy)\n",
    "    else:\n",
    "        #model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=10, random_state = 312,tree_method=\"hist\", device=\"cuda\")#verbosity=2, verbosity\n",
    "        model.fit(xx, yy,xgb_model=model)\n",
    "    y_pred = model.predict(x) \n",
    "    print(f1_score(y,y_pred, average=None))\n",
    "    print(confusion_matrix(y,y_pred ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d5ce260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:31:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11943944 0.04851752 0.36019193 0.48130483 0.93369988]\n",
      "[[   1027      17      89       1       0]\n",
      " [      8     144      16       0       0]\n",
      " [  11657    3921   36258   67096   29923]\n",
      " [   2482    1206   12359  166402  225000]\n",
      " [    889     480    3749   50514 2186762]]\n",
      "[0.23436454 0.18267293 0.50815536 0.54956841 0.93979459]\n",
      "[[    875       3     256       0       0]\n",
      " [      2     136      30       0       0]\n",
      " [   4471     916   59007   61336   23125]\n",
      " [    724     178   18644  201574  186329]\n",
      " [    261      88    5448   63213 2173384]]\n",
      "[0.36157254 0.44559585 0.55810921 0.57548337 0.94261246]\n",
      "[[    653       0     481       0       0]\n",
      " [      0     129      39       0       0]\n",
      " [   1509     237   68055   57979   21075]\n",
      " [    238      31   20644  214390  172146]\n",
      " [     78      14    5803   65260 2171239]]\n",
      "[0.47747329 0.67007673 0.58224785 0.59041464 0.94424138]\n",
      "[[    514       0     620       0       0]\n",
      " [      0     131      37       0       0]\n",
      " [    410      82   72659   55751   19953]\n",
      " [     75       5   21522  221830  164017]\n",
      " [     20       5    5888   66408 2170073]]\n",
      "[0.53414097 0.79279279 0.59485015 0.60035617 0.94537892]\n",
      "[[    485       0     649       0       0]\n",
      " [      0     132      36       0       0]\n",
      " [    159      32   74988   54392   19284]\n",
      " [     32       0   21782  226714  158921]\n",
      " [      6       1    5814   66710 2169863]]\n",
      "[0.61795873 0.87179487 0.60405145 0.60805066 0.94629012]\n",
      "[[    554       0     580       0       0]\n",
      " [      0     136      32       0       0]\n",
      " [     89       8   76620   53471   18667]\n",
      " [     13       0   21857  230557  155022]\n",
      " [      3       0    5743   66871 2169777]]\n",
      "[0.70065076 0.9245283  0.6123791  0.61410177 0.94698027]\n",
      "[[    646       0     488       0       0]\n",
      " [      0     147      21       0       0]\n",
      " [     52       3   78131   52408   18261]\n",
      " [     10       0   21936  233386  152117]\n",
      " [      2       0    5741   66846 2169805]]\n",
      "[0.77580813 0.96636086 0.61849049 0.61986149 0.94766034]\n",
      "[[    744       0     390       0       0]\n",
      " [      0     158      10       0       0]\n",
      " [     31       1   79164   51697   17962]\n",
      " [      7       0   21890  236157  149395]\n",
      " [      2       0    5682   66664 2170046]]\n",
      "[0.81507896 0.98489426 0.62437393 0.62508283 0.94823949]\n",
      "[[    800       0     334       0       0]\n",
      " [      0     163       5       0       0]\n",
      " [     24       0   80095   51065   17671]\n",
      " [      4       0   21609  238651  147185]\n",
      " [      1       0    5663   66417 2170313]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "import datetime \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# x , y, 데이터 가져오기 \n",
    "x = pd.DataFrame(np.load('ppp/open/datas/data_6/all_pca_40_x.npy'))\n",
    "y = pd.read_csv('ppp/open/datas/data_6/all_pca_40_y.csv')[\"Segment\"].values\n",
    "\n",
    "\n",
    "#pd.DataFrame(np.load(\"ppp/open/AE_data_01/AE_y/all_pca_40_AE_01_0_y.npy\"))[:2000000]\n",
    "\n",
    "x0=pd.concat([x,pd.DataFrame(np.load(\"ppp/open/AE_data_01/AE_x/all_pca_40_AE_01_14_x.npy\"))[:2000000]])\n",
    "y0=pd.concat([pd.DataFrame(y),pd.DataFrame(np.load(\"ppp/open/AE_data_01/AE_y/all_pca_40_AE_01_14_y.npy\"))[:2000000]])\n",
    "\n",
    "\n",
    "for su in range(1,10):\n",
    "    \n",
    "    if su==1:\n",
    "        model = XGBClassifier(n_estimators=50, learning_rate=0.1, max_depth=5, random_state = 312,tree_method=\"hist\", device=\"cuda\",n_jobs=-1,subsample=0.5)#verbosity=2, verbosity\n",
    "        model.fit(x0, y0)\n",
    "    else:\n",
    "        #model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=10, random_state = 312,tree_method=\"hist\", device=\"cuda\")#verbosity=2, verbosity\n",
    "        model.fit(x0, y0,xgb_model=model)\n",
    "    y_pred = model.predict(x) \n",
    "    print(f1_score(y,y_pred, average=None))\n",
    "    print(confusion_matrix(y,y_pred ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2868f537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "822b38f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88768719 0.95440729 0.55174061 0.51110872 0.92767925]\n",
      "[[   1067       0      60       4       3]\n",
      " [      0     157      10       0       1]\n",
      " [    150       4   76234   45880   26587]\n",
      " [     36       0   37404  194782  175227]\n",
      " [     17       0   13777  114079 2114521]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "import datetime \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "        \n",
    "from sklearn.model_selection import train_test_split\n",
    "x = pd.DataFrame(np.load('ppp/open/datas/data_6/all_pca_40_x.npy'))\n",
    "y = pd.read_csv('ppp/open/datas/data_6/all_pca_40_y.csv')[\"Segment\"].values\n",
    "model = XGBClassifier(n_estimators=50, learning_rate=0.1, max_depth=5, random_state = 312,tree_method=\"hist\", device=\"cuda\",n_jobs=-1,subsample=0.5)#verbosity=2, verbosity\n",
    "model.load_model(\"ppp/open/AE_data_01/AE_model/xgb_200_6_all_pca_40_f1_67_op_32.model\")\n",
    "model.fit(x, y, xgb_model=model)\n",
    "\n",
    "y_pred = model.predict(x) \n",
    "print(f1_score(y,y_pred, average=None))\n",
    "print(confusion_matrix(y,y_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "476bb930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:42:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save_model(f\"ppp/open/models/xgb_200_10_all_pca_40_f1_67_32_xytr_01_shuffle_subsample05.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da4d1317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(88+95+55+51+92)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2e5d8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:54:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25870783 0.25300092 0.31531757 0.36453373 0.71390093]\n",
      "[[    947       6     135      46       0]\n",
      " [     10     137      15       6       0]\n",
      " [   4364     647   53630   86128    4086]\n",
      " [    601      85   65580  312202   28981]\n",
      " [    265      40   71950  907053 1263086]]\n",
      "[0.35968214 0.57011494 0.31348903 0.36481494 0.69664449]\n",
      "[[    860       2     193      79       0]\n",
      " [      6     124      21      17       0]\n",
      " [   2327     127   50378   92446    3577]\n",
      " [    304       9   55536  326113   25487]\n",
      " [    151       5   66419  961723 1214096]]\n",
      "[0.39547739 0.69253731 0.30630739 0.36008981 0.67925133]\n",
      "[[    787       1     193     153       0]\n",
      " [      4     116      21      27       0]\n",
      " [   1719      47   48165   95600    3324]\n",
      " [    230       1   51732  332241   23245]\n",
      " [    106       2   65522 1009853 1166911]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "import datetime \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 01 a b \n",
    "a=np.load(\"ppp/open/AE_data_01/AE_x/all_pca_40_AE_01_0_x.npy\")[:2000000]\n",
    "# 0005 c d\n",
    "b=np.load(\"ppp/open/AE_data_0005/AE_x/all_pca_40_AE_0005_10_x.npy\")[2000000:4000000]\n",
    "# 00005 e \n",
    "c=np.load(\"ppp/open/AE_data_00005/AE_x/all_pca_40_AE_00005_10_x.npy\")[4000000:]\n",
    "\n",
    "x = pd.DataFrame(np.load('ppp/open/datas/data_6/all_pca_40_x.npy'))\n",
    "y = pd.read_csv('ppp/open/datas/data_6/all_pca_40_y.csv')[\"Segment\"].values\n",
    "\n",
    "\n",
    "x1=np.vstack([a,b,c])\n",
    "y1=np.load(\"ppp/open/AE_data_01/AE_y/all_pca_40_AE_01_0_y.npy\")\n",
    "\n",
    "for su in range(1,10):\n",
    "    \n",
    "    if su==1:\n",
    "        model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state = 312,tree_method=\"hist\", device=\"cuda\",n_jobs=-1,subsample=0.5)#verbosity=2, verbosity\n",
    "        model.fit(x1, y1)\n",
    "    else:\n",
    "        #model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=10, random_state = 312,tree_method=\"hist\", device=\"cuda\")#verbosity=2, verbosity\n",
    "        model.fit(x1, y1,xgb_model=model)\n",
    "    y_pred = model.predict(x) \n",
    "    print(f1_score(y,y_pred, average=None))\n",
    "    print(confusion_matrix(y,y_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "744bd34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:51:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save_model(f\"ppp/open/models/01010050050005.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b832635d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39353ad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_pca_40_AE_00005_10_x.npy\n",
      "all_pca_40_AE_00005_10_y.npy\n",
      "Epoch 1/2\n",
      "167/167 [==============================] - 9s 46ms/step - loss: 0.6082 - f1_macro: 0.7424 - val_loss: 0.5481 - val_f1_macro: 0.4394\n",
      "Epoch 2/2\n",
      "167/167 [==============================] - 7s 42ms/step - loss: 0.3830 - f1_macro: 0.8434 - val_loss: 0.4834 - val_f1_macro: 0.4518\n",
      " num : 2, time : 2025-04-10 17:01:40.371211\n",
      "\n",
      "all_pca_40_AE_00005_11_x.npy\n",
      "all_pca_40_AE_00005_11_y.npy\n",
      "Epoch 1/2\n",
      "167/167 [==============================] - 8s 45ms/step - loss: 0.3526 - f1_macro: 0.8559 - val_loss: 0.7593 - val_f1_macro: 0.4485\n",
      "Epoch 2/2\n",
      "167/167 [==============================] - 7s 42ms/step - loss: 0.3199 - f1_macro: 0.8710 - val_loss: 0.4769 - val_f1_macro: 0.4785\n",
      " num : 2, time : 2025-04-10 17:01:55.682321\n",
      "\n",
      "all_pca_40_AE_00005_1_x.npy\n",
      "all_pca_40_AE_00005_1_y.npy\n",
      "Epoch 1/2\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.3821 - f1_macro: 0.8495 - val_loss: 0.5401 - val_f1_macro: 0.4521\n",
      "Epoch 2/2\n",
      "167/167 [==============================] - 7s 42ms/step - loss: 0.2956 - f1_macro: 0.8833 - val_loss: 0.5140 - val_f1_macro: 0.4525\n",
      " num : 2, time : 2025-04-10 17:02:11.416644\n",
      "\n",
      "all_pca_40_AE_00005_2_x.npy\n",
      "all_pca_40_AE_00005_2_y.npy\n",
      "Epoch 1/2\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.2739 - f1_macro: 0.8922 - val_loss: 0.5637 - val_f1_macro: 0.4548\n",
      "Epoch 2/2\n",
      "167/167 [==============================] - 7s 42ms/step - loss: 0.2682 - f1_macro: 0.8944 - val_loss: 0.7018 - val_f1_macro: 0.4495\n",
      " num : 2, time : 2025-04-10 17:02:27.345278\n",
      "\n",
      "all_pca_40_AE_00005_3_x.npy\n",
      "all_pca_40_AE_00005_3_y.npy\n",
      "Epoch 1/2\n",
      "107/167 [==================>...........] - ETA: 2s - loss: 0.2386 - f1_macro: 0.9076"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "import datetime \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "tf.random.set_seed(2025)\n",
    "np.random.seed(2025)\n",
    "import datetime \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:  # gpu가 있다면, 용량 한도를 5GB로 설정\n",
    "  tf.config.experimental.set_virtual_device_configuration(gpus[0], \n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=6*1024)])\n",
    "\n",
    "# x , y, 데이터 가져오기 \n",
    "x = pd.DataFrame(np.load('ppp/open/datas/data_6/all_pca_40_x.npy'))\n",
    "y = pd.read_csv('ppp/open/datas/data_6/all_pca_40_y.csv')[\"Segment\"]\n",
    "y=pd.get_dummies(y)\n",
    "\n",
    "x11, x22, y11, y22 = train_test_split(x, y, test_size=0.3, random_state=42,shuffle=True,stratify=y)\n",
    "x33, x44, y33, y44 = train_test_split(x22, y22, test_size=0.01, random_state=42,shuffle=True,stratify=y22)\n",
    "\n",
    "# x,y 가져오기 \n",
    "\n",
    "# F1 Score를 계산하는 커스텀 메트릭스 함수\n",
    "def f1_macro(y_true, y_pred):\n",
    "    # 예측값에서 가장 큰 값의 인덱스를 추출 (One-Hot Encoding -> 클래스 번호로 변환)\n",
    "    y_pred_classes = tf.argmax(y_pred, axis=-1)\n",
    "    y_true_classes = tf.argmax(y_true, axis=-1)\n",
    "    \n",
    "    # F1 score 계산\n",
    "    f1 = tf.py_function(\n",
    "        lambda y_true, y_pred: f1_score(y_true, y_pred, average='macro'),\n",
    "        [y_true_classes, y_pred_classes],\n",
    "        tf.float32\n",
    "    )\n",
    "    \n",
    "    return f1\n",
    "model = Sequential()\n",
    "\n",
    "# 입력층과 첫 번째 은닉층\n",
    "model.add(Dense(1024, input_dim=40, activation='relu'))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(51, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=[f1_macro])\n",
    "\n",
    "import os \n",
    "\n",
    "\n",
    "ffiles=list(filter(lambda x:\"AE\" in x ,os.listdir(f'ppp/open/')))\n",
    "for nn in range(20):\n",
    "    for fn in ffiles[:1]:\n",
    "        fn=\"AE_data_00005\"\n",
    "        x_file = os.listdir(f'ppp/open/{fn}/AE_x/')\n",
    "        y_file = os.listdir(f'ppp/open/{fn}/AE_y/')\n",
    "\n",
    "        su=1\n",
    "        for xx, yy in list(zip(x_file, y_file))[nn:nn+1]:\n",
    "            a_x = np.load(f'ppp/open/{fn}/AE_x/{xx}')\n",
    "            a_y = np.load(f'ppp/open/{fn}/AE_y/{yy}')\n",
    "            \n",
    "            a_y=pd.get_dummies(a_y)\n",
    "            \n",
    "            #a_x=np.vstack([x33,a_x])\n",
    "            #a_y=np.vstack([y33,a_y])\n",
    "            with tf.device('/cpu:0'):\n",
    "               a_x = tf.convert_to_tensor(a_x, np.float32)\n",
    "               a_y = tf.convert_to_tensor(a_y, np.float32)\n",
    "\n",
    "            print(xx)\n",
    "            print(yy)\n",
    "            #if su==1:\n",
    "            \n",
    "            model.fit(a_x, a_y, epochs=2, batch_size=30000, validation_data=(x11, y11))\n",
    "\n",
    "            \n",
    "            #test_loss, test_acc = model.evaluate(x22, y22,batch_size=2048)\n",
    "            su+=1\n",
    "            print(f\" num : {su}, time : {datetime.datetime.now()}\")\n",
    "            print()\n",
    "            del a_x,a_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05d8ea85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AE_data', 'AE_data_01', 'AE_data_02']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "list(filter(lambda x:\"AE\" in x ,os.listdir(f'ppp/open/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7621a24c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda6932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "import datetime \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "x = pd.DataFrame(np.load('ppp/open/datas/data_6/all_pca_40_x.npy'))\n",
    "y = pd.read_csv('ppp/open/datas/data_6/all_pca_40_y.csv')[\"Segment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd14fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = pd.DataFrame(np.load('ppp/open/AE_data_01/AE_x/all_pca_40_AE_01_0_x.npy'))\n",
    "#y = np.load('ppp/open/AE_data_01/AE_y/all_pca_40_AE_01_11_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2ae7965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00196273, 0.74943984, 0.32633352, ..., 0.3469764 , 0.22710495,\n",
       "        0.49726948],\n",
       "       [0.00203551, 0.7414431 , 0.34441128, ..., 0.45883355, 0.33418533,\n",
       "        0.61503303],\n",
       "       [0.00208634, 0.7129164 , 0.37804583, ..., 0.46564317, 0.34485123,\n",
       "        0.6040838 ],\n",
       "       ...,\n",
       "       [0.9999883 , 0.1328285 , 0.8106572 , ..., 0.37945217, 0.2052309 ,\n",
       "        0.41671276],\n",
       "       [0.99999106, 0.1488867 , 0.6724597 , ..., 0.5959051 , 0.23235561,\n",
       "        0.48170665],\n",
       "       [0.9999912 , 0.07628937, 0.6892963 , ..., 0.5062025 , 0.20894049,\n",
       "        0.4266767 ]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b92291f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800000,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x=x[400000:]\n",
    "y.shape\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f403103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=[]\n",
    "ty=[]\n",
    "for i in range(400000):\n",
    "    t.append(x[i+400000::400000])\n",
    "    ty.append(y[i+400000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf35d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 6, 40)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xi=np.array(t)\n",
    "yi=np.array(ty)\n",
    "xi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4ab8fc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800000,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack([yi,yi]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cce1fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 24, 6, 40)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt=[]\n",
    "for i in range(2):\n",
    "    noi=np.random.normal(0,0.0001,(24,6,40))\n",
    "    noi[noi<0]=0\n",
    "    noi[noi>1]=1\n",
    "    ttt.append(xi[np.where(yi==1)]+noi)\n",
    "    #yi=np.hstack([yi,np.array([1]*24)])\n",
    "np.array(ttt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86645e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh=np.array(ttt)\n",
    "xi=np.vstack([xi,hh.reshape(24*2,6,40)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fc89c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "yi=np.hstack([yi,np.array([1]*(24*2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "307edbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xi=np.expand_dims(xi, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df7037c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x0000019692007820>>\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 23s 127ms/step - loss: 0.4498 - f1_macro: 0.4304 - val_loss: 0.3336 - val_f1_macro: 0.6654\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 19s 124ms/step - loss: 0.3135 - f1_macro: 0.5638 - val_loss: 0.3086 - val_f1_macro: 0.6801\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 19s 124ms/step - loss: 0.2981 - f1_macro: 0.5745 - val_loss: 0.2901 - val_f1_macro: 0.6823\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 20s 125ms/step - loss: 0.2907 - f1_macro: 0.5922 - val_loss: 0.2861 - val_f1_macro: 0.6973\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 20s 125ms/step - loss: 0.2819 - f1_macro: 0.5874 - val_loss: 0.2817 - val_f1_macro: 0.7013\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 19s 123ms/step - loss: 0.2784 - f1_macro: 0.5925 - val_loss: 0.2787 - val_f1_macro: 0.6921\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 19s 123ms/step - loss: 0.2717 - f1_macro: 0.5981 - val_loss: 0.2668 - val_f1_macro: 0.7017\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 19s 124ms/step - loss: 0.2653 - f1_macro: 0.6135 - val_loss: 0.2635 - val_f1_macro: 0.7135\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 19s 124ms/step - loss: 0.2620 - f1_macro: 0.6171 - val_loss: 0.2617 - val_f1_macro: 0.7047\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 19s 124ms/step - loss: 0.2596 - f1_macro: 0.6177 - val_loss: 0.2686 - val_f1_macro: 0.6942\n",
      "2501/2501 - 8s - loss: 0.2686 - f1_macro: 0.7079 - 8s/epoch - 3ms/step\n",
      "\n",
      "Test accuracy: 0.7078546285629272\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.metrics import PrecisionAtRecall,RecallAtPrecision\n",
    "from tensorflow.keras import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:  # gpu가 있다면, 용량 한도를 5GB로 설정\n",
    "  tf.config.experimental.set_virtual_device_configuration(gpus[0], \n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=6*1024)])\n",
    "\n",
    "x1, x_te, y1, y_te = train_test_split(xi,yi,test_size=0.2,shuffle=True,stratify =yi)\n",
    "\n",
    "def f1_macro(y_true, y_pred):\n",
    "    # 예측값에서 가장 큰 값의 인덱스를 추출 (One-Hot Encoding -> 클래스 번호로 변환)\n",
    "    y_pred_classes = tf.argmax(y_pred, axis=-1)\n",
    "    y_true_classes = tf.argmax(y_true, axis=-1)\n",
    "    \n",
    "    # F1 score 계산\n",
    "    f1 = tf.py_function(\n",
    "        lambda y_true, y_pred: f1_score(y_true, y_pred, average='macro'),\n",
    "        [y_true_classes, y_pred_classes],\n",
    "        tf.float32\n",
    "    )\n",
    "    \n",
    "    return f1\n",
    "\n",
    "y_train = to_categorical(y1, 5)\n",
    "y_test = to_categorical(y_te, 5)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(256, (3, 1), activation='relu', input_shape=(6, 40, 1), padding='same'),\n",
    "    layers.MaxPooling2D((2, 1), padding='same'),  # 풀링 크기를 줄여줍니다.\n",
    "    \n",
    "    layers.Conv2D(128, (3, 1), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 1), padding='same'),  # 풀링 크기를 줄여줍니다.\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(5, activation='softmax')  \n",
    "])\n",
    "\n",
    "print(model.summary)\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  \n",
    "              metrics=f1_macro)\n",
    "\n",
    "history = model.fit(x1, y_train, epochs=10, batch_size=2048, validation_data=(x_te, y_test),validation_batch_size=512)\n",
    "\n",
    "\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_acc = model.evaluate(x_te, y_test, verbose=2)\n",
    "print(f'\\nTest accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc82c3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cfae7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4], dtype=int64), array([   32,     5,  4253, 11642, 64068], dtype=int64))\n",
      "(array([0, 2, 3, 4], dtype=int64), array([   17,  3559, 11649, 64775], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf448cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b028f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2501/2501 [==============================] - 4s 2ms/step\n",
      "[0.42857143 0.         0.61143818 0.65316111 0.95430905]\n",
      "[[   12     1    19     0     0]\n",
      " [    5     0     9     0     0]\n",
      " [    7     2  2181  1652   411]\n",
      " [    0     0   555  7206  3881]\n",
      " [    0     0   117  1565 62387]]\n",
      "0.5294959558670278\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = model.predict(x_te)\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# F1 Score (Macro) 계산\n",
    "f1_macro = f1_score(y_true_classes, y_pred_classes, average='macro')\n",
    "print(f1_score(y_true_classes,y_pred_classes, average=None))\n",
    "print(confusion_matrix(y_true_classes,y_pred_classes ))\n",
    "print(f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b1ea5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4], dtype=int64), array([   32,    14,  4253, 11642, 64069], dtype=int64))\n",
      "(array([0, 1, 2, 3, 4], dtype=int64), array([   24,     3,  2881, 10423, 66679], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_true_classes,return_counts=True))\n",
    "print(np.unique(y_pred_classes,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e31a5d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.회원정보 201807_test_회원정보.parquet\n",
      "1.회원정보 201808_test_회원정보.parquet\n",
      "1.회원정보 201809_test_회원정보.parquet\n",
      "1.회원정보 201810_test_회원정보.parquet\n",
      "1.회원정보 201811_test_회원정보.parquet\n",
      "1.회원정보 201812_test_회원정보.parquet\n",
      "76\n",
      "2.신용정보 201807_test_신용정보.parquet\n",
      "2.신용정보 201808_test_신용정보.parquet\n",
      "2.신용정보 201809_test_신용정보.parquet\n",
      "2.신용정보 201810_test_신용정보.parquet\n",
      "2.신용정보 201811_test_신용정보.parquet\n",
      "2.신용정보 201812_test_신용정보.parquet\n",
      "116\n",
      "3.승인매출정보 201807_test_승인매출정보.parquet\n",
      "3.승인매출정보 201808_test_승인매출정보.parquet\n",
      "3.승인매출정보 201809_test_승인매출정보.parquet\n",
      "3.승인매출정보 201810_test_승인매출정보.parquet\n",
      "3.승인매출정보 201811_test_승인매출정보.parquet\n",
      "3.승인매출정보 201812_test_승인매출정보.parquet\n",
      "520\n",
      "4.청구입금정보 201807_test_청구정보.parquet\n",
      "4.청구입금정보 201808_test_청구정보.parquet\n",
      "4.청구입금정보 201809_test_청구정보.parquet\n",
      "4.청구입금정보 201810_test_청구정보.parquet\n",
      "4.청구입금정보 201811_test_청구정보.parquet\n",
      "4.청구입금정보 201812_test_청구정보.parquet\n",
      "564\n",
      "5.잔액정보 201807_test_잔액정보.parquet\n",
      "5.잔액정보 201808_test_잔액정보.parquet\n",
      "5.잔액정보 201809_test_잔액정보.parquet\n",
      "5.잔액정보 201810_test_잔액정보.parquet\n",
      "5.잔액정보 201811_test_잔액정보.parquet\n",
      "5.잔액정보 201812_test_잔액정보.parquet\n",
      "644\n",
      "6.채널정보 201807_test_채널정보.parquet\n",
      "6.채널정보 201808_test_채널정보.parquet\n",
      "6.채널정보 201809_test_채널정보.parquet\n",
      "6.채널정보 201810_test_채널정보.parquet\n",
      "6.채널정보 201811_test_채널정보.parquet\n",
      "6.채널정보 201812_test_채널정보.parquet\n",
      "747\n",
      "7.마케팅정보 201807_test_마케팅정보.parquet\n",
      "7.마케팅정보 201808_test_마케팅정보.parquet\n",
      "7.마케팅정보 201809_test_마케팅정보.parquet\n",
      "7.마케팅정보 201810_test_마케팅정보.parquet\n",
      "7.마케팅정보 201811_test_마케팅정보.parquet\n",
      "7.마케팅정보 201812_test_마케팅정보.parquet\n",
      "809\n",
      "8.성과정보 201807_test_성과정보.parquet\n",
      "8.성과정보 201808_test_성과정보.parquet\n",
      "8.성과정보 201809_test_성과정보.parquet\n",
      "8.성과정보 201810_test_성과정보.parquet\n",
      "8.성과정보 201811_test_성과정보.parquet\n",
      "8.성과정보 201812_test_성과정보.parquet\n",
      "856\n"
     ]
    }
   ],
   "source": [
    "path1=os.listdir(\"ppp/open/test/\")\n",
    "#data=1\n",
    "data2=10\n",
    "aaa=0\n",
    "for j in path1:    \n",
    "    a=os.listdir(f\"ppp/open/test/{j}\")\n",
    "    p=[]\n",
    "    \n",
    "    pp=[]\n",
    "    for i in a:\n",
    "        print(j,i)\n",
    "        p=(pd.read_parquet(f\"ppp/open/test/{j}/{i}\").drop(\"기준년월\",axis=1))\n",
    "        #p=p.iloc[idx]\n",
    "        #print(len(p))\n",
    "        pp.append(p)\n",
    "    #print(len(pd.concat(pp).columns))\n",
    "    #pd.concat(pp)\n",
    "    data2=pd.concat([data2,pd.concat(pp).drop(\"ID\",axis=1)],axis=1) if aaa==1 else pd.concat(pp)\n",
    "    print(len(data2.columns))\n",
    "    aaa=1\n",
    "    pp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a7c6aaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=data2\n",
    "#x=data2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44c06897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "num=max(list(map(lambda x: int(x.split(\"_\")[-1]),os.listdir(\"ppp/open/datas\"))))-15\n",
    "x=pd.DataFrame(np.load(f'ppp/open/datas/data_{num}/all_pca_40_x.npy'))\n",
    "y=pd.read_csv(f\"ppp/open/datas/data_{num}/all_pca_40_y.csv\")[\"Segment\"]\n",
    "\n",
    "mi=pd.read_csv(f\"ppp/open/datas/data_{num}/all_mi.csv\")\n",
    "ma=pd.read_csv(f\"ppp/open/datas/data_{num}/all_ma.csv\")\n",
    "\n",
    "with open(f\"ppp/open/datas/data_{num}/all_encoder.pickle\", 'rb') as f: \n",
    "    led = pickle.load(f)\n",
    "with open(f\"ppp/open/datas/data_{num}/all_pca.pickle\", 'rb') as f: \n",
    "    pca = pickle.load(f)\n",
    "with open(f\"ppp/open/datas/data_{1}/all_fillna.pickle\", 'rb') as f: \n",
    "    fid = pickle.load(f)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed07869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7edd0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.columns:\n",
    "    if data[i].dtype=='O':\n",
    "        if i==\"ID\":\n",
    "            continue\n",
    "        data[i]=led[i].transform(data[i])\n",
    "xt=data.drop([\"ID\"],axis=1)\n",
    "\n",
    "#x=x.fillna(method=\"mean\",axis=1)\n",
    "xt=xt.fillna(fid)\n",
    "#x=x.fillna(x.mean())#\n",
    "\n",
    "#pca = PCA(n_components=40)\n",
    "xt = pd.DataFrame(pca.transform(xt))\n",
    "#mi=x.min()\n",
    "#ma=x.max()\n",
    "xt=((xt-mi[\"0\"])/(ma[\"0\"]-mi[\"0\"]))\n",
    "xt=xt.fillna(0)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcd5defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"ppp/open/test.npy\",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f11e024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt=np.load(\"ppp/open/test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "244d8819",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=[]\n",
    "#ty1=[]\n",
    "for i in range(100000):\n",
    "    t1.append(xt[i::100000])\n",
    "    #ty1.append(yt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b21c18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 6, 40)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xi1=np.array(t1)\n",
    "#yi1=np.array(ty1)\n",
    "xi1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "259c632f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 5s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(xi1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a2393ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c73a6567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 4, 2, 4], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f958e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 2, 3, 4], dtype=int64), array([   36,  4370, 14449, 81145], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(np.argmax(y_pred, axis=1),return_counts=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
