{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "856acd85-e098-4a7c-94cf-61151a4418a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.회원정보 201807_train_회원정보.parquet\n",
      "2.신용정보 201807_train_신용정보.parquet\n",
      "3.승인매출정보 201807_train_승인매출정보.parquet\n",
      "4.청구입금정보 201807_train_청구정보.parquet\n",
      "5.잔액정보 201807_train_잔액정보.parquet\n",
      "6.채널정보 201807_train_채널정보.parquet\n",
      "7.마케팅정보 201807_train_마케팅정보.parquet\n",
      "8.성과정보 201807_train_성과정보.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "\n",
    "path1=os.listdir(\"C:/Users/607-12/ppp/open/train/\")\n",
    "data=1\n",
    "for j in path1:\n",
    "    \n",
    "    a=os.listdir(f\"C:/Users/607-12/ppp/open/train/{j}\")\n",
    "    p=[]\n",
    "    \n",
    "    for i in a[:1]:\n",
    "        p=pd.read_parquet(f\"C:/Users/607-12/ppp/open/train/{j}/{i}\").drop(\"기준년월\",axis=1)\n",
    "        data=pd.merge(data,p,on=\"ID\",how=\"inner\") if j!=\"1.회원정보\" else p\n",
    "        \n",
    "        print(j,i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b57e2326-18b3-4aff-b4e6-d702f44fe834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Segment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162.0</td>\n",
       "      <td>199.302469</td>\n",
       "      <td>80.278482</td>\n",
       "      <td>6.0</td>\n",
       "      <td>136.50</td>\n",
       "      <td>223.5</td>\n",
       "      <td>266.5</td>\n",
       "      <td>316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>127.708333</td>\n",
       "      <td>77.311611</td>\n",
       "      <td>2.0</td>\n",
       "      <td>81.25</td>\n",
       "      <td>118.0</td>\n",
       "      <td>185.5</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21265.0</td>\n",
       "      <td>130.105055</td>\n",
       "      <td>80.817492</td>\n",
       "      <td>2.0</td>\n",
       "      <td>63.00</td>\n",
       "      <td>114.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58207.0</td>\n",
       "      <td>95.630663</td>\n",
       "      <td>73.396287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320342.0</td>\n",
       "      <td>62.868275</td>\n",
       "      <td>68.640761</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>39.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count        mean        std  min     25%    50%    75%    max\n",
       "Segment                                                                   \n",
       "0           162.0  199.302469  80.278482  6.0  136.50  223.5  266.5  316.0\n",
       "1            24.0  127.708333  77.311611  2.0   81.25  118.0  185.5  266.0\n",
       "2         21265.0  130.105055  80.817492  2.0   63.00  114.0  200.0  322.0\n",
       "3         58207.0   95.630663  73.396287  2.0   42.00   73.0  134.0  320.0\n",
       "4        320342.0   62.868275  68.640761  2.0   10.00   39.0   87.0  333.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for i in data.columns:\n",
    "    le = LabelEncoder()\n",
    "    if data[i].dtype=='O':\n",
    "        data[i]=le.fit_transform(data[i])\n",
    "\n",
    "data.groupby(\"Segment\").describe()[\"입회경과개월수_신용\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c0b3f19-6cee-4840-9130-2831e5bb45a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "for j in data.columns:\n",
    "    \n",
    "    for i in range(0,5):\n",
    "        d=data[[\"Segment\",j]]\n",
    "        d=d[d[\"Segment\"]==i]\n",
    "        plt.scatter(d[\"Segment\"],d[j])\n",
    "    plt.title(j)\n",
    "    plt.savefig(f\"ppp/img/{j}.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3932c0d8-20c0-4652-9323-68b285f6a9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for j in data.columns:\n",
    "    if j==\"Segment\":\n",
    "        continue\n",
    "    \n",
    "    d=data[[\"Segment\",j]]\n",
    "    d=d[d[\"Segment\"]==1]\n",
    "    plt.scatter(range(len(d[j])),sorted(d[j]))\n",
    "    plt.title(j)\n",
    "    plt.savefig(f\"ppp/img1/{j}.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b165e78-cd9d-42e6-a227-50b34a59d56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 400000)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(d[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0b274c64-ec59-4315-95ca-b31853aedcd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RV신청일자            16\n",
       "최종카드론_금융상환방식코드    11\n",
       "최종카드론_대출일자        13\n",
       "연체일자_B0M          24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=data[data[\"Segment\"]==1]\n",
    "x.isnull().sum()[x.isnull().sum()>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d969750e-3933-444b-8d36-553af0ebfdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f2c124b6-a624-4e95-aa04-19b7164195ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.drop(\"ID\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6ef32c10-8d88-4968-b7db-5b9916e9eedc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>남녀구분코드</th>\n",
       "      <th>연령</th>\n",
       "      <th>Segment</th>\n",
       "      <th>회원여부_이용가능</th>\n",
       "      <th>회원여부_이용가능_CA</th>\n",
       "      <th>회원여부_이용가능_카드론</th>\n",
       "      <th>소지여부_신용</th>\n",
       "      <th>소지카드수_유효_신용</th>\n",
       "      <th>소지카드수_이용가능_신용</th>\n",
       "      <th>입회일자_신용</th>\n",
       "      <th>...</th>\n",
       "      <th>변동률_RV일시불평잔</th>\n",
       "      <th>변동률_할부평잔</th>\n",
       "      <th>변동률_CA평잔</th>\n",
       "      <th>변동률_RVCA평잔</th>\n",
       "      <th>변동률_카드론평잔</th>\n",
       "      <th>변동률_잔액_B1M</th>\n",
       "      <th>변동률_잔액_일시불_B1M</th>\n",
       "      <th>변동률_잔액_CA_B1M</th>\n",
       "      <th>혜택수혜율_R3M</th>\n",
       "      <th>혜택수혜율_B0M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33783</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19960601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.045284</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.235003</td>\n",
       "      <td>0.292826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250928</td>\n",
       "      <td>0.820717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61321</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>19970401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.046498</td>\n",
       "      <td>1.003019</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.079760</td>\n",
       "      <td>-0.010086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321904</td>\n",
       "      <td>1.111626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61664</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20100201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.058028</td>\n",
       "      <td>1.001830</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.147794</td>\n",
       "      <td>0.202691</td>\n",
       "      <td>-0.046823</td>\n",
       "      <td>-0.330547</td>\n",
       "      <td>0.550934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64700</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20131201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.049187</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.063978</td>\n",
       "      <td>-0.036457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.908533</td>\n",
       "      <td>1.729495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103311</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20180601</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007577</td>\n",
       "      <td>1.045298</td>\n",
       "      <td>1.002872</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.928411</td>\n",
       "      <td>-0.209052</td>\n",
       "      <td>-0.124355</td>\n",
       "      <td>-0.032057</td>\n",
       "      <td>0.256611</td>\n",
       "      <td>0.947896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112900</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20180601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.530249</td>\n",
       "      <td>0.844892</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>0.095173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.026059</td>\n",
       "      <td>1.445633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149555</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20040601</td>\n",
       "      <td>...</td>\n",
       "      <td>1.236102</td>\n",
       "      <td>1.047157</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.022665</td>\n",
       "      <td>-0.025760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.136402</td>\n",
       "      <td>1.245026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155671</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20100401</td>\n",
       "      <td>...</td>\n",
       "      <td>1.023803</td>\n",
       "      <td>1.056083</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.083730</td>\n",
       "      <td>-0.043347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.924277</td>\n",
       "      <td>1.227015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158775</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20080801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975048</td>\n",
       "      <td>1.046677</td>\n",
       "      <td>0.847286</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.241237</td>\n",
       "      <td>0.229954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193847</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19990101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.583822</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.056105</td>\n",
       "      <td>-0.050879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.059205</td>\n",
       "      <td>1.433706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194417</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20080801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963853</td>\n",
       "      <td>1.047271</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155146</td>\n",
       "      <td>0.084236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.267857</td>\n",
       "      <td>1.531428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211122</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20071001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.045613</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.144693</td>\n",
       "      <td>0.186482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.982185</td>\n",
       "      <td>1.453670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213882</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20111001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.054562</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.081021</td>\n",
       "      <td>0.169762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751975</td>\n",
       "      <td>0.730083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227355</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20081201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.048603</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.040512</td>\n",
       "      <td>0.073542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.541468</td>\n",
       "      <td>1.225396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235877</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20000701</td>\n",
       "      <td>...</td>\n",
       "      <td>1.110543</td>\n",
       "      <td>1.040715</td>\n",
       "      <td>1.990229</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.928766</td>\n",
       "      <td>-0.032969</td>\n",
       "      <td>0.016533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.233293</td>\n",
       "      <td>1.309625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256790</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20070401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.900760</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.009657</td>\n",
       "      <td>0.051918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289152</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20120101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.232824</td>\n",
       "      <td>0.578083</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.117470</td>\n",
       "      <td>0.115058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.736184</td>\n",
       "      <td>1.733322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294250</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20040101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.001384</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.086666</td>\n",
       "      <td>0.075865</td>\n",
       "      <td>-0.041251</td>\n",
       "      <td>2.869411</td>\n",
       "      <td>2.987582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305269</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20160701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.039288</td>\n",
       "      <td>1.126873</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.474508</td>\n",
       "      <td>0.588598</td>\n",
       "      <td>0.011668</td>\n",
       "      <td>-0.026326</td>\n",
       "      <td>0.620318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318536</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20101001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.901646</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.117046</td>\n",
       "      <td>0.127061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.822029</td>\n",
       "      <td>0.734784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349712</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>20140101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024559</td>\n",
       "      <td>0.762538</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.038098</td>\n",
       "      <td>-0.106315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.779787</td>\n",
       "      <td>1.721224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362774</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20000201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.038990</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.241872</td>\n",
       "      <td>0.183432</td>\n",
       "      <td>-0.009471</td>\n",
       "      <td>-0.517796</td>\n",
       "      <td>-0.764780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368113</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20110401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.040691</td>\n",
       "      <td>1.000966</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.165229</td>\n",
       "      <td>0.275146</td>\n",
       "      <td>-0.057469</td>\n",
       "      <td>0.695361</td>\n",
       "      <td>1.168062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390620</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20000701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.055856</td>\n",
       "      <td>1.001177</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174052</td>\n",
       "      <td>1.999996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.557659</td>\n",
       "      <td>2.774639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 852 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        남녀구분코드  연령  Segment  회원여부_이용가능  회원여부_이용가능_CA  회원여부_이용가능_카드론  소지여부_신용  \\\n",
       "33783        2   2        1          1             1              0        1   \n",
       "61321        2   3        1          1             1              0        1   \n",
       "61664        2   3        1          1             1              0        1   \n",
       "64700        2   1        1          1             1              0        1   \n",
       "103311       1   2        1          1             1              0        1   \n",
       "112900       1   0        1          1             1              0        1   \n",
       "149555       1   2        1          1             1              1        1   \n",
       "155671       2   3        1          1             1              1        1   \n",
       "158775       2   1        1          1             0              0        1   \n",
       "193847       1   3        1          1             1              1        1   \n",
       "194417       2   1        1          1             1              1        1   \n",
       "211122       1   3        1          1             1              1        1   \n",
       "213882       1   1        1          1             1              0        1   \n",
       "227355       1   2        1          1             1              1        1   \n",
       "235877       1   2        1          1             1              0        1   \n",
       "256790       1   1        1          1             1              0        1   \n",
       "289152       2   1        1          1             1              1        1   \n",
       "294250       1   2        1          1             1              0        1   \n",
       "305269       1   3        1          1             1              0        1   \n",
       "318536       2   3        1          1             1              1        1   \n",
       "349712       1   2        1          1             1              1        1   \n",
       "362774       2   1        1          1             1              0        1   \n",
       "368113       1   2        1          1             1              0        1   \n",
       "390620       2   3        1          1             1              0        1   \n",
       "\n",
       "        소지카드수_유효_신용  소지카드수_이용가능_신용   입회일자_신용  ...  변동률_RV일시불평잔  변동률_할부평잔  \\\n",
       "33783             1              1  19960601  ...     0.999998  1.045284   \n",
       "61321             3              3  19970401  ...     0.999998  1.046498   \n",
       "61664             3              3  20100201  ...     0.999998  1.058028   \n",
       "64700             1              1  20131201  ...     0.999998  1.049187   \n",
       "103311            1              1  20180601  ...     1.007577  1.045298   \n",
       "112900            1              1  20180601  ...     0.999998  1.530249   \n",
       "149555            3              3  20040601  ...     1.236102  1.047157   \n",
       "155671            2              2  20100401  ...     1.023803  1.056083   \n",
       "158775            1              1  20080801  ...     0.975048  1.046677   \n",
       "193847            1              1  19990101  ...     0.999998  0.583822   \n",
       "194417            2              2  20080801  ...     0.963853  1.047271   \n",
       "211122            3              3  20071001  ...     0.999998  1.045613   \n",
       "213882            1              1  20111001  ...     0.999998  1.054562   \n",
       "227355            2              2  20081201  ...     0.999998  1.048603   \n",
       "235877            2              2  20000701  ...     1.110543  1.040715   \n",
       "256790            1              1  20070401  ...     0.999998  0.900760   \n",
       "289152            2              2  20120101  ...     1.232824  0.578083   \n",
       "294250            3              3  20040101  ...     0.999998  0.999998   \n",
       "305269            1              1  20160701  ...     0.999998  1.039288   \n",
       "318536            3              3  20101001  ...     0.999998  0.901646   \n",
       "349712            3              2  20140101  ...     1.024559  0.762538   \n",
       "362774            1              1  20000201  ...     0.999998  1.038990   \n",
       "368113            2              2  20110401  ...     0.999998  1.040691   \n",
       "390620            1              1  20000701  ...     0.999998  1.055856   \n",
       "\n",
       "        변동률_CA평잔  변동률_RVCA평잔  변동률_카드론평잔  변동률_잔액_B1M  변동률_잔액_일시불_B1M  \\\n",
       "33783   0.999983    0.999998   0.999998    0.235003        0.292826   \n",
       "61321   1.003019    0.999998   0.999998   -0.079760       -0.010086   \n",
       "61664   1.001830    0.999998   0.999998    0.147794        0.202691   \n",
       "64700   0.999998    0.999998   0.999998   -0.063978       -0.036457   \n",
       "103311  1.002872    0.999998   0.928411   -0.209052       -0.124355   \n",
       "112900  0.844892    0.999998   0.999998    0.018677        0.095173   \n",
       "149555  0.999998    0.999998   0.999998    0.022665       -0.025760   \n",
       "155671  0.999998    0.999998   0.999998   -0.083730       -0.043347   \n",
       "158775  0.847286    0.999998   0.999998    0.241237        0.229954   \n",
       "193847  0.999998    0.999998   0.999998   -0.056105       -0.050879   \n",
       "194417  0.999998    0.999998   0.000000    0.155146        0.084236   \n",
       "211122  0.999998    0.999998   0.999998    0.144693        0.186482   \n",
       "213882  0.999998    0.999998   0.999998    0.081021        0.169762   \n",
       "227355  0.999998    0.999998   0.999998   -0.040512        0.073542   \n",
       "235877  1.990229    0.999998   0.928766   -0.032969        0.016533   \n",
       "256790  0.999998    0.999998   0.999998   -0.009657        0.051918   \n",
       "289152  0.999998    0.999998   0.999998    0.117470        0.115058   \n",
       "294250  1.001384    0.999998   0.999998   -0.086666        0.075865   \n",
       "305269  1.126873    0.999998   0.999998    0.474508        0.588598   \n",
       "318536  0.999998    0.999998   0.999998    0.117046        0.127061   \n",
       "349712  0.999998    0.999998   0.999998   -0.038098       -0.106315   \n",
       "362774  0.999861    0.999998   0.999998    0.241872        0.183432   \n",
       "368113  1.000966    0.999998   0.999998    0.165229        0.275146   \n",
       "390620  1.001177    0.999998   0.000000    0.174052        1.999996   \n",
       "\n",
       "        변동률_잔액_CA_B1M  혜택수혜율_R3M  혜택수혜율_B0M  \n",
       "33783        0.000000   0.250928   0.820717  \n",
       "61321        0.000000   0.321904   1.111626  \n",
       "61664       -0.046823  -0.330547   0.550934  \n",
       "64700        0.000000   1.908533   1.729495  \n",
       "103311      -0.032057   0.256611   0.947896  \n",
       "112900       0.000000   1.026059   1.445633  \n",
       "149555       0.000000   2.136402   1.245026  \n",
       "155671       0.000000   1.924277   1.227015  \n",
       "158775       0.000000   0.000000   0.000000  \n",
       "193847       0.000000   2.059205   1.433706  \n",
       "194417       0.000000   2.267857   1.531428  \n",
       "211122       0.000000   1.982185   1.453670  \n",
       "213882       0.000000   0.751975   0.730083  \n",
       "227355       0.000000   1.541468   1.225396  \n",
       "235877       0.000000   2.233293   1.309625  \n",
       "256790       0.000000   0.000000   0.000000  \n",
       "289152       0.000000   1.736184   1.733322  \n",
       "294250      -0.041251   2.869411   2.987582  \n",
       "305269       0.011668  -0.026326   0.620318  \n",
       "318536       0.000000   1.822029   0.734784  \n",
       "349712       0.000000   2.779787   1.721224  \n",
       "362774      -0.009471  -0.517796  -0.764780  \n",
       "368113      -0.057469   0.695361   1.168062  \n",
       "390620       0.000000   2.557659   2.774639  \n",
       "\n",
       "[24 rows x 852 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ee0093ca-ad36-4fbc-9c34-07ab527705b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24 entries, 33783 to 390620\n",
      "Columns: 852 entries, 남녀구분코드 to 혜택수혜율_B0M\n",
      "dtypes: float64(57), int32(49), int64(746)\n",
      "memory usage: 155.3 KB\n"
     ]
    }
   ],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f75b7c3d-0d5b-4266-a8cd-a95c82009e81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>최종유효년월_신용_이용가능</th>\n",
       "      <th>최종유효년월_신용_이용</th>\n",
       "      <th>최종카드발급일자</th>\n",
       "      <th>CA이자율_할인전</th>\n",
       "      <th>CL이자율_할인전</th>\n",
       "      <th>RV일시불이자율_할인전</th>\n",
       "      <th>RV현금서비스이자율_할인전</th>\n",
       "      <th>RV약정청구율</th>\n",
       "      <th>RV최소결제비율</th>\n",
       "      <th>최종카드론_대출이율</th>\n",
       "      <th>...</th>\n",
       "      <th>변동률_RV일시불평잔</th>\n",
       "      <th>변동률_할부평잔</th>\n",
       "      <th>변동률_CA평잔</th>\n",
       "      <th>변동률_RVCA평잔</th>\n",
       "      <th>변동률_카드론평잔</th>\n",
       "      <th>변동률_잔액_B1M</th>\n",
       "      <th>변동률_잔액_일시불_B1M</th>\n",
       "      <th>변동률_잔액_CA_B1M</th>\n",
       "      <th>혜택수혜율_R3M</th>\n",
       "      <th>혜택수혜율_B0M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33783</th>\n",
       "      <td>202105.0</td>\n",
       "      <td>202106.0</td>\n",
       "      <td>20160521.0</td>\n",
       "      <td>21.993507</td>\n",
       "      <td>17.711561</td>\n",
       "      <td>15.445377</td>\n",
       "      <td>21.217255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.99996</td>\n",
       "      <td>18.234396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.045284</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.235003</td>\n",
       "      <td>0.292826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250928</td>\n",
       "      <td>0.820717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61321</th>\n",
       "      <td>202306.0</td>\n",
       "      <td>202302.0</td>\n",
       "      <td>20180322.0</td>\n",
       "      <td>22.197464</td>\n",
       "      <td>18.305614</td>\n",
       "      <td>16.502746</td>\n",
       "      <td>21.105198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.99998</td>\n",
       "      <td>17.036080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.046498</td>\n",
       "      <td>1.003019</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.079760</td>\n",
       "      <td>-0.010086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321904</td>\n",
       "      <td>1.111626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61664</th>\n",
       "      <td>202208.0</td>\n",
       "      <td>202205.0</td>\n",
       "      <td>20170911.0</td>\n",
       "      <td>22.210160</td>\n",
       "      <td>17.909171</td>\n",
       "      <td>14.919473</td>\n",
       "      <td>21.340047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.99996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.058028</td>\n",
       "      <td>1.001830</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.147794</td>\n",
       "      <td>0.202691</td>\n",
       "      <td>-0.046823</td>\n",
       "      <td>-0.330547</td>\n",
       "      <td>0.550934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64700</th>\n",
       "      <td>202008.0</td>\n",
       "      <td>202008.0</td>\n",
       "      <td>20160607.0</td>\n",
       "      <td>14.662196</td>\n",
       "      <td>14.833134</td>\n",
       "      <td>10.249980</td>\n",
       "      <td>13.275189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.99998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.049187</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.063978</td>\n",
       "      <td>-0.036457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.908533</td>\n",
       "      <td>1.729495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103311</th>\n",
       "      <td>202201.0</td>\n",
       "      <td>202201.0</td>\n",
       "      <td>20170123.0</td>\n",
       "      <td>22.116691</td>\n",
       "      <td>17.854504</td>\n",
       "      <td>14.757641</td>\n",
       "      <td>21.201390</td>\n",
       "      <td>99.999800</td>\n",
       "      <td>14.99997</td>\n",
       "      <td>16.257827</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007577</td>\n",
       "      <td>1.045298</td>\n",
       "      <td>1.002872</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.928411</td>\n",
       "      <td>-0.209052</td>\n",
       "      <td>-0.124355</td>\n",
       "      <td>-0.032057</td>\n",
       "      <td>0.256611</td>\n",
       "      <td>0.947896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112900</th>\n",
       "      <td>202104.0</td>\n",
       "      <td>202106.0</td>\n",
       "      <td>20170128.0</td>\n",
       "      <td>22.322097</td>\n",
       "      <td>17.773053</td>\n",
       "      <td>13.693140</td>\n",
       "      <td>21.326557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.99997</td>\n",
       "      <td>15.374836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.530249</td>\n",
       "      <td>0.844892</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>0.095173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.026059</td>\n",
       "      <td>1.445633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149555</th>\n",
       "      <td>202309.0</td>\n",
       "      <td>202307.0</td>\n",
       "      <td>20180706.0</td>\n",
       "      <td>15.103184</td>\n",
       "      <td>14.860574</td>\n",
       "      <td>13.001901</td>\n",
       "      <td>14.172961</td>\n",
       "      <td>24.506596</td>\n",
       "      <td>9.99998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.236102</td>\n",
       "      <td>1.047157</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.022665</td>\n",
       "      <td>-0.025760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.136402</td>\n",
       "      <td>1.245026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155671</th>\n",
       "      <td>202006.0</td>\n",
       "      <td>202005.0</td>\n",
       "      <td>20150603.0</td>\n",
       "      <td>14.219972</td>\n",
       "      <td>10.898373</td>\n",
       "      <td>10.249980</td>\n",
       "      <td>13.113238</td>\n",
       "      <td>99.999800</td>\n",
       "      <td>9.99998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.023803</td>\n",
       "      <td>1.056083</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.083730</td>\n",
       "      <td>-0.043347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.924277</td>\n",
       "      <td>1.227015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158775</th>\n",
       "      <td>202012.0</td>\n",
       "      <td>202102.0</td>\n",
       "      <td>20151226.0</td>\n",
       "      <td>22.997127</td>\n",
       "      <td>18.132160</td>\n",
       "      <td>17.723674</td>\n",
       "      <td>21.270850</td>\n",
       "      <td>22.123906</td>\n",
       "      <td>14.99997</td>\n",
       "      <td>16.013697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975048</td>\n",
       "      <td>1.046677</td>\n",
       "      <td>0.847286</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.241237</td>\n",
       "      <td>0.229954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193847</th>\n",
       "      <td>202008.0</td>\n",
       "      <td>202008.0</td>\n",
       "      <td>20151119.0</td>\n",
       "      <td>14.662737</td>\n",
       "      <td>14.830060</td>\n",
       "      <td>10.593044</td>\n",
       "      <td>13.323960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.99998</td>\n",
       "      <td>16.286991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.583822</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.056105</td>\n",
       "      <td>-0.050879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.059205</td>\n",
       "      <td>1.433706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194417</th>\n",
       "      <td>202306.0</td>\n",
       "      <td>202302.0</td>\n",
       "      <td>20180728.0</td>\n",
       "      <td>16.933220</td>\n",
       "      <td>14.884741</td>\n",
       "      <td>12.141226</td>\n",
       "      <td>16.162401</td>\n",
       "      <td>99.999800</td>\n",
       "      <td>9.99998</td>\n",
       "      <td>11.954144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963853</td>\n",
       "      <td>1.047271</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155146</td>\n",
       "      <td>0.084236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.267857</td>\n",
       "      <td>1.531428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211122</th>\n",
       "      <td>202301.0</td>\n",
       "      <td>202208.0</td>\n",
       "      <td>20171214.0</td>\n",
       "      <td>14.669612</td>\n",
       "      <td>14.821747</td>\n",
       "      <td>10.249980</td>\n",
       "      <td>13.304815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.99998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.045613</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.144693</td>\n",
       "      <td>0.186482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.982185</td>\n",
       "      <td>1.453670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213882</th>\n",
       "      <td>202005.0</td>\n",
       "      <td>202004.0</td>\n",
       "      <td>20150822.0</td>\n",
       "      <td>19.970335</td>\n",
       "      <td>17.738246</td>\n",
       "      <td>14.276952</td>\n",
       "      <td>21.268635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.99998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.054562</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.081021</td>\n",
       "      <td>0.169762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751975</td>\n",
       "      <td>0.730083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227355</th>\n",
       "      <td>202109.0</td>\n",
       "      <td>202109.0</td>\n",
       "      <td>20161230.0</td>\n",
       "      <td>14.669893</td>\n",
       "      <td>14.830098</td>\n",
       "      <td>10.439660</td>\n",
       "      <td>13.306725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.99998</td>\n",
       "      <td>16.371284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.048603</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.040512</td>\n",
       "      <td>0.073542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.541468</td>\n",
       "      <td>1.225396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235877</th>\n",
       "      <td>202208.0</td>\n",
       "      <td>202208.0</td>\n",
       "      <td>20180113.0</td>\n",
       "      <td>21.880143</td>\n",
       "      <td>17.531852</td>\n",
       "      <td>13.951371</td>\n",
       "      <td>18.931944</td>\n",
       "      <td>99.999800</td>\n",
       "      <td>9.99998</td>\n",
       "      <td>12.800026</td>\n",
       "      <td>...</td>\n",
       "      <td>1.110543</td>\n",
       "      <td>1.040715</td>\n",
       "      <td>1.990229</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.928766</td>\n",
       "      <td>-0.032969</td>\n",
       "      <td>0.016533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.233293</td>\n",
       "      <td>1.309625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256790</th>\n",
       "      <td>202204.0</td>\n",
       "      <td>202205.0</td>\n",
       "      <td>20170715.0</td>\n",
       "      <td>14.860610</td>\n",
       "      <td>14.829577</td>\n",
       "      <td>11.191358</td>\n",
       "      <td>13.629972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.99998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.900760</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.009657</td>\n",
       "      <td>0.051918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289152</th>\n",
       "      <td>202210.0</td>\n",
       "      <td>202210.0</td>\n",
       "      <td>20180415.0</td>\n",
       "      <td>14.221068</td>\n",
       "      <td>10.897471</td>\n",
       "      <td>10.249980</td>\n",
       "      <td>13.100016</td>\n",
       "      <td>99.999800</td>\n",
       "      <td>9.99998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.232824</td>\n",
       "      <td>0.578083</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.117470</td>\n",
       "      <td>0.115058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.736184</td>\n",
       "      <td>1.733322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294250</th>\n",
       "      <td>202207.0</td>\n",
       "      <td>202206.0</td>\n",
       "      <td>20171203.0</td>\n",
       "      <td>22.059038</td>\n",
       "      <td>17.932423</td>\n",
       "      <td>14.226362</td>\n",
       "      <td>21.305650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.99997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.001384</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.086666</td>\n",
       "      <td>0.075865</td>\n",
       "      <td>-0.041251</td>\n",
       "      <td>2.869411</td>\n",
       "      <td>2.987582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305269</th>\n",
       "      <td>202105.0</td>\n",
       "      <td>202106.0</td>\n",
       "      <td>20160122.0</td>\n",
       "      <td>22.998682</td>\n",
       "      <td>18.054956</td>\n",
       "      <td>16.445327</td>\n",
       "      <td>21.205331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.99996</td>\n",
       "      <td>16.190678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.039288</td>\n",
       "      <td>1.126873</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.474508</td>\n",
       "      <td>0.588598</td>\n",
       "      <td>0.011668</td>\n",
       "      <td>-0.026326</td>\n",
       "      <td>0.620318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318536</th>\n",
       "      <td>202212.0</td>\n",
       "      <td>202210.0</td>\n",
       "      <td>20180205.0</td>\n",
       "      <td>14.219972</td>\n",
       "      <td>10.897607</td>\n",
       "      <td>10.249980</td>\n",
       "      <td>13.128592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.99998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.901646</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.117046</td>\n",
       "      <td>0.127061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.822029</td>\n",
       "      <td>0.734784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349712</th>\n",
       "      <td>201911.0</td>\n",
       "      <td>202002.0</td>\n",
       "      <td>20150308.0</td>\n",
       "      <td>14.664431</td>\n",
       "      <td>14.824555</td>\n",
       "      <td>10.539773</td>\n",
       "      <td>13.240579</td>\n",
       "      <td>99.999800</td>\n",
       "      <td>9.99998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024559</td>\n",
       "      <td>0.762538</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.038098</td>\n",
       "      <td>-0.106315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.779787</td>\n",
       "      <td>1.721224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362774</th>\n",
       "      <td>201910.0</td>\n",
       "      <td>202001.0</td>\n",
       "      <td>20140402.0</td>\n",
       "      <td>21.833985</td>\n",
       "      <td>17.194650</td>\n",
       "      <td>14.566384</td>\n",
       "      <td>18.995288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.99996</td>\n",
       "      <td>17.766352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.038990</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.241872</td>\n",
       "      <td>0.183432</td>\n",
       "      <td>-0.009471</td>\n",
       "      <td>-0.517796</td>\n",
       "      <td>-0.764780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368113</th>\n",
       "      <td>202302.0</td>\n",
       "      <td>202211.0</td>\n",
       "      <td>20171128.0</td>\n",
       "      <td>22.056443</td>\n",
       "      <td>17.853525</td>\n",
       "      <td>15.601459</td>\n",
       "      <td>21.250911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.99996</td>\n",
       "      <td>16.788867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.040691</td>\n",
       "      <td>1.000966</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.165229</td>\n",
       "      <td>0.275146</td>\n",
       "      <td>-0.057469</td>\n",
       "      <td>0.695361</td>\n",
       "      <td>1.168062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390620</th>\n",
       "      <td>202211.0</td>\n",
       "      <td>202210.0</td>\n",
       "      <td>20171114.0</td>\n",
       "      <td>21.851740</td>\n",
       "      <td>18.150342</td>\n",
       "      <td>15.116598</td>\n",
       "      <td>21.223555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.99996</td>\n",
       "      <td>17.441644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.055856</td>\n",
       "      <td>1.001177</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174052</td>\n",
       "      <td>1.999996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.557659</td>\n",
       "      <td>2.774639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        최종유효년월_신용_이용가능  최종유효년월_신용_이용    최종카드발급일자  CA이자율_할인전  CL이자율_할인전  \\\n",
       "33783         202105.0      202106.0  20160521.0  21.993507  17.711561   \n",
       "61321         202306.0      202302.0  20180322.0  22.197464  18.305614   \n",
       "61664         202208.0      202205.0  20170911.0  22.210160  17.909171   \n",
       "64700         202008.0      202008.0  20160607.0  14.662196  14.833134   \n",
       "103311        202201.0      202201.0  20170123.0  22.116691  17.854504   \n",
       "112900        202104.0      202106.0  20170128.0  22.322097  17.773053   \n",
       "149555        202309.0      202307.0  20180706.0  15.103184  14.860574   \n",
       "155671        202006.0      202005.0  20150603.0  14.219972  10.898373   \n",
       "158775        202012.0      202102.0  20151226.0  22.997127  18.132160   \n",
       "193847        202008.0      202008.0  20151119.0  14.662737  14.830060   \n",
       "194417        202306.0      202302.0  20180728.0  16.933220  14.884741   \n",
       "211122        202301.0      202208.0  20171214.0  14.669612  14.821747   \n",
       "213882        202005.0      202004.0  20150822.0  19.970335  17.738246   \n",
       "227355        202109.0      202109.0  20161230.0  14.669893  14.830098   \n",
       "235877        202208.0      202208.0  20180113.0  21.880143  17.531852   \n",
       "256790        202204.0      202205.0  20170715.0  14.860610  14.829577   \n",
       "289152        202210.0      202210.0  20180415.0  14.221068  10.897471   \n",
       "294250        202207.0      202206.0  20171203.0  22.059038  17.932423   \n",
       "305269        202105.0      202106.0  20160122.0  22.998682  18.054956   \n",
       "318536        202212.0      202210.0  20180205.0  14.219972  10.897607   \n",
       "349712        201911.0      202002.0  20150308.0  14.664431  14.824555   \n",
       "362774        201910.0      202001.0  20140402.0  21.833985  17.194650   \n",
       "368113        202302.0      202211.0  20171128.0  22.056443  17.853525   \n",
       "390620        202211.0      202210.0  20171114.0  21.851740  18.150342   \n",
       "\n",
       "        RV일시불이자율_할인전  RV현금서비스이자율_할인전    RV약정청구율  RV최소결제비율  최종카드론_대출이율  ...  \\\n",
       "33783      15.445377       21.217255   0.000000  19.99996   18.234396  ...   \n",
       "61321      16.502746       21.105198   0.000000   9.99998   17.036080  ...   \n",
       "61664      14.919473       21.340047   0.000000  19.99996    0.000000  ...   \n",
       "64700      10.249980       13.275189   0.000000   9.99998    0.000000  ...   \n",
       "103311     14.757641       21.201390  99.999800  14.99997   16.257827  ...   \n",
       "112900     13.693140       21.326557   0.000000  14.99997   15.374836  ...   \n",
       "149555     13.001901       14.172961  24.506596   9.99998    0.000000  ...   \n",
       "155671     10.249980       13.113238  99.999800   9.99998    0.000000  ...   \n",
       "158775     17.723674       21.270850  22.123906  14.99997   16.013697  ...   \n",
       "193847     10.593044       13.323960   0.000000   9.99998   16.286991  ...   \n",
       "194417     12.141226       16.162401  99.999800   9.99998   11.954144  ...   \n",
       "211122     10.249980       13.304815   0.000000   9.99998    0.000000  ...   \n",
       "213882     14.276952       21.268635   0.000000   9.99998    0.000000  ...   \n",
       "227355     10.439660       13.306725   0.000000   9.99998   16.371284  ...   \n",
       "235877     13.951371       18.931944  99.999800   9.99998   12.800026  ...   \n",
       "256790     11.191358       13.629972   0.000000   9.99998    0.000000  ...   \n",
       "289152     10.249980       13.100016  99.999800   9.99998    0.000000  ...   \n",
       "294250     14.226362       21.305650   0.000000  14.99997    0.000000  ...   \n",
       "305269     16.445327       21.205331   0.000000  19.99996   16.190678  ...   \n",
       "318536     10.249980       13.128592   0.000000   9.99998    0.000000  ...   \n",
       "349712     10.539773       13.240579  99.999800   9.99998    0.000000  ...   \n",
       "362774     14.566384       18.995288   0.000000  19.99996   17.766352  ...   \n",
       "368113     15.601459       21.250911   0.000000  19.99996   16.788867  ...   \n",
       "390620     15.116598       21.223555   0.000000  19.99996   17.441644  ...   \n",
       "\n",
       "        변동률_RV일시불평잔  변동률_할부평잔  변동률_CA평잔  변동률_RVCA평잔  변동률_카드론평잔  변동률_잔액_B1M  \\\n",
       "33783      0.999998  1.045284  0.999983    0.999998   0.999998    0.235003   \n",
       "61321      0.999998  1.046498  1.003019    0.999998   0.999998   -0.079760   \n",
       "61664      0.999998  1.058028  1.001830    0.999998   0.999998    0.147794   \n",
       "64700      0.999998  1.049187  0.999998    0.999998   0.999998   -0.063978   \n",
       "103311     1.007577  1.045298  1.002872    0.999998   0.928411   -0.209052   \n",
       "112900     0.999998  1.530249  0.844892    0.999998   0.999998    0.018677   \n",
       "149555     1.236102  1.047157  0.999998    0.999998   0.999998    0.022665   \n",
       "155671     1.023803  1.056083  0.999998    0.999998   0.999998   -0.083730   \n",
       "158775     0.975048  1.046677  0.847286    0.999998   0.999998    0.241237   \n",
       "193847     0.999998  0.583822  0.999998    0.999998   0.999998   -0.056105   \n",
       "194417     0.963853  1.047271  0.999998    0.999998   0.000000    0.155146   \n",
       "211122     0.999998  1.045613  0.999998    0.999998   0.999998    0.144693   \n",
       "213882     0.999998  1.054562  0.999998    0.999998   0.999998    0.081021   \n",
       "227355     0.999998  1.048603  0.999998    0.999998   0.999998   -0.040512   \n",
       "235877     1.110543  1.040715  1.990229    0.999998   0.928766   -0.032969   \n",
       "256790     0.999998  0.900760  0.999998    0.999998   0.999998   -0.009657   \n",
       "289152     1.232824  0.578083  0.999998    0.999998   0.999998    0.117470   \n",
       "294250     0.999998  0.999998  1.001384    0.999998   0.999998   -0.086666   \n",
       "305269     0.999998  1.039288  1.126873    0.999998   0.999998    0.474508   \n",
       "318536     0.999998  0.901646  0.999998    0.999998   0.999998    0.117046   \n",
       "349712     1.024559  0.762538  0.999998    0.999998   0.999998   -0.038098   \n",
       "362774     0.999998  1.038990  0.999861    0.999998   0.999998    0.241872   \n",
       "368113     0.999998  1.040691  1.000966    0.999998   0.999998    0.165229   \n",
       "390620     0.999998  1.055856  1.001177    0.999998   0.000000    0.174052   \n",
       "\n",
       "        변동률_잔액_일시불_B1M  변동률_잔액_CA_B1M  혜택수혜율_R3M  혜택수혜율_B0M  \n",
       "33783         0.292826       0.000000   0.250928   0.820717  \n",
       "61321        -0.010086       0.000000   0.321904   1.111626  \n",
       "61664         0.202691      -0.046823  -0.330547   0.550934  \n",
       "64700        -0.036457       0.000000   1.908533   1.729495  \n",
       "103311       -0.124355      -0.032057   0.256611   0.947896  \n",
       "112900        0.095173       0.000000   1.026059   1.445633  \n",
       "149555       -0.025760       0.000000   2.136402   1.245026  \n",
       "155671       -0.043347       0.000000   1.924277   1.227015  \n",
       "158775        0.229954       0.000000   0.000000   0.000000  \n",
       "193847       -0.050879       0.000000   2.059205   1.433706  \n",
       "194417        0.084236       0.000000   2.267857   1.531428  \n",
       "211122        0.186482       0.000000   1.982185   1.453670  \n",
       "213882        0.169762       0.000000   0.751975   0.730083  \n",
       "227355        0.073542       0.000000   1.541468   1.225396  \n",
       "235877        0.016533       0.000000   2.233293   1.309625  \n",
       "256790        0.051918       0.000000   0.000000   0.000000  \n",
       "289152        0.115058       0.000000   1.736184   1.733322  \n",
       "294250        0.075865      -0.041251   2.869411   2.987582  \n",
       "305269        0.588598       0.011668  -0.026326   0.620318  \n",
       "318536        0.127061       0.000000   1.822029   0.734784  \n",
       "349712       -0.106315       0.000000   2.779787   1.721224  \n",
       "362774        0.183432      -0.009471  -0.517796  -0.764780  \n",
       "368113        0.275146      -0.057469   0.695361   1.168062  \n",
       "390620        1.999996       0.000000   2.557659   2.774639  \n",
       "\n",
       "[24 rows x 57 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xfi=x.dtypes[x.dtypes==np.float64].index\n",
    "x[xfi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f8d4512c-1cff-4243-bd1d-40a7926e3e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-25682.154560636132 14646.954873292805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -5562.00077295],\n",
       "       [ 14240.93697561],\n",
       "       [  4828.96401891],\n",
       "       [ -5477.68776652],\n",
       "       [  4040.97252181],\n",
       "       [  4044.2643698 ],\n",
       "       [ 14624.9887521 ],\n",
       "       [-15480.92611084],\n",
       "       [-14857.2073492 ],\n",
       "       [-14964.97234554],\n",
       "       [ 14646.95487329],\n",
       "       [  5132.85434395],\n",
       "       [-15262.00808916],\n",
       "       [ -4852.99189023],\n",
       "       [ 14030.33931157],\n",
       "       [  4632.94145007],\n",
       "       [ 14332.35249451],\n",
       "       [  5120.9406018 ],\n",
       "       [ -5960.97048763],\n",
       "       [ 14122.33953736],\n",
       "       [-15776.83530671],\n",
       "       [-25682.15456064],\n",
       "       [  5046.89104428],\n",
       "       [  5032.01438438]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1,)\n",
    "g=pca.fit_transform(x[xfi])\n",
    "\n",
    "print(g.min(),g.max())\n",
    "g\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd21f5ae-6824-4925-b467-4f0cf1a7d2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "fb317ad4-cc15-48a5-a152-a479cfd76fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-20448, -10514,   6071, ...,  -7656, -19379,  -4060])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.randint(-25682, 14646,20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "76ef78f2-97e4-4cb0-a731-8a5f2f2ba5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 57)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.inverse_transform(np.random.randint(-25682, 14646,20000).reshape(-1,1)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb6ef4d-78c8-4d83-9f20-e50601bc9606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "y=data[\"Segment\"]\n",
    "x=data.drop([\"ID\"],axis=1)\n",
    "x=x.fillna(0)\n",
    "\n",
    "\n",
    "xp=[]\n",
    "xpp=[]\n",
    "for i in range(5):\n",
    "    xp.append(x[x[\"Segment\"]==i])\n",
    "    pca = PCA(n_components=40)\n",
    "    x = pd.DataFrame(columns=x.columns, pca.fit_transform(x))\n",
    "    xpp.appned(pca)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_rt,x_te,y_tr,y_te=train_test_split(x,y,test_size=0.5,shuffle=True,stratify =y)\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(n_estimators=100, learning_rate=0.05, max_depth=15, random_state = 312)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(x_rt, y_tr)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "\n",
    "y_pred = model.predict(x_te) # 예측 라벨(0과 1로 예측)\n",
    "\n",
    "# 예측 라벨과 실제 라벨 사이의 정확도 측정\n",
    "\n",
    "f1_score(y_pred, y_te,average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e528e8d8-4e28-4714-a618-ec54b0fad6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    " max \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64fb5aad-171b-4e01-bc7f-3a6346a39305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.회원정보 201807_train_회원정보.parquet\n",
      "2.신용정보 201807_train_신용정보.parquet\n",
      "3.승인매출정보 201807_train_승인매출정보.parquet\n",
      "4.청구입금정보 201807_train_청구정보.parquet\n",
      "5.잔액정보 201807_train_잔액정보.parquet\n",
      "6.채널정보 201807_train_채널정보.parquet\n",
      "7.마케팅정보 201807_train_마케팅정보.parquet\n",
      "8.성과정보 201807_train_성과정보.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "\n",
    "path1=os.listdir(\"ppp/open/train/\")\n",
    "data=1\n",
    "for j in path1:\n",
    "    \n",
    "    a=os.listdir(f\"ppp/open/train/{j}\")\n",
    "    p=[]\n",
    "    \n",
    "    for i in a[:1]:\n",
    "        p=pd.read_parquet(f\"ppp/open/train/{j}/{i}\").drop(\"기준년월\",axis=1)\n",
    "        data=pd.merge(data,p,on=\"ID\",how=\"inner\") if j!=\"1.회원정보\" else p\n",
    "        \n",
    "        print(j,i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2080af-3289-4fe0-8564-b45b638755a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "69 80 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719da8c6-9254-4b2b-9c3e-8fa0d4c25627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#data[\"Segment\"]=data[\"Segment\"].apply(lambda x: 1 if x==\"B\" else 0)\n",
    "for i in data.columns:\n",
    "    le = LabelEncoder()\n",
    "    if data[i].dtype=='O':\n",
    "        data[i]=le.fit_transform(data[i])\n",
    "#x=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d98184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "y=data[\"Segment\"]\n",
    "x=data.drop([\"ID\",\"Segment\"],axis=1)\n",
    "\n",
    "#x=x.fillna(method=\"mean\",axis=1)\n",
    "for i in x.columns:\n",
    "    if x[i].isnull().sum():\n",
    "        x[i]=x[i].fillna(x[i].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3abb266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=100)\n",
    "x = pd.DataFrame(pca.fit_transform(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "0b3d98cb-b83f-4b53-aebd-52ac1a324117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.394974e+07</td>\n",
       "      <td>1.874335e+07</td>\n",
       "      <td>-4.059311e+06</td>\n",
       "      <td>-5.955014e+05</td>\n",
       "      <td>-5.688609e+05</td>\n",
       "      <td>-147024.840190</td>\n",
       "      <td>-150169.662263</td>\n",
       "      <td>218142.810412</td>\n",
       "      <td>-144158.695226</td>\n",
       "      <td>-206729.250366</td>\n",
       "      <td>...</td>\n",
       "      <td>-8479.040183</td>\n",
       "      <td>-16804.918520</td>\n",
       "      <td>-60573.150810</td>\n",
       "      <td>37954.386426</td>\n",
       "      <td>-43704.216849</td>\n",
       "      <td>-9625.182500</td>\n",
       "      <td>37860.745791</td>\n",
       "      <td>14197.851795</td>\n",
       "      <td>-7357.588052</td>\n",
       "      <td>-5757.534984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.796668e+07</td>\n",
       "      <td>2.258872e+07</td>\n",
       "      <td>-4.842997e+06</td>\n",
       "      <td>-2.490068e+06</td>\n",
       "      <td>3.569791e+05</td>\n",
       "      <td>-253058.726831</td>\n",
       "      <td>-96337.077197</td>\n",
       "      <td>-95407.009347</td>\n",
       "      <td>330742.759318</td>\n",
       "      <td>-45461.166229</td>\n",
       "      <td>...</td>\n",
       "      <td>-7209.873186</td>\n",
       "      <td>-1165.745223</td>\n",
       "      <td>-9667.585155</td>\n",
       "      <td>34051.993619</td>\n",
       "      <td>-14811.010098</td>\n",
       "      <td>1364.519718</td>\n",
       "      <td>-1025.650756</td>\n",
       "      <td>-3387.414175</td>\n",
       "      <td>-11580.242452</td>\n",
       "      <td>15837.269412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.930788e+07</td>\n",
       "      <td>-1.421066e+07</td>\n",
       "      <td>9.441162e+06</td>\n",
       "      <td>-1.053052e+07</td>\n",
       "      <td>1.598723e+06</td>\n",
       "      <td>-106383.217957</td>\n",
       "      <td>-260729.922974</td>\n",
       "      <td>64331.855061</td>\n",
       "      <td>81508.922822</td>\n",
       "      <td>-153092.032678</td>\n",
       "      <td>...</td>\n",
       "      <td>2018.694528</td>\n",
       "      <td>-7320.277721</td>\n",
       "      <td>1972.245737</td>\n",
       "      <td>-747.956289</td>\n",
       "      <td>6970.913883</td>\n",
       "      <td>20904.183490</td>\n",
       "      <td>5571.672674</td>\n",
       "      <td>4563.341867</td>\n",
       "      <td>3089.320804</td>\n",
       "      <td>790.607996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.916890e+07</td>\n",
       "      <td>-2.278206e+06</td>\n",
       "      <td>-4.213210e+06</td>\n",
       "      <td>1.139375e+07</td>\n",
       "      <td>6.399745e+05</td>\n",
       "      <td>-285799.640375</td>\n",
       "      <td>67511.684080</td>\n",
       "      <td>-185020.202925</td>\n",
       "      <td>69516.152071</td>\n",
       "      <td>-21932.646082</td>\n",
       "      <td>...</td>\n",
       "      <td>13831.202516</td>\n",
       "      <td>-18851.205196</td>\n",
       "      <td>-3887.746492</td>\n",
       "      <td>-13004.683034</td>\n",
       "      <td>1149.033873</td>\n",
       "      <td>18556.095709</td>\n",
       "      <td>8796.892876</td>\n",
       "      <td>-17125.273209</td>\n",
       "      <td>9687.421323</td>\n",
       "      <td>10111.902523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.916907e+07</td>\n",
       "      <td>-2.258699e+06</td>\n",
       "      <td>-4.201850e+06</td>\n",
       "      <td>1.142531e+07</td>\n",
       "      <td>6.362235e+05</td>\n",
       "      <td>-259382.084412</td>\n",
       "      <td>72209.440414</td>\n",
       "      <td>62578.516298</td>\n",
       "      <td>-89807.398027</td>\n",
       "      <td>-125443.633254</td>\n",
       "      <td>...</td>\n",
       "      <td>26556.150827</td>\n",
       "      <td>-3083.319849</td>\n",
       "      <td>3002.132225</td>\n",
       "      <td>8288.922470</td>\n",
       "      <td>13248.845325</td>\n",
       "      <td>-8312.918041</td>\n",
       "      <td>10449.294960</td>\n",
       "      <td>-2840.888651</td>\n",
       "      <td>-23445.932519</td>\n",
       "      <td>2347.963622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-8.380118e+07</td>\n",
       "      <td>1.633214e+07</td>\n",
       "      <td>1.521683e+07</td>\n",
       "      <td>-5.816362e+06</td>\n",
       "      <td>-1.276695e+06</td>\n",
       "      <td>-224593.955757</td>\n",
       "      <td>-414187.168431</td>\n",
       "      <td>-6725.818406</td>\n",
       "      <td>-17176.463406</td>\n",
       "      <td>124774.385113</td>\n",
       "      <td>...</td>\n",
       "      <td>29495.661918</td>\n",
       "      <td>17035.682615</td>\n",
       "      <td>-4735.403442</td>\n",
       "      <td>21506.554888</td>\n",
       "      <td>-2715.852851</td>\n",
       "      <td>-24576.106494</td>\n",
       "      <td>1248.128895</td>\n",
       "      <td>9333.708859</td>\n",
       "      <td>17469.616830</td>\n",
       "      <td>-1608.643612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.930753e+07</td>\n",
       "      <td>-1.421044e+07</td>\n",
       "      <td>9.421396e+06</td>\n",
       "      <td>-1.052428e+07</td>\n",
       "      <td>1.599715e+06</td>\n",
       "      <td>-125780.125678</td>\n",
       "      <td>-60828.275802</td>\n",
       "      <td>150495.372402</td>\n",
       "      <td>15248.266227</td>\n",
       "      <td>33473.307969</td>\n",
       "      <td>...</td>\n",
       "      <td>-3018.855250</td>\n",
       "      <td>10815.045797</td>\n",
       "      <td>-9284.036600</td>\n",
       "      <td>5952.813548</td>\n",
       "      <td>-4092.167855</td>\n",
       "      <td>-17935.330152</td>\n",
       "      <td>9360.489531</td>\n",
       "      <td>2754.730561</td>\n",
       "      <td>-7260.244041</td>\n",
       "      <td>8992.298584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.915856e+07</td>\n",
       "      <td>-1.178644e+07</td>\n",
       "      <td>-9.865190e+06</td>\n",
       "      <td>-5.306427e+06</td>\n",
       "      <td>2.304277e+06</td>\n",
       "      <td>-48104.404330</td>\n",
       "      <td>160267.583045</td>\n",
       "      <td>22562.896169</td>\n",
       "      <td>-113433.990776</td>\n",
       "      <td>121980.975285</td>\n",
       "      <td>...</td>\n",
       "      <td>10005.185710</td>\n",
       "      <td>13759.145212</td>\n",
       "      <td>17999.066332</td>\n",
       "      <td>10414.737131</td>\n",
       "      <td>-9415.718462</td>\n",
       "      <td>6548.224609</td>\n",
       "      <td>-9177.624384</td>\n",
       "      <td>-4205.006890</td>\n",
       "      <td>2893.332876</td>\n",
       "      <td>-9396.963553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-8.258571e+07</td>\n",
       "      <td>-8.555930e+06</td>\n",
       "      <td>1.589186e+07</td>\n",
       "      <td>8.085808e+06</td>\n",
       "      <td>-9.952620e+05</td>\n",
       "      <td>-311781.747171</td>\n",
       "      <td>76633.540138</td>\n",
       "      <td>53003.160468</td>\n",
       "      <td>152.400039</td>\n",
       "      <td>33530.864302</td>\n",
       "      <td>...</td>\n",
       "      <td>5485.636492</td>\n",
       "      <td>33969.587934</td>\n",
       "      <td>-13755.774962</td>\n",
       "      <td>-3055.714935</td>\n",
       "      <td>-14490.898123</td>\n",
       "      <td>-3242.934552</td>\n",
       "      <td>-3748.349657</td>\n",
       "      <td>2215.036653</td>\n",
       "      <td>-3512.580724</td>\n",
       "      <td>13199.358223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.915850e+07</td>\n",
       "      <td>-1.178485e+07</td>\n",
       "      <td>-9.865082e+06</td>\n",
       "      <td>-5.305768e+06</td>\n",
       "      <td>2.305039e+06</td>\n",
       "      <td>-48329.099542</td>\n",
       "      <td>-3673.624521</td>\n",
       "      <td>-129353.577007</td>\n",
       "      <td>27398.078544</td>\n",
       "      <td>17485.029449</td>\n",
       "      <td>...</td>\n",
       "      <td>-2291.939900</td>\n",
       "      <td>-994.606451</td>\n",
       "      <td>-5201.269742</td>\n",
       "      <td>-12554.016308</td>\n",
       "      <td>12493.266018</td>\n",
       "      <td>-6620.612710</td>\n",
       "      <td>8165.692772</td>\n",
       "      <td>6476.736391</td>\n",
       "      <td>-20066.910641</td>\n",
       "      <td>-13536.282311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0             1             2             3             4   \\\n",
       "0   -8.394974e+07  1.874335e+07 -4.059311e+06 -5.955014e+05 -5.688609e+05   \n",
       "1    1.796668e+07  2.258872e+07 -4.842997e+06 -2.490068e+06  3.569791e+05   \n",
       "2    1.930788e+07 -1.421066e+07  9.441162e+06 -1.053052e+07  1.598723e+06   \n",
       "3    1.916890e+07 -2.278206e+06 -4.213210e+06  1.139375e+07  6.399745e+05   \n",
       "4    1.916907e+07 -2.258699e+06 -4.201850e+06  1.142531e+07  6.362235e+05   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "157 -8.380118e+07  1.633214e+07  1.521683e+07 -5.816362e+06 -1.276695e+06   \n",
       "158  1.930753e+07 -1.421044e+07  9.421396e+06 -1.052428e+07  1.599715e+06   \n",
       "159  1.915856e+07 -1.178644e+07 -9.865190e+06 -5.306427e+06  2.304277e+06   \n",
       "160 -8.258571e+07 -8.555930e+06  1.589186e+07  8.085808e+06 -9.952620e+05   \n",
       "161  1.915850e+07 -1.178485e+07 -9.865082e+06 -5.305768e+06  2.305039e+06   \n",
       "\n",
       "                5              6              7              8   \\\n",
       "0   -147024.840190 -150169.662263  218142.810412 -144158.695226   \n",
       "1   -253058.726831  -96337.077197  -95407.009347  330742.759318   \n",
       "2   -106383.217957 -260729.922974   64331.855061   81508.922822   \n",
       "3   -285799.640375   67511.684080 -185020.202925   69516.152071   \n",
       "4   -259382.084412   72209.440414   62578.516298  -89807.398027   \n",
       "..             ...            ...            ...            ...   \n",
       "157 -224593.955757 -414187.168431   -6725.818406  -17176.463406   \n",
       "158 -125780.125678  -60828.275802  150495.372402   15248.266227   \n",
       "159  -48104.404330  160267.583045   22562.896169 -113433.990776   \n",
       "160 -311781.747171   76633.540138   53003.160468     152.400039   \n",
       "161  -48329.099542   -3673.624521 -129353.577007   27398.078544   \n",
       "\n",
       "                9   ...            30            31            32  \\\n",
       "0   -206729.250366  ...  -8479.040183 -16804.918520 -60573.150810   \n",
       "1    -45461.166229  ...  -7209.873186  -1165.745223  -9667.585155   \n",
       "2   -153092.032678  ...   2018.694528  -7320.277721   1972.245737   \n",
       "3    -21932.646082  ...  13831.202516 -18851.205196  -3887.746492   \n",
       "4   -125443.633254  ...  26556.150827  -3083.319849   3002.132225   \n",
       "..             ...  ...           ...           ...           ...   \n",
       "157  124774.385113  ...  29495.661918  17035.682615  -4735.403442   \n",
       "158   33473.307969  ...  -3018.855250  10815.045797  -9284.036600   \n",
       "159  121980.975285  ...  10005.185710  13759.145212  17999.066332   \n",
       "160   33530.864302  ...   5485.636492  33969.587934 -13755.774962   \n",
       "161   17485.029449  ...  -2291.939900   -994.606451  -5201.269742   \n",
       "\n",
       "               33            34            35            36            37  \\\n",
       "0    37954.386426 -43704.216849  -9625.182500  37860.745791  14197.851795   \n",
       "1    34051.993619 -14811.010098   1364.519718  -1025.650756  -3387.414175   \n",
       "2     -747.956289   6970.913883  20904.183490   5571.672674   4563.341867   \n",
       "3   -13004.683034   1149.033873  18556.095709   8796.892876 -17125.273209   \n",
       "4     8288.922470  13248.845325  -8312.918041  10449.294960  -2840.888651   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "157  21506.554888  -2715.852851 -24576.106494   1248.128895   9333.708859   \n",
       "158   5952.813548  -4092.167855 -17935.330152   9360.489531   2754.730561   \n",
       "159  10414.737131  -9415.718462   6548.224609  -9177.624384  -4205.006890   \n",
       "160  -3055.714935 -14490.898123  -3242.934552  -3748.349657   2215.036653   \n",
       "161 -12554.016308  12493.266018  -6620.612710   8165.692772   6476.736391   \n",
       "\n",
       "               38            39  \n",
       "0    -7357.588052  -5757.534984  \n",
       "1   -11580.242452  15837.269412  \n",
       "2     3089.320804    790.607996  \n",
       "3     9687.421323  10111.902523  \n",
       "4   -23445.932519   2347.963622  \n",
       "..            ...           ...  \n",
       "157  17469.616830  -1608.643612  \n",
       "158  -7260.244041   8992.298584  \n",
       "159   2893.332876  -9396.963553  \n",
       "160  -3512.580724  13199.358223  \n",
       "161 -20066.910641 -13536.282311  \n",
       "\n",
       "[162 rows x 40 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aaad0c3-e827-4762-a46e-570caf114e18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "x=x.fillna(0)\n",
    "xp=[]\n",
    "xp1=[]\n",
    "xpp=[]\n",
    "ttt=[]\n",
    "yr=[]\n",
    "for i in range(5):\n",
    "    xk=x[x[\"Segment\"]==i]\n",
    "    xk=xk.drop([\"ID\",\"Segment\"],axis=1)\n",
    "    xp.append(xk)\n",
    "    \n",
    "    pca = PCA(n_components=24)\n",
    "    x1 = pd.DataFrame(data=pca.fit_transform(xk))\n",
    "    xp1.append(x1)\n",
    "    mi=(np.array(x1.min())+1).reshape(1,-1)\n",
    "    ma=(np.array(x1.max())-1).reshape(1,-1)\n",
    "    tt=np.random.random((100000,24))*(ma-mi)+mi\n",
    "    ttt.append(pd.DataFrame(tt))\n",
    "    yr.append([i]*100000)\n",
    "    xpp.append(pca)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb1e680a-68d8-4db9-9d87-36c057ec7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy=pd.concat(ttt)\n",
    "tr=xy\n",
    "#yr\n",
    "ye=x[\"Segment\"]\n",
    "te=pd.concat(xp1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3527fac4-e19d-41e8-a658-1c64858bd761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.054435414711439534"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(n_estimators=300, learning_rate=0.001, max_depth=20, random_state = 312)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(tr, yr)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "\n",
    "y_pred = model.predict(te) # 예측 라벨(0과 1로 예측)\n",
    "\n",
    "# 예측 라벨과 실제 라벨 사이의 정확도 측정\n",
    "\n",
    "f1_score(y_pred, ye,average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9f4d94e-d136-479d-b933-f1db25e117f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    84,     11,  10781,  29482, 163691],\n",
       "       [     3,      0,    302,    859,   4642],\n",
       "       [    58,      8,   7992,  22062, 119902],\n",
       "       [     0,      0,      2,      8,     76],\n",
       "       [    17,      5,   2188,   5796,  32031]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred, ye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e068530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1782512214913558"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_rt,x_te,y_tr,y_te=train_test_split(te,ye,test_size=0.5,shuffle=True,stratify =ye)\n",
    "model.fit(x_rt, y_tr)\n",
    "y_pred = model.predict(x_te) # 예측 라벨(0과 1로 예측)\n",
    "\n",
    "# 예측 라벨과 실제 라벨 사이의 정확도 측정\n",
    "\n",
    "f1_score(y_pred, y_te,average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7fcb152-168c-4a16-9b84-5a3557fc9496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      0,      0,      0,      0],\n",
       "       [     0,      0,      0,      0,      0],\n",
       "       [     0,      0,      0,      0,      2],\n",
       "       [     0,      0,      7,     34,    186],\n",
       "       [    81,     12,  10626,  29069, 159983]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54749396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc0f0c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "y=data[\"Segment\"]\n",
    "x=data.drop([\"ID\"],axis=1)\n",
    "\n",
    "#x=x.fillna(method=\"mean\",axis=1)\n",
    "for i in x.columns:\n",
    "    if x[i].isnull().sum():\n",
    "        x[i]=x[i].fillna(x[i].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac37293",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>남녀구분코드</th>\n",
       "      <th>연령</th>\n",
       "      <th>회원여부_이용가능</th>\n",
       "      <th>회원여부_이용가능_CA</th>\n",
       "      <th>회원여부_이용가능_카드론</th>\n",
       "      <th>소지여부_신용</th>\n",
       "      <th>소지카드수_유효_신용</th>\n",
       "      <th>소지카드수_이용가능_신용</th>\n",
       "      <th>입회일자_신용</th>\n",
       "      <th>입회경과개월수_신용</th>\n",
       "      <th>...</th>\n",
       "      <th>변동률_RV일시불평잔</th>\n",
       "      <th>변동률_할부평잔</th>\n",
       "      <th>변동률_CA평잔</th>\n",
       "      <th>변동률_RVCA평잔</th>\n",
       "      <th>변동률_카드론평잔</th>\n",
       "      <th>변동률_잔액_B1M</th>\n",
       "      <th>변동률_잔액_일시불_B1M</th>\n",
       "      <th>변동률_잔액_CA_B1M</th>\n",
       "      <th>혜택수혜율_R3M</th>\n",
       "      <th>혜택수혜율_B0M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33783</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19960601</td>\n",
       "      <td>266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.045284</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.235003</td>\n",
       "      <td>0.292826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250928</td>\n",
       "      <td>0.820717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61321</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>19970401</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.046498</td>\n",
       "      <td>1.003019</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.079760</td>\n",
       "      <td>-0.010086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321904</td>\n",
       "      <td>1.111626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61664</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20100201</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.058028</td>\n",
       "      <td>1.001830</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.147794</td>\n",
       "      <td>0.202691</td>\n",
       "      <td>-0.046823</td>\n",
       "      <td>-0.330547</td>\n",
       "      <td>0.550934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64700</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20131201</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.049187</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.063978</td>\n",
       "      <td>-0.036457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.908533</td>\n",
       "      <td>1.729495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103311</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20180601</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007577</td>\n",
       "      <td>1.045298</td>\n",
       "      <td>1.002872</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.928411</td>\n",
       "      <td>-0.209052</td>\n",
       "      <td>-0.124355</td>\n",
       "      <td>-0.032057</td>\n",
       "      <td>0.256611</td>\n",
       "      <td>0.947896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112900</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20180601</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.530249</td>\n",
       "      <td>0.844892</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>0.095173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.026059</td>\n",
       "      <td>1.445633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149555</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20040601</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>1.236102</td>\n",
       "      <td>1.047157</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.022665</td>\n",
       "      <td>-0.025760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.136402</td>\n",
       "      <td>1.245026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155671</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20100401</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>1.023803</td>\n",
       "      <td>1.056083</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.083730</td>\n",
       "      <td>-0.043347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.924277</td>\n",
       "      <td>1.227015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158775</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20080801</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975048</td>\n",
       "      <td>1.046677</td>\n",
       "      <td>0.847286</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.241237</td>\n",
       "      <td>0.229954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193847</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19990101</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.583822</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.056105</td>\n",
       "      <td>-0.050879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.059205</td>\n",
       "      <td>1.433706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194417</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20080801</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963853</td>\n",
       "      <td>1.047271</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155146</td>\n",
       "      <td>0.084236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.267857</td>\n",
       "      <td>1.531428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211122</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20071001</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.045613</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.144693</td>\n",
       "      <td>0.186482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.982185</td>\n",
       "      <td>1.453670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213882</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20111001</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.054562</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.081021</td>\n",
       "      <td>0.169762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751975</td>\n",
       "      <td>0.730083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227355</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20081201</td>\n",
       "      <td>116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.048603</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.040512</td>\n",
       "      <td>0.073542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.541468</td>\n",
       "      <td>1.225396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235877</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20000701</td>\n",
       "      <td>217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.110543</td>\n",
       "      <td>1.040715</td>\n",
       "      <td>1.990229</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.928766</td>\n",
       "      <td>-0.032969</td>\n",
       "      <td>0.016533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.233293</td>\n",
       "      <td>1.309625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256790</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20070401</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.900760</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.009657</td>\n",
       "      <td>0.051918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289152</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20120101</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>1.232824</td>\n",
       "      <td>0.578083</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.117470</td>\n",
       "      <td>0.115058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.736184</td>\n",
       "      <td>1.733322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294250</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20040101</td>\n",
       "      <td>175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.001384</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.086666</td>\n",
       "      <td>0.075865</td>\n",
       "      <td>-0.041251</td>\n",
       "      <td>2.869411</td>\n",
       "      <td>2.987582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305269</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20160701</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.039288</td>\n",
       "      <td>1.126873</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.474508</td>\n",
       "      <td>0.588598</td>\n",
       "      <td>0.011668</td>\n",
       "      <td>-0.026326</td>\n",
       "      <td>0.620318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318536</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20101001</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.901646</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.117046</td>\n",
       "      <td>0.127061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.822029</td>\n",
       "      <td>0.734784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349712</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>20140101</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024559</td>\n",
       "      <td>0.762538</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.038098</td>\n",
       "      <td>-0.106315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.779787</td>\n",
       "      <td>1.721224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362774</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20000201</td>\n",
       "      <td>222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.038990</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.241872</td>\n",
       "      <td>0.183432</td>\n",
       "      <td>-0.009471</td>\n",
       "      <td>-0.517796</td>\n",
       "      <td>-0.764780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368113</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20110401</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.040691</td>\n",
       "      <td>1.000966</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.165229</td>\n",
       "      <td>0.275146</td>\n",
       "      <td>-0.057469</td>\n",
       "      <td>0.695361</td>\n",
       "      <td>1.168062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390620</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20000701</td>\n",
       "      <td>217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.055856</td>\n",
       "      <td>1.001177</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174052</td>\n",
       "      <td>1.999996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.557659</td>\n",
       "      <td>2.774639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 855 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        남녀구분코드  연령  회원여부_이용가능  회원여부_이용가능_CA  회원여부_이용가능_카드론  소지여부_신용  \\\n",
       "33783        2   2          1             1              0        1   \n",
       "61321        2   3          1             1              0        1   \n",
       "61664        2   3          1             1              0        1   \n",
       "64700        2   1          1             1              0        1   \n",
       "103311       1   2          1             1              0        1   \n",
       "112900       1   0          1             1              0        1   \n",
       "149555       1   2          1             1              1        1   \n",
       "155671       2   3          1             1              1        1   \n",
       "158775       2   1          1             0              0        1   \n",
       "193847       1   3          1             1              1        1   \n",
       "194417       2   1          1             1              1        1   \n",
       "211122       1   3          1             1              1        1   \n",
       "213882       1   1          1             1              0        1   \n",
       "227355       1   2          1             1              1        1   \n",
       "235877       1   2          1             1              0        1   \n",
       "256790       1   1          1             1              0        1   \n",
       "289152       2   1          1             1              1        1   \n",
       "294250       1   2          1             1              0        1   \n",
       "305269       1   3          1             1              0        1   \n",
       "318536       2   3          1             1              1        1   \n",
       "349712       1   2          1             1              1        1   \n",
       "362774       2   1          1             1              0        1   \n",
       "368113       1   2          1             1              0        1   \n",
       "390620       2   3          1             1              0        1   \n",
       "\n",
       "        소지카드수_유효_신용  소지카드수_이용가능_신용   입회일자_신용  입회경과개월수_신용  ...  변동률_RV일시불평잔  \\\n",
       "33783             1              1  19960601         266  ...     0.999998   \n",
       "61321             3              3  19970401         256  ...     0.999998   \n",
       "61664             3              3  20100201         102  ...     0.999998   \n",
       "64700             1              1  20131201          56  ...     0.999998   \n",
       "103311            1              1  20180601           2  ...     1.007577   \n",
       "112900            1              1  20180601           2  ...     0.999998   \n",
       "149555            3              3  20040601         170  ...     1.236102   \n",
       "155671            2              2  20100401         100  ...     1.023803   \n",
       "158775            1              1  20080801         120  ...     0.975048   \n",
       "193847            1              1  19990101         235  ...     0.999998   \n",
       "194417            2              2  20080801         120  ...     0.963853   \n",
       "211122            3              3  20071001         130  ...     0.999998   \n",
       "213882            1              1  20111001          82  ...     0.999998   \n",
       "227355            2              2  20081201         116  ...     0.999998   \n",
       "235877            2              2  20000701         217  ...     1.110543   \n",
       "256790            1              1  20070401         136  ...     0.999998   \n",
       "289152            2              2  20120101          79  ...     1.232824   \n",
       "294250            3              3  20040101         175  ...     0.999998   \n",
       "305269            1              1  20160701          25  ...     0.999998   \n",
       "318536            3              3  20101001          94  ...     0.999998   \n",
       "349712            3              2  20140101          55  ...     1.024559   \n",
       "362774            1              1  20000201         222  ...     0.999998   \n",
       "368113            2              2  20110401          88  ...     0.999998   \n",
       "390620            1              1  20000701         217  ...     0.999998   \n",
       "\n",
       "        변동률_할부평잔  변동률_CA평잔  변동률_RVCA평잔  변동률_카드론평잔  변동률_잔액_B1M  변동률_잔액_일시불_B1M  \\\n",
       "33783   1.045284  0.999983    0.999998   0.999998    0.235003        0.292826   \n",
       "61321   1.046498  1.003019    0.999998   0.999998   -0.079760       -0.010086   \n",
       "61664   1.058028  1.001830    0.999998   0.999998    0.147794        0.202691   \n",
       "64700   1.049187  0.999998    0.999998   0.999998   -0.063978       -0.036457   \n",
       "103311  1.045298  1.002872    0.999998   0.928411   -0.209052       -0.124355   \n",
       "112900  1.530249  0.844892    0.999998   0.999998    0.018677        0.095173   \n",
       "149555  1.047157  0.999998    0.999998   0.999998    0.022665       -0.025760   \n",
       "155671  1.056083  0.999998    0.999998   0.999998   -0.083730       -0.043347   \n",
       "158775  1.046677  0.847286    0.999998   0.999998    0.241237        0.229954   \n",
       "193847  0.583822  0.999998    0.999998   0.999998   -0.056105       -0.050879   \n",
       "194417  1.047271  0.999998    0.999998   0.000000    0.155146        0.084236   \n",
       "211122  1.045613  0.999998    0.999998   0.999998    0.144693        0.186482   \n",
       "213882  1.054562  0.999998    0.999998   0.999998    0.081021        0.169762   \n",
       "227355  1.048603  0.999998    0.999998   0.999998   -0.040512        0.073542   \n",
       "235877  1.040715  1.990229    0.999998   0.928766   -0.032969        0.016533   \n",
       "256790  0.900760  0.999998    0.999998   0.999998   -0.009657        0.051918   \n",
       "289152  0.578083  0.999998    0.999998   0.999998    0.117470        0.115058   \n",
       "294250  0.999998  1.001384    0.999998   0.999998   -0.086666        0.075865   \n",
       "305269  1.039288  1.126873    0.999998   0.999998    0.474508        0.588598   \n",
       "318536  0.901646  0.999998    0.999998   0.999998    0.117046        0.127061   \n",
       "349712  0.762538  0.999998    0.999998   0.999998   -0.038098       -0.106315   \n",
       "362774  1.038990  0.999861    0.999998   0.999998    0.241872        0.183432   \n",
       "368113  1.040691  1.000966    0.999998   0.999998    0.165229        0.275146   \n",
       "390620  1.055856  1.001177    0.999998   0.000000    0.174052        1.999996   \n",
       "\n",
       "        변동률_잔액_CA_B1M  혜택수혜율_R3M  혜택수혜율_B0M  \n",
       "33783        0.000000   0.250928   0.820717  \n",
       "61321        0.000000   0.321904   1.111626  \n",
       "61664       -0.046823  -0.330547   0.550934  \n",
       "64700        0.000000   1.908533   1.729495  \n",
       "103311      -0.032057   0.256611   0.947896  \n",
       "112900       0.000000   1.026059   1.445633  \n",
       "149555       0.000000   2.136402   1.245026  \n",
       "155671       0.000000   1.924277   1.227015  \n",
       "158775       0.000000   0.000000   0.000000  \n",
       "193847       0.000000   2.059205   1.433706  \n",
       "194417       0.000000   2.267857   1.531428  \n",
       "211122       0.000000   1.982185   1.453670  \n",
       "213882       0.000000   0.751975   0.730083  \n",
       "227355       0.000000   1.541468   1.225396  \n",
       "235877       0.000000   2.233293   1.309625  \n",
       "256790       0.000000   0.000000   0.000000  \n",
       "289152       0.000000   1.736184   1.733322  \n",
       "294250      -0.041251   2.869411   2.987582  \n",
       "305269       0.011668  -0.026326   0.620318  \n",
       "318536       0.000000   1.822029   0.734784  \n",
       "349712       0.000000   2.779787   1.721224  \n",
       "362774      -0.009471  -0.517796  -0.764780  \n",
       "368113      -0.057469   0.695361   1.168062  \n",
       "390620       0.000000   2.557659   2.774639  \n",
       "\n",
       "[24 rows x 855 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=x[x[\"Segment\"]==1].drop([\"Segment\"],axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef753004",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4676/712908582.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f22d9eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>남녀구분코드</th>\n",
       "      <th>연령</th>\n",
       "      <th>회원여부_이용가능</th>\n",
       "      <th>회원여부_이용가능_CA</th>\n",
       "      <th>회원여부_이용가능_카드론</th>\n",
       "      <th>소지여부_신용</th>\n",
       "      <th>소지카드수_유효_신용</th>\n",
       "      <th>소지카드수_이용가능_신용</th>\n",
       "      <th>입회일자_신용</th>\n",
       "      <th>입회경과개월수_신용</th>\n",
       "      <th>...</th>\n",
       "      <th>변동률_RV일시불평잔</th>\n",
       "      <th>변동률_할부평잔</th>\n",
       "      <th>변동률_CA평잔</th>\n",
       "      <th>변동률_RVCA평잔</th>\n",
       "      <th>변동률_카드론평잔</th>\n",
       "      <th>변동률_잔액_B1M</th>\n",
       "      <th>변동률_잔액_일시불_B1M</th>\n",
       "      <th>변동률_잔액_CA_B1M</th>\n",
       "      <th>혜택수혜율_R3M</th>\n",
       "      <th>혜택수혜율_B0M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33783</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.490671</td>\n",
       "      <td>0.135411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649620</td>\n",
       "      <td>0.196380</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.226949</td>\n",
       "      <td>0.422533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61321</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.044545</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.491947</td>\n",
       "      <td>0.138062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.189144</td>\n",
       "      <td>0.053790</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.247903</td>\n",
       "      <td>0.500060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61664</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.634545</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.504056</td>\n",
       "      <td>0.137024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522040</td>\n",
       "      <td>0.153951</td>\n",
       "      <td>0.153990</td>\n",
       "      <td>0.055281</td>\n",
       "      <td>0.350636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64700</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.775455</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.494771</td>\n",
       "      <td>0.135424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.212232</td>\n",
       "      <td>0.041376</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.716322</td>\n",
       "      <td>0.664721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103311</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160602</td>\n",
       "      <td>0.490686</td>\n",
       "      <td>0.137933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.928413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.367552</td>\n",
       "      <td>0.228627</td>\n",
       "      <td>0.456426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112900</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333151</td>\n",
       "      <td>0.103339</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.455790</td>\n",
       "      <td>0.589072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149555</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.492639</td>\n",
       "      <td>0.135424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.338986</td>\n",
       "      <td>0.046411</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.783595</td>\n",
       "      <td>0.535611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155671</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.635455</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220201</td>\n",
       "      <td>0.502013</td>\n",
       "      <td>0.135424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.183337</td>\n",
       "      <td>0.038133</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.720970</td>\n",
       "      <td>0.530811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158775</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.546364</td>\n",
       "      <td>0.446970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041121</td>\n",
       "      <td>0.492135</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658740</td>\n",
       "      <td>0.166785</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.152868</td>\n",
       "      <td>0.203813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193847</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134091</td>\n",
       "      <td>0.882576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.135424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223751</td>\n",
       "      <td>0.034587</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.760804</td>\n",
       "      <td>0.585894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194417</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.546364</td>\n",
       "      <td>0.446970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.492758</td>\n",
       "      <td>0.135424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.532795</td>\n",
       "      <td>0.098190</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.822404</td>\n",
       "      <td>0.611937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211122</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.501818</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.491017</td>\n",
       "      <td>0.135424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517504</td>\n",
       "      <td>0.146321</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.738066</td>\n",
       "      <td>0.591214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213882</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683636</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.500416</td>\n",
       "      <td>0.135424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.424356</td>\n",
       "      <td>0.138450</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.374873</td>\n",
       "      <td>0.398379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227355</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.548182</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.494158</td>\n",
       "      <td>0.135424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.246562</td>\n",
       "      <td>0.093156</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.607953</td>\n",
       "      <td>0.530380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235877</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.182273</td>\n",
       "      <td>0.814394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538809</td>\n",
       "      <td>0.485874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.928768</td>\n",
       "      <td>0.257596</td>\n",
       "      <td>0.066320</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.812200</td>\n",
       "      <td>0.552827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256790</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499091</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.338887</td>\n",
       "      <td>0.135424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.291700</td>\n",
       "      <td>0.082977</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.152868</td>\n",
       "      <td>0.203813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289152</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.477679</td>\n",
       "      <td>0.112699</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.665439</td>\n",
       "      <td>0.665741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294250</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.361364</td>\n",
       "      <td>0.655303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.443111</td>\n",
       "      <td>0.136634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179041</td>\n",
       "      <td>0.094250</td>\n",
       "      <td>0.234584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305269</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909545</td>\n",
       "      <td>0.087121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.484374</td>\n",
       "      <td>0.246199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.335610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.145096</td>\n",
       "      <td>0.369127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318536</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.638182</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.339817</td>\n",
       "      <td>0.135424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.477058</td>\n",
       "      <td>0.118350</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.690783</td>\n",
       "      <td>0.399632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349712</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.815909</td>\n",
       "      <td>0.200758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222977</td>\n",
       "      <td>0.193721</td>\n",
       "      <td>0.135424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250093</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.973540</td>\n",
       "      <td>0.662517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362774</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.484061</td>\n",
       "      <td>0.135304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659670</td>\n",
       "      <td>0.144885</td>\n",
       "      <td>0.694247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.680909</td>\n",
       "      <td>0.325758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.485848</td>\n",
       "      <td>0.136269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.547546</td>\n",
       "      <td>0.188058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.358159</td>\n",
       "      <td>0.515100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390620</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182273</td>\n",
       "      <td>0.814394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.501775</td>\n",
       "      <td>0.136453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560453</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.831229</td>\n",
       "      <td>0.907962</td>\n",
       "      <td>0.943251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 855 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        남녀구분코드        연령  회원여부_이용가능  회원여부_이용가능_CA  회원여부_이용가능_카드론  소지여부_신용  \\\n",
       "33783      1.0  0.666667        0.0           1.0            0.0      0.0   \n",
       "61321      1.0  1.000000        0.0           1.0            0.0      0.0   \n",
       "61664      1.0  1.000000        0.0           1.0            0.0      0.0   \n",
       "64700      1.0  0.333333        0.0           1.0            0.0      0.0   \n",
       "103311     0.0  0.666667        0.0           1.0            0.0      0.0   \n",
       "112900     0.0  0.000000        0.0           1.0            0.0      0.0   \n",
       "149555     0.0  0.666667        0.0           1.0            1.0      0.0   \n",
       "155671     1.0  1.000000        0.0           1.0            1.0      0.0   \n",
       "158775     1.0  0.333333        0.0           0.0            0.0      0.0   \n",
       "193847     0.0  1.000000        0.0           1.0            1.0      0.0   \n",
       "194417     1.0  0.333333        0.0           1.0            1.0      0.0   \n",
       "211122     0.0  1.000000        0.0           1.0            1.0      0.0   \n",
       "213882     0.0  0.333333        0.0           1.0            0.0      0.0   \n",
       "227355     0.0  0.666667        0.0           1.0            1.0      0.0   \n",
       "235877     0.0  0.666667        0.0           1.0            0.0      0.0   \n",
       "256790     0.0  0.333333        0.0           1.0            0.0      0.0   \n",
       "289152     1.0  0.333333        0.0           1.0            1.0      0.0   \n",
       "294250     0.0  0.666667        0.0           1.0            0.0      0.0   \n",
       "305269     0.0  1.000000        0.0           1.0            0.0      0.0   \n",
       "318536     1.0  1.000000        0.0           1.0            1.0      0.0   \n",
       "349712     0.0  0.666667        0.0           1.0            1.0      0.0   \n",
       "362774     1.0  0.333333        0.0           1.0            0.0      0.0   \n",
       "368113     0.0  0.666667        0.0           1.0            0.0      0.0   \n",
       "390620     1.0  1.000000        0.0           1.0            0.0      0.0   \n",
       "\n",
       "        소지카드수_유효_신용  소지카드수_이용가능_신용   입회일자_신용  입회경과개월수_신용  ...  변동률_RV일시불평잔  \\\n",
       "33783           0.0            0.0  0.000000    1.000000  ...     0.132763   \n",
       "61321           1.0            1.0  0.044545    0.962121  ...     0.132763   \n",
       "61664           1.0            1.0  0.634545    0.378788  ...     0.132763   \n",
       "64700           0.0            0.0  0.775455    0.204545  ...     0.132763   \n",
       "103311          0.0            0.0  1.000000    0.000000  ...     0.160602   \n",
       "112900          0.0            0.0  1.000000    0.000000  ...     0.132763   \n",
       "149555          1.0            1.0  0.363636    0.636364  ...     1.000000   \n",
       "155671          0.5            0.5  0.635455    0.371212  ...     0.220201   \n",
       "158775          0.0            0.0  0.546364    0.446970  ...     0.041121   \n",
       "193847          0.0            0.0  0.134091    0.882576  ...     0.132763   \n",
       "194417          0.5            0.5  0.546364    0.446970  ...     0.000000   \n",
       "211122          1.0            1.0  0.501818    0.484848  ...     0.132763   \n",
       "213882          0.0            0.0  0.683636    0.303030  ...     0.132763   \n",
       "227355          0.5            0.5  0.548182    0.431818  ...     0.132763   \n",
       "235877          0.5            0.5  0.182273    0.814394  ...     0.538809   \n",
       "256790          0.0            0.0  0.499091    0.507576  ...     0.132763   \n",
       "289152          0.5            0.5  0.725000    0.291667  ...     0.987959   \n",
       "294250          1.0            1.0  0.361364    0.655303  ...     0.132763   \n",
       "305269          0.0            0.0  0.909545    0.087121  ...     0.132763   \n",
       "318536          1.0            1.0  0.638182    0.348485  ...     0.132763   \n",
       "349712          1.0            0.5  0.815909    0.200758  ...     0.222977   \n",
       "362774          0.0            0.0  0.180000    0.833333  ...     0.132763   \n",
       "368113          0.5            0.5  0.680909    0.325758  ...     0.132763   \n",
       "390620          0.0            0.0  0.182273    0.814394  ...     0.132763   \n",
       "\n",
       "        변동률_할부평잔  변동률_CA평잔  변동률_RVCA평잔  변동률_카드론평잔  변동률_잔액_B1M  변동률_잔액_일시불_B1M  \\\n",
       "33783   0.490671  0.135411         0.0   1.000000    0.649620        0.196380   \n",
       "61321   0.491947  0.138062         0.0   1.000000    0.189144        0.053790   \n",
       "61664   0.504056  0.137024         0.0   1.000000    0.522040        0.153951   \n",
       "64700   0.494771  0.135424         0.0   1.000000    0.212232        0.041376   \n",
       "103311  0.490686  0.137933         0.0   0.928413    0.000000        0.000000   \n",
       "112900  1.000000  0.000000         0.0   1.000000    0.333151        0.103339   \n",
       "149555  0.492639  0.135424         0.0   1.000000    0.338986        0.046411   \n",
       "155671  0.502013  0.135424         0.0   1.000000    0.183337        0.038133   \n",
       "158775  0.492135  0.002090         0.0   1.000000    0.658740        0.166785   \n",
       "193847  0.006027  0.135424         0.0   1.000000    0.223751        0.034587   \n",
       "194417  0.492758  0.135424         0.0   0.000000    0.532795        0.098190   \n",
       "211122  0.491017  0.135424         0.0   1.000000    0.517504        0.146321   \n",
       "213882  0.500416  0.135424         0.0   1.000000    0.424356        0.138450   \n",
       "227355  0.494158  0.135424         0.0   1.000000    0.246562        0.093156   \n",
       "235877  0.485874  1.000000         0.0   0.928768    0.257596        0.066320   \n",
       "256790  0.338887  0.135424         0.0   1.000000    0.291700        0.082977   \n",
       "289152  0.000000  0.135424         0.0   1.000000    0.477679        0.112699   \n",
       "294250  0.443111  0.136634         0.0   1.000000    0.179041        0.094250   \n",
       "305269  0.484374  0.246199         0.0   1.000000    1.000000        0.335610   \n",
       "318536  0.339817  0.135424         0.0   1.000000    0.477058        0.118350   \n",
       "349712  0.193721  0.135424         0.0   1.000000    0.250093        0.008492   \n",
       "362774  0.484061  0.135304         0.0   1.000000    0.659670        0.144885   \n",
       "368113  0.485848  0.136269         0.0   1.000000    0.547546        0.188058   \n",
       "390620  0.501775  0.136453         0.0   0.000000    0.560453        1.000000   \n",
       "\n",
       "        변동률_잔액_CA_B1M  혜택수혜율_R3M  혜택수혜율_B0M  \n",
       "33783        0.831229   0.226949   0.422533  \n",
       "61321        0.831229   0.247903   0.500060  \n",
       "61664        0.153990   0.055281   0.350636  \n",
       "64700        0.831229   0.716322   0.664721  \n",
       "103311       0.367552   0.228627   0.456426  \n",
       "112900       0.831229   0.455790   0.589072  \n",
       "149555       0.831229   0.783595   0.535611  \n",
       "155671       0.831229   0.720970   0.530811  \n",
       "158775       0.831229   0.152868   0.203813  \n",
       "193847       0.831229   0.760804   0.585894  \n",
       "194417       0.831229   0.822404   0.611937  \n",
       "211122       0.831229   0.738066   0.591214  \n",
       "213882       0.831229   0.374873   0.398379  \n",
       "227355       0.831229   0.607953   0.530380  \n",
       "235877       0.831229   0.812200   0.552827  \n",
       "256790       0.831229   0.152868   0.203813  \n",
       "289152       0.831229   0.665439   0.665741  \n",
       "294250       0.234584   1.000000   1.000000  \n",
       "305269       1.000000   0.145096   0.369127  \n",
       "318536       0.831229   0.690783   0.399632  \n",
       "349712       0.831229   0.973540   0.662517  \n",
       "362774       0.694247   0.000000   0.000000  \n",
       "368113       0.000000   0.358159   0.515100  \n",
       "390620       0.831229   0.907962   0.943251  \n",
       "\n",
       "[24 rows x 855 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi=x.min()\n",
    "ma=x.max()\n",
    "x=((x-mi)/(ma-mi))\n",
    "x=x.fillna(0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ae59015",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "input_size = 855\n",
    "hidden_size = 128\n",
    "code_size = 32   # latent vector의 차원\n",
    " \n",
    "# Encoder 부분 생성\n",
    "input_img = Input(shape=(input_size, ))\n",
    "hidden_1 = Dense(hidden_size, activation='relu')(input_img)\n",
    "code = Dense(code_size, activation='relu')(hidden_1)\n",
    " \n",
    "# Decoder 부분 생성\n",
    "hidden_2 = Dense(hidden_size, activation='relu')(code)\n",
    "output_img = Dense(input_size, activation='sigmoid')(hidden_2)\n",
    " \n",
    "\n",
    "autoencoder = Model(input_img, output_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9633395c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.2003\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1989\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1972\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1942\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1897\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1836\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1759\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1667\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1560\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1442\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1320\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1202\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1094\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1005\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0938\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0889\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0855\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0830\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0809\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0790\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0772\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0754\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0739\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0726\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0714\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0704\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0695\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0686\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0676\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24ec797f5b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(x, x, epochs=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc6a756e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4982339 , 0.6643183 , 0.02479012, ..., 0.73571336, 0.3425213 ,\n",
       "        0.48942363],\n",
       "       [0.5525243 , 0.6656275 , 0.01109128, ..., 0.7612119 , 0.33604044,\n",
       "        0.47536582],\n",
       "       [0.5109942 , 0.6558119 , 0.01120562, ..., 0.7359405 , 0.35719064,\n",
       "        0.4841024 ],\n",
       "       ...,\n",
       "       [0.5173558 , 0.61690813, 0.0066683 , ..., 0.7297238 , 0.42231822,\n",
       "        0.47685596],\n",
       "       [0.50784636, 0.66849625, 0.00714045, ..., 0.75945926, 0.36186427,\n",
       "        0.4963211 ],\n",
       "       [0.5405464 , 0.6753198 , 0.01434262, ..., 0.7536541 , 0.33452123,\n",
       "        0.47530675]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b89abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.회원정보 201807_train_회원정보.parquet\n",
      "2.신용정보 201807_train_신용정보.parquet\n",
      "3.승인매출정보 201807_train_승인매출정보.parquet\n",
      "4.청구입금정보 201807_train_청구정보.parquet\n",
      "5.잔액정보 201807_train_잔액정보.parquet\n",
      "6.채널정보 201807_train_채널정보.parquet\n",
      "7.마케팅정보 201807_train_마케팅정보.parquet\n",
      "8.성과정보 201807_train_성과정보.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "\n",
    "path1=os.listdir(\"ppp/open/train/\")\n",
    "data=1\n",
    "for j in path1:\n",
    "    \n",
    "    a=os.listdir(f\"ppp/open/train/{j}\")\n",
    "    p=[]\n",
    "    \n",
    "    for i in a[:1]:\n",
    "        p=pd.read_parquet(f\"ppp/open/train/{j}/{i}\").drop(\"기준년월\",axis=1)\n",
    "        data=pd.merge(data,p,on=\"ID\",how=\"inner\") if j!=\"1.회원정보\" else p\n",
    "        \n",
    "        print(j,i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86475461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#data[\"Segment\"]=data[\"Segment\"].apply(lambda x: 1 if x==\"B\" else 0)\n",
    "for i in data.columns:\n",
    "    le = LabelEncoder()\n",
    "    if data[i].dtype=='O':\n",
    "        data[i]=le.fit_transform(data[i])\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "y=data[\"Segment\"]\n",
    "x=data.drop([\"ID\",\"Segment\"],axis=1)\n",
    "\n",
    "#x=x.fillna(method=\"mean\",axis=1)\n",
    "for i in x.columns:\n",
    "    if x[i].isnull().sum():\n",
    "        x[i]=x[i].fillna(x[i].mean())\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=400)\n",
    "x = pd.DataFrame(pca.fit_transform(x))\n",
    "mi=x.min()\n",
    "ma=x.max()\n",
    "x=((x-mi)/(ma-mi))\n",
    "x=x.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660dae6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mi=x.min()\n",
    "ma=x.max()\n",
    "x=((x-mi)/(ma-mi))\n",
    "x=x.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408d6123",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__version' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14688/1497267557.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m__version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name '__version' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e1da272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:  # gpu가 있다면, 용량 한도를 5GB로 설정\n",
    "  tf.config.experimental.set_virtual_device_configuration(gpus[0], \n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5*1024)])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bed4653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0844\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0455\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0398\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0347\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0328\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0307\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0296\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0285\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0275\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0262\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0254\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0247\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0234\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0224\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0220\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0208\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0201\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0194\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0181\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0173\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0165\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0159\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0150\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0142\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0136\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0131\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0125\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0121\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0124\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0114\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0107\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0099\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0093\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0087\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0083\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0078\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0072\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0068\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0067\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0066\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0065\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0065\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0060\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0055\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0052\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0049\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0044\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0043\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0045\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0044\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0042\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0039\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0037\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0036\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0034\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0033\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0033\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0032\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0025\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0024\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0023\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0022\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0022\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0022\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0020\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0020\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0020\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0020\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0019\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0019\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0021\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0020\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0019\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0019\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0020\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0019\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0018\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0017\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0017\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0017\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0017\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0017\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0017\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0015\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0013\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Original data shape: (162, 855)\n",
      "Augmented data shape: (25, 855)\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1785\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1105\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0677\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0630\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0591\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0561\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0525\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0505\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0483\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0465\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0441\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0419\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0400\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0386\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0373\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0363\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0356\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0349\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0341\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0333\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0321\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0306\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0294\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0281\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0268\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0256\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0244\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0230\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0215\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0204\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0197\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0186\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0177\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0162\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0156\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0147\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0139\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0132\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0120\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0114\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0107\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0100\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0090\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0084\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0077\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0072\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0066\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0063\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0059\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0051\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0048\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0048\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0047\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0048\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0046\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0041\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0035\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0034\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0031\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0026\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0024\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0022\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0021\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0019\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0017\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0014\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0013\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0012\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0010\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.7727e-04\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.5181e-04\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.9053e-04\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.5356e-04\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.2217e-04\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 7.9150e-04\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.4803e-04\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.3281e-04\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.0522e-04\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.0311e-04\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.7378e-04\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.6273e-04\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.5282e-04\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.6192e-04\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.4613e-04\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.3683e-04\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.5153e-04\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.5694e-04\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.5800e-04\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.6844e-04\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.7467e-04\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.6661e-04\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.9955e-04\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7.0138e-04\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.8669e-04\n",
      "Original data shape: (24, 855)\n",
      "Augmented data shape: (25, 855)\n",
      "Epoch 1/100\n",
      "2659/2659 [==============================] - 15s 6ms/step - loss: 0.0205\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/2659 [================>.............] - ETA: 6s - loss: 0.0146"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7896/6672620.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# 모델 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m# 데이터 증강 함수\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 데이터셋 예시 (24개 샘플, 855개 특성)\n",
    "\n",
    "pae=[]\n",
    "pyy=[]\n",
    "for i in range(5):\n",
    "    \n",
    "    xxx=x.iloc[y[y==i].index]\n",
    "    \n",
    "    #xxx\n",
    "\n",
    "    data = xxx.values  # 실제 데이터로 교체\n",
    "\n",
    "    # 오토인코더 모델 정의\n",
    "    def build_autoencoder(input_dim):\n",
    "        # 인코더\n",
    "        input_layer = layers.Input(shape=(input_dim,))\n",
    "        encoded = layers.Dense(512, activation='relu')(input_layer)\n",
    "        encoded = layers.Dense(256, activation='relu')(encoded)\n",
    "        encoded = layers.Dense(128, activation='relu')(encoded)\n",
    "\n",
    "        # 디코더\n",
    "        decoded = layers.Dense(256, activation='relu')(encoded)\n",
    "        decoded = layers.Dense(512, activation='relu')(decoded)\n",
    "        decoded = layers.Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "        # 모델 생성\n",
    "        autoencoder = models.Model(input_layer, decoded)\n",
    "        autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        return autoencoder\n",
    "\n",
    "    # 오토인코더 모델 생성\n",
    "    input_dim = data.shape[1]\n",
    "    autoencoder = build_autoencoder(input_dim)\n",
    "\n",
    "    # 모델 학습\n",
    "    autoencoder.fit(data, data, epochs=100, batch_size=8, shuffle=True)\n",
    "\n",
    "    # 데이터 증강 함수\n",
    "    def augment_data(autoencoder, data, n_samples):\n",
    "        augmented_data = []\n",
    "\n",
    "        for _ in range(n_samples):\n",
    "            \n",
    "            aa=np.random.randint(data.shape[0])\n",
    "\n",
    "            augmented_data.append(autoencoder.predict(data[aa].reshape(1, -1),verbose=0).flatten())\n",
    "\n",
    "        return np.array(augmented_data)\n",
    "\n",
    "    # 10000개 이상의 데이터를 증강\n",
    "    augmented_data = augment_data(autoencoder, data, 25)\n",
    "    pae.append(augmented_data)\n",
    "    pyy.append([i]*25)\n",
    "    # 결과 확인\n",
    "    print(f\"Original data shape: {data.shape}\")\n",
    "    print(f\"Augmented data shape: {augmented_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(n_estimators=300, learning_rate=0.001, max_depth=20, random_state = 312)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(tr, pyy)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "\n",
    "y_pred = model.predict(x) # 예측 라벨(0과 1로 예측)\n",
    "\n",
    "# 예측 라벨과 실제 라벨 사이의 정확도 측정\n",
    "\n",
    "f1_score(y_pred, y,average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d91830e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "673d6374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1063\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0649\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0361\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0216\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0155\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0132\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0092\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0066\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0062\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0043\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0032\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0023\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0021\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0017\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0021\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0016\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.5923e-04\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0010\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 9.7752e-04\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.3382e-04\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6.7826e-04\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5.1273e-04\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6.0028e-04\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4.0981e-04\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3.3170e-04\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2.1269e-04\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.8699e-04\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 2.0419e-04\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2.2828e-04\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 5.5282e-04\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7.0735e-04\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5.9258e-04\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 3.9210e-04\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 4.0434e-04\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 3.9549e-04\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 2.5134e-04\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.5063e-04\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.5993e-04\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.4520e-04\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.3921e-04\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.5782e-04\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2.0651e-04\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2.3988e-04\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.7005e-04\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.2946e-04\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.3173e-04\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.3386e-04\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.2330e-04\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0134e-04\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.3801e-05\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.0412e-05\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.6096e-05\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.2352e-05\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.9650e-05\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.2827e-05\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.2272e-05\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7.2397e-05\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7.1019e-05\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.2826e-05\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 9.1112e-05\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.6848e-05\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.5960e-05\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.1258e-05\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.9087e-05\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.3630e-05\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.9940e-05\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5.7551e-05\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5.8156e-05\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.0494e-05\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6.1200e-05\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5.6895e-05\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5.8752e-05\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.9069e-05\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5.6460e-05\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.4135e-05\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5.5193e-05\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.6242e-05\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.6605e-05\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 7.0391e-05\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.1583e-05\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7.6398e-05\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.9901e-05\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.9487e-05\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.3597e-04\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 9.4782e-05\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.5444e-05\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8.5305e-05\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.6608e-05\n",
      "6/6 [==============================] - 0s 964us/step\n",
      "3125/3125 [==============================] - 3s 902us/step\n",
      "(100000, 5)\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1097\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1034\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0909\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0757\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0682\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0576\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0438\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0326\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0265\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0237\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0231\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0208\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0185\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0164\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0151\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0141\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0137\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0128\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0123\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0122\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0118\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0113\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0110\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0097\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0089\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0078\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0059\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0045\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0029\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0022\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0020\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0017\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0013\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.1593e-04\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.4163e-04\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.7230e-04\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.8040e-04\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.0155e-04\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.4464e-04\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4.7555e-04\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.8855e-04\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.8505e-04\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.5470e-04\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.7784e-04\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.6620e-04\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.1354e-04\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 4.1068e-04\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.8824e-04\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.3317e-04\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.1582e-04\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.7575e-04\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.5172e-04\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.3625e-04\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.4241e-04\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.1731e-04\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0518e-04\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.0142e-04\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.9484e-04\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.9585e-04\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.8708e-04\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.8262e-04\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7240e-04\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6694e-04\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.9026e-04\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.8430e-04\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.7531e-04\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.7402e-04\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.6626e-04\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6312e-04\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5580e-04\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5590e-04\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5046e-04\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.5209e-04\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.3982e-04\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4324e-04\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3669e-04\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3924e-04\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3673e-04\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3594e-04\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.3613e-04\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3045e-04\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3919e-04\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3329e-04\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2852e-04\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2475e-04\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2510e-04\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2664e-04\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2262e-04\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3340e-04\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4408e-04\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.2133e-04\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.3912e-04\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5002e-04\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3516e-04\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.7990e-04\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.9513e-04\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7494e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.4142e-04\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "3125/3125 [==============================] - 5s 1ms/step\n",
      "(100000, 5)\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 2s 6ms/step - loss: 0.0064\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 2s 6ms/step - loss: 5.7644e-05\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 3.5524e-05\n",
      "665/665 [==============================] - 1s 1ms/step\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "(100000, 5)\n",
      "Epoch 1/3\n",
      "455/455 [==============================] - 3s 6ms/step - loss: 0.0058\n",
      "Epoch 2/3\n",
      "455/455 [==============================] - 3s 6ms/step - loss: 1.4161e-04\n",
      "Epoch 3/3\n",
      "455/455 [==============================] - 3s 6ms/step - loss: 3.4259e-05\n",
      "1819/1819 [==============================] - 3s 2ms/step\n",
      "3125/3125 [==============================] - 5s 1ms/step\n",
      "(100000, 5)\n",
      "Epoch 1/3\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0092\n",
      "Epoch 2/3\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 8.7684e-05\n",
      "Epoch 3/3\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 3.5545e-05\n",
      "10011/10011 [==============================] - 14s 1ms/step\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "(100000, 5)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "# 오토인코더 모델 정의\n",
    "def build_autoencoder(input_dim):\n",
    "    input_layer = layers.Input(shape=(input_dim,))\n",
    "    \n",
    "    # 인코더\n",
    "    encoded = layers.Dense(512, activation='relu')(input_layer)\n",
    "    encoded = layers.Dense(128, activation='relu')(encoded)\n",
    "    encoded = layers.Dense(64, activation='relu')(encoded)\n",
    "    latent_space = layers.Dense(64, activation='relu')(encoded)  # 잠재 공간 벡터\n",
    "    \n",
    "    # 디코더\n",
    "    decoded = layers.Dense(64, activation='relu')(latent_space)\n",
    "    decoded = layers.Dense(128, activation='relu')(decoded)\n",
    "    decoded = layers.Dense(512, activation='relu')(decoded)\n",
    "    output_layer = layers.Dense(input_dim, activation='sigmoid')(decoded)  # 원본 차원으로 복원\n",
    "    \n",
    "    autoencoder = models.Model(input_layer, output_layer)\n",
    "    encoder = models.Model(input_layer, latent_space)  # 인코더 부분만 별도 모델로\n",
    "    \n",
    "    autoencoder.compile(optimizer='adam', loss='mse')  # 손실 함수는 평균 제곱 오차(MSE)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "xaep=[]\n",
    "yaep=[]\n",
    "# 모델 빌드\n",
    "for i in range(5):\n",
    "    \n",
    "    xxx=x.iloc[y[y==i].index]#[:10000]\n",
    "    ep=[100,100,3,3,3][i]\n",
    "    bh=[20,8,64,128,1024][i]\n",
    "    nn=100000\n",
    "    #ep=[100,100,100,100,100][i]\n",
    "    #bh=[8,8,8,8,8][i]\n",
    "    #ep=10\n",
    "    input_dim = xxx.shape[1]  # 데이터의 열 수\n",
    "    autoencoder, encoder = build_autoencoder(input_dim)\n",
    "\n",
    "\n",
    "    # 예시로 랜덤 데이터를 생성 (실제 데이터로 교체해야 함)\n",
    "    \n",
    "    \n",
    "\n",
    "    X_train = xxx.values  \n",
    "\n",
    "    # 오토인코더 학습\n",
    "    autoencoder.fit(X_train, X_train, epochs=ep, batch_size=bh)\n",
    "    # 잠재 공간에서 샘플링\n",
    "    latent_vectors = encoder.predict(X_train)\n",
    "\n",
    "    # Latent 벡터에 약간의 노이즈를 추가하여 새로운 샘플 생성\n",
    "    def generate_new_samples(latent_vectors, num_samples):\n",
    "        noise_factor = 0.05\n",
    "            \n",
    "        new_latent_vectors = []\n",
    "        for _ in range(num_samples):\n",
    "            noise = np.random.normal(0, noise_factor, latent_vectors.shape[1])\n",
    "            new_latent_vector = latent_vectors[np.random.choice(latent_vectors.shape[0])] + noise\n",
    "            new_latent_vectors.append(new_latent_vector)\n",
    "\n",
    "        new_latent_vectors = np.array(new_latent_vectors)\n",
    "        return new_latent_vectors\n",
    "\n",
    "    new_latent_vectors=generate_new_samples(latent_vectors,nn)\n",
    "    # 디코더 부분만 따로 모델로 정의\n",
    "\n",
    "    decoder_input = layers.Input(shape=(64,))  # 잠재 벡터 차원 (예: 64)\n",
    "    decoder_layer = autoencoder.layers[-4](decoder_input)\n",
    "    decoder_layer = autoencoder.layers[-3](decoder_layer)  # 첫 번째 디코더 레이어\n",
    "    decoder_layer = autoencoder.layers[-2](decoder_layer)  # 두 번째 디코더 레이어\n",
    "    decoder_layer = autoencoder.layers[-1](decoder_layer)  # 마지막 디코더 레이어\n",
    "    decoder = models.Model(decoder_input, decoder_layer)\n",
    "\n",
    "    # 잠재 벡터로부터 복원된 데이터 생성\n",
    "    augmented_data = decoder.predict(new_latent_vectors)\n",
    "\n",
    "    # 중복된 데이터 제거\n",
    "    augmented_data_unique = np.unique(augmented_data, axis=0)  # 중복 제거\n",
    "    print(augmented_data_unique.shape)\n",
    "    xaep.append(augmented_data_unique)\n",
    "    yaep.append([i]*nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2183391",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr=np.vstack(xaep)#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad2ef002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10928012822334691"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr=np.vstack(xaep)#.shape\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=10, random_state = 312,tree_method=\"hist\", device=\"cuda\")\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(tr, yaep)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "\n",
    "y_pred = model.predict(x) # 예측 라벨(0과 1로 예측)\n",
    "\n",
    "# 예측 라벨과 실제 라벨 사이의 정확도 측정\n",
    "\n",
    "f1_score(y_pred, y,average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "124e0b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00101138, 0.13212544, 0.19351056, 0.21975326])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y,y_pred, average=None)\n",
    "confusion_matrix(y,y_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79fbc66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      4,     65,     83,     10],\n",
       "       [     0,      4,      7,     12,      1],\n",
       "       [     0,    979,   8481,   9821,   1984],\n",
       "       [     0,   2415,  21582,  28549,   5661],\n",
       "       [     0,   4484,  76978, 198392,  40488]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y,y_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf6b0070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "117\n",
      "521\n",
      "565\n",
      "645\n",
      "748\n",
      "810\n",
      "857\n",
      "186\n",
      "77 1116\n",
      "117 1116\n",
      "521 1116\n",
      "565 1116\n",
      "645 1116\n",
      "748 1116\n",
      "810 1116\n",
      "857 1116\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "\n",
    "path1=os.listdir(\"ppp/open/train/\")\n",
    "data=1\n",
    "\n",
    "aaa=0\n",
    "for j in path1:    \n",
    "    a=os.listdir(f\"ppp/open/train/{j}\")\n",
    "    p=[]\n",
    "    \n",
    "    pp=[]\n",
    "    for i in a[:1]:\n",
    "        p=pd.read_parquet(f\"ppp/open/train/{j}/{i}\").drop(\"기준년월\",axis=1)\n",
    "        data=pd.merge(data,p,on=\"ID\",how=\"inner\") if j!=\"1.회원정보\" else p\n",
    "        \n",
    "        print(len(data.columns))\n",
    "idx=data[data[\"Segment\"].apply(lambda x: x==\"A\" or x==\"B\")].index\n",
    "print(len(idx))\n",
    "path1=os.listdir(\"ppp/open/train/\")\n",
    "#data=1\n",
    "data2=10\n",
    "aaa=0\n",
    "for j in path1:    \n",
    "    a=os.listdir(f\"ppp/open/train/{j}\")\n",
    "    p=[]\n",
    "    \n",
    "    pp=[]\n",
    "    for i in a:\n",
    "        \n",
    "        p=(pd.read_parquet(f\"ppp/open/train/{j}/{i}\").drop(\"기준년월\",axis=1))\n",
    "        p=p.iloc[idx]\n",
    "        #print(len(p))\n",
    "        pp.append(p)\n",
    "    #print(len(pd.concat(pp).columns))\n",
    "    pd.concat(pp)\n",
    "    data2=pd.concat([data2,pd.concat(pp).drop(\"ID\",axis=1)],axis=1) if aaa==1 else pd.concat(pp)\n",
    "    print(len(data2.columns),len(pd.concat(pp)))\n",
    "    aaa=1\n",
    "    pp=[]\n",
    "    #print(len(data2))\n",
    "    #print(i,j)  \n",
    "data=pd.concat([data,data2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a6db842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=pd.concat([data,data2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59bd730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#data[\"Segment\"]=data[\"Segment\"].apply(lambda x: 1 if x==\"B\" else 0)\n",
    "for i in data.columns:\n",
    "    le = LabelEncoder()\n",
    "    if data[i].dtype=='O':\n",
    "        data[i]=le.fit_transform(data[i])\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "y=data[\"Segment\"]\n",
    "x=data.drop([\"ID\",\"Segment\"],axis=1)\n",
    "\n",
    "#x=x.fillna(method=\"mean\",axis=1)\n",
    "for i in x.columns:\n",
    "    if x[i].isnull().sum():\n",
    "        x[i]=x[i].fillna(x[i].mean())\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=40)\n",
    "x = pd.DataFrame(pca.fit_transform(x))\n",
    "mi=x.min()\n",
    "ma=x.max()\n",
    "x=((x-mi)/(ma-mi))\n",
    "x=x.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05cb7959",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x_te, y1, y_te = train_test_split(x,y,test_size=0.1,shuffle=True,stratify =y)\n",
    "#xel, x_te1, yel, y_te1=train_test_split(x_te,y_te,test_size=0.5,shuffle=True,stratify =y_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98c4c621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    320342\n",
       "3     58207\n",
       "2     21265\n",
       "0      1134\n",
       "1       168\n",
       "Name: Segment, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Segment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "743cef8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "57/57 [==============================] - 2s 3ms/step - loss: 0.0213\n",
      "Epoch 2/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0113\n",
      "Epoch 3/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0079\n",
      "Epoch 4/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 5/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0043\n",
      "Epoch 6/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 7/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0029\n",
      "Epoch 8/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 9/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0023\n",
      "Epoch 10/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0019\n",
      "Epoch 11/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0017\n",
      "Epoch 12/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0016\n",
      "Epoch 13/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 14/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 15/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 16/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 17/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 18/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 19/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 9.9681e-04\n",
      "Epoch 20/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 8.5326e-04\n",
      "Epoch 21/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 8.0688e-04\n",
      "Epoch 22/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 8.7589e-04\n",
      "Epoch 23/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 7.3656e-04\n",
      "Epoch 24/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 6.3076e-04\n",
      "Epoch 25/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 5.7597e-04\n",
      "Epoch 26/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 5.7444e-04\n",
      "Epoch 27/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 5.2632e-04\n",
      "Epoch 28/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 5.1739e-04\n",
      "Epoch 29/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 4.5153e-04\n",
      "Epoch 30/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 4.7046e-04\n",
      "Epoch 31/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 4.1991e-04\n",
      "Epoch 32/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 4.2849e-04\n",
      "Epoch 33/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 4.6430e-04\n",
      "Epoch 34/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 4.2034e-04\n",
      "Epoch 35/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 4.4706e-04\n",
      "Epoch 36/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.8938e-04\n",
      "Epoch 37/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.3947e-04\n",
      "Epoch 38/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.1996e-04\n",
      "Epoch 39/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 4.0026e-04\n",
      "Epoch 40/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.4159e-04\n",
      "Epoch 41/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.2350e-04\n",
      "Epoch 42/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.0763e-04\n",
      "Epoch 43/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.5928e-04\n",
      "Epoch 44/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.9945e-04\n",
      "Epoch 45/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.7196e-04\n",
      "Epoch 46/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.7442e-04\n",
      "Epoch 47/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.5629e-04\n",
      "Epoch 48/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.7097e-04\n",
      "Epoch 49/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.5955e-04\n",
      "Epoch 50/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.2939e-04\n",
      "Epoch 51/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.4773e-04\n",
      "Epoch 52/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.7258e-04\n",
      "Epoch 53/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.9624e-04\n",
      "Epoch 54/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.6090e-04\n",
      "Epoch 55/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.4289e-04\n",
      "Epoch 56/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.5333e-04\n",
      "Epoch 57/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.7657e-04\n",
      "Epoch 58/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 3.7420e-04\n",
      "Epoch 59/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.2078e-04\n",
      "Epoch 60/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.7845e-04\n",
      "Epoch 61/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.5010e-04\n",
      "Epoch 62/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.2363e-04\n",
      "Epoch 63/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.3105e-04\n",
      "Epoch 64/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.0769e-04\n",
      "Epoch 65/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.0768e-04\n",
      "Epoch 66/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.7932e-04\n",
      "Epoch 67/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.8558e-04\n",
      "Epoch 68/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.9197e-04\n",
      "Epoch 69/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.1639e-04\n",
      "Epoch 70/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.4275e-04\n",
      "Epoch 71/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.5326e-04\n",
      "Epoch 72/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.1894e-04\n",
      "Epoch 73/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.8143e-04\n",
      "Epoch 74/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.5563e-04\n",
      "Epoch 75/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.1902e-04\n",
      "Epoch 76/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.8958e-04\n",
      "Epoch 77/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.5332e-04\n",
      "Epoch 78/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.3386e-04\n",
      "Epoch 79/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.0207e-04\n",
      "Epoch 80/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.1964e-04\n",
      "Epoch 81/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.0804e-04\n",
      "Epoch 82/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.7824e-04\n",
      "Epoch 83/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.4582e-04\n",
      "Epoch 84/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.5593e-04\n",
      "Epoch 85/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 6.3795e-04\n",
      "Epoch 86/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0069\n",
      "Epoch 87/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0022\n",
      "Epoch 88/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 89/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 6.7310e-04\n",
      "Epoch 90/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 4.3446e-04\n",
      "Epoch 91/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.1697e-04\n",
      "Epoch 92/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.4162e-04\n",
      "Epoch 93/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.0941e-04\n",
      "Epoch 94/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.0769e-04\n",
      "Epoch 95/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.7896e-04\n",
      "Epoch 96/130\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.6200e-04\n",
      "Epoch 97/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.6120e-04\n",
      "Epoch 98/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 5ms/step - loss: 1.3181e-04\n",
      "Epoch 99/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2757e-04\n",
      "Epoch 100/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.3751e-04\n",
      "Epoch 101/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2811e-04\n",
      "Epoch 102/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.1772e-04\n",
      "Epoch 103/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.0698e-04\n",
      "Epoch 104/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.1093e-04\n",
      "Epoch 105/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2317e-04\n",
      "Epoch 106/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.1196e-04\n",
      "Epoch 107/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.0180e-04\n",
      "Epoch 108/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 9.0980e-05\n",
      "Epoch 109/130\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 8.9400e-05\n",
      "Epoch 110/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 8.2238e-05\n",
      "Epoch 111/130\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 8.5803e-05\n",
      "Epoch 112/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 9.4594e-05\n",
      "Epoch 113/130\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 9.4143e-05\n",
      "Epoch 114/130\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 9.7404e-05\n",
      "Epoch 115/130\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 1.2017e-04\n",
      "Epoch 116/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.3835e-04\n",
      "Epoch 117/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2475e-04\n",
      "Epoch 118/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2042e-04\n",
      "Epoch 119/130\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 1.2885e-04\n",
      "Epoch 120/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.4947e-04\n",
      "Epoch 121/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.7903e-04\n",
      "Epoch 122/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.6781e-04\n",
      "Epoch 123/130\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 1.6913e-04\n",
      "Epoch 124/130\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 1.5625e-04\n",
      "Epoch 125/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.6346e-04\n",
      "Epoch 126/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.8116e-04\n",
      "Epoch 127/130\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 1.6973e-04\n",
      "Epoch 128/130\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.6816e-04\n",
      "Epoch 129/130\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 1.7429e-04\n",
      "Epoch 130/130\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 1.4946e-04\n",
      "36/36 [==============================] - 0s 1ms/step\n",
      "22778/22778 [==============================] - 21s 938us/step\n",
      "(728865, 40)\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0338\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0229\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0198\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0131\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0121\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0115\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0110\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0101\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0094\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0088\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0077\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0069\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0061\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0055\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0051\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0042\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0037\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0033\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0031\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0023\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0023\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0022\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0022\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0021\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0017\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0016\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0017\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0020\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.4447e-04\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0010\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.3260e-04\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0010\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0010\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.6264e-04\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.5133e-04\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.9485e-04\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.1100e-04\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.3601e-04\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0397e-04\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1175e-04\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1966e-04\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1908e-04\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.4454e-04\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.3107e-04\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1247e-04\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9752e-04\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 7.2163e-04\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.3974e-04\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.7250e-04\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1396e-04\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7677e-04\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.6139e-04\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.9498e-04\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.8884e-04\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.6190e-04\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.3199e-04\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.0364e-04\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.3993e-04\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.8612e-04\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.4178e-04\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.2184e-04\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.3721e-04\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.2802e-04\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.0413e-04\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.1543e-04\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.6090e-04\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.6671e-04\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7834e-04\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.3558e-04\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5379e-04\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7976e-04\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.4961e-04\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.3686e-04\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1153e-04\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.5959e-04\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.7320e-04\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.4907e-04\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.8713e-04\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.6682e-04\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2649e-04\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.3645e-04\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2935e-04\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.9507e-04\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.5574e-04\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.5462e-04\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.5464e-04\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.4743e-04\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.2342e-04\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.6033e-04\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.6543e-04\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.6769e-04\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3.1493e-04\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.3814e-04\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2064e-04\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3.5617e-04\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.6552e-04\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.5907e-04\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1810e-04\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.0273e-04\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.4691e-04\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.1841e-04\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9955e-04\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.8846e-04\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0537e-04\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9245e-04\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9289e-04\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.8876e-04\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0123e-04\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9340e-04\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7611e-04\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7806e-04\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.6232e-04\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0488e-04\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0174e-04\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9849e-04\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9439e-04\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7732e-04\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7713e-04\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.6496e-04\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5142e-04\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.8131e-04\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7079e-04\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0010e-04\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.4215e-04\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.6026e-04\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.5807e-04\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 5.9847e-04\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.8780e-04\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.1801e-04\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.0148e-04\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.8555e-04\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.5459e-04\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.8645e-04\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.9431e-04\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.5203e-04\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.8363e-04\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.2153e-04\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7861e-04\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5617e-04\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5845e-04\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2561e-04\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1319e-04\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0611e-04\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.0992e-05\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.7409e-05\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.4116e-05\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.5267e-05\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.5228e-05\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.3205e-05\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.2332e-05\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.1116e-05\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.0916e-05\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.9229e-05\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.2158e-05\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.2670e-05\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.1192e-05\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.4292e-05\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.3737e-05\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 6.8643e-05\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6488e-05\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.0344e-05\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0875e-05\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.5288e-05\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.6806e-05\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0352e-05\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9065e-05\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5190e-05\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.7126e-05\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.2008e-05\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.8326e-05\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5384e-04\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4736e-04\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4613e-04\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5099e-04\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4428e-04\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2212e-04\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2494e-04\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0782e-04\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1132e-04\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0150e-04\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.0714e-05\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1480e-04\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "22808/22808 [==============================] - 21s 900us/step\n",
      "(729831, 40)\n",
      "Epoch 1/7\n",
      "333/333 [==============================] - 2s 4ms/step - loss: 0.0072\n",
      "Epoch 2/7\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021\n",
      "Epoch 3/7\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0013\n",
      "Epoch 4/7\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 8.6092e-04\n",
      "Epoch 5/7\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 5.9232e-04\n",
      "Epoch 6/7\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 4.2950e-04\n",
      "Epoch 7/7\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 3.4071e-04\n",
      "665/665 [==============================] - 1s 906us/step\n",
      "22148/22148 [==============================] - 20s 918us/step\n",
      "(708734, 40)\n",
      "Epoch 1/4\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 0.0048\n",
      "Epoch 2/4\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 0.0012\n",
      "Epoch 3/4\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 5.9466e-04\n",
      "Epoch 4/4\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 3.0349e-04\n",
      "1819/1819 [==============================] - 2s 919us/step\n",
      "20994/20994 [==============================] - 19s 925us/step\n",
      "(671792, 40)\n",
      "Epoch 1/2\n",
      "1252/1252 [==============================] - 4s 3ms/step - loss: 0.0017\n",
      "Epoch 2/2\n",
      "1252/1252 [==============================] - 4s 3ms/step - loss: 1.9498e-04\n",
      "10011/10011 [==============================] - 9s 930us/step\n",
      "12802/12802 [==============================] - 12s 908us/step\n",
      "(409657, 40)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "# 오토인코더 모델 정의\n",
    "def build_autoencoder(input_dim):\n",
    "    input_layer = layers.Input(shape=(input_dim,))\n",
    "    \n",
    "    # 인코더\n",
    "    encoded = layers.Dense(1024, activation='relu')(input_layer)\n",
    "    encoded = layers.Dense(512, activation='relu')(encoded)\n",
    "    encoded = layers.Dense(256, activation='relu')(encoded)\n",
    "    latent_space = layers.Dense(200, activation='relu')(encoded)  # 잠재 공간 벡터\n",
    "    \n",
    "    # 디코더\n",
    "    decoded = layers.Dense(256, activation='relu')(latent_space)\n",
    "    decoded = layers.Dense(512, activation='relu')(decoded)\n",
    "    decoded = layers.Dense(1024, activation='relu')(decoded)\n",
    "    output_layer = layers.Dense(input_dim, activation='sigmoid')(decoded)  # 원본 차원으로 복원\n",
    "    \n",
    "    autoencoder = models.Model(input_layer, output_layer)\n",
    "    encoder = models.Model(input_layer, latent_space)  # 인코더 부분만 별도 모델로\n",
    "    \n",
    "    autoencoder.compile(optimizer='adam', loss='mse')  # 손실 함수는 평균 제곱 오차(MSE)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "xaep=[]\n",
    "yaep=[]\n",
    "# 모델 빌드\n",
    "for i in range(5):\n",
    "    \n",
    "    xxx=x.loc[y[y==i].index]#[:10000]\n",
    "    ep=[130,200,7,4,2][i]\n",
    "    bh=[20,16,64,128,256][i]\n",
    "    kj=629999+100000\n",
    "    nn=kj-len(xxx)\n",
    "    #nn=100000\n",
    "    #ep=[100,100,100,100,100][i]\n",
    "    #bh=[8,8,8,8,8][i]\n",
    "    #ep=10\n",
    "    input_dim = xxx.shape[1]  # 데이터의 열 수\n",
    "    autoencoder, encoder = build_autoencoder(input_dim)\n",
    "\n",
    "\n",
    "    # 예시로 랜덤 데이터를 생성 (실제 데이터로 교체해야 함)\n",
    "    \n",
    "    \n",
    "\n",
    "    X_train = xxx.values  \n",
    "\n",
    "    # 오토인코더 학습\n",
    "    autoencoder.fit(X_train, X_train, epochs=ep, batch_size=bh)\n",
    "    # 잠재 공간에서 샘플링\n",
    "    latent_vectors = encoder.predict(X_train)\n",
    "\n",
    "    # Latent 벡터에 약간의 노이즈를 추가하여 새로운 샘플 생성\n",
    "    def generate_new_samples(latent_vectors, num_samples):\n",
    "        noise_factor = 0.1\n",
    "            \n",
    "        new_latent_vectors = []\n",
    "        for _ in range(num_samples):\n",
    "            noise = np.random.normal(0, noise_factor, latent_vectors.shape[1])\n",
    "            new_latent_vector = latent_vectors[np.random.choice(latent_vectors.shape[0])] + noise\n",
    "            new_latent_vectors.append(new_latent_vector)\n",
    "\n",
    "        new_latent_vectors = np.array(new_latent_vectors)\n",
    "        return new_latent_vectors\n",
    "\n",
    "    new_latent_vectors=generate_new_samples(latent_vectors,nn)\n",
    "    # 디코더 부분만 따로 모델로 정의\n",
    "\n",
    "    decoder_input = layers.Input(shape=(200,))  # 잠재 벡터 차원 (예: 64)\n",
    "    decoder_layer = autoencoder.layers[-4](decoder_input)\n",
    "    decoder_layer = autoencoder.layers[-3](decoder_layer)  # 첫 번째 디코더 레이어\n",
    "    decoder_layer = autoencoder.layers[-2](decoder_layer)  # 두 번째 디코더 레이어\n",
    "    decoder_layer = autoencoder.layers[-1](decoder_layer)  # 마지막 디코더 레이어\n",
    "    decoder = models.Model(decoder_input, decoder_layer)\n",
    "\n",
    "    # 잠재 벡터로부터 복원된 데이터 생성\n",
    "    augmented_data = decoder.predict(new_latent_vectors)\n",
    "\n",
    "    # 중복된 데이터 제거\n",
    "    augmented_data_unique = np.unique(augmented_data, axis=0)  # 중복 제거\n",
    "    print(augmented_data_unique.shape)\n",
    "    xaep.append(augmented_data_unique)\n",
    "    yaep+=[i]*nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "454f64d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tr=np.vstack(xaep)#.shape\n",
    "\n",
    "x123=np.vstack([x.values,tr])\n",
    "y123=np.concatenate([y.values,np.array(yaep)])\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=20, random_state = 312,tree_method=\"hist\", device=\"cuda\")\n",
    "\n",
    "# 모델 학습\n",
    "#model.fit(x1, y1)\n",
    "#model.fit(tr, yaep)\n",
    "model.fit(x123, y123)\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "\n",
    "#y_pred = model.predict(x_te) # 예측 라벨(0과 1로 예측)\n",
    "\n",
    "# 예측 라벨과 실제 라벨 사이의 정확도 측정\n",
    "\n",
    "#print(f1_score(y_pred, y_te,average=\"macro\"))\n",
    "#print(f1_score(y_te,y_pred, average=None))\n",
    "#print(confusion_matrix(y_te,y_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c9b03f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:12:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save_model(f\"ppp/open/xgb_200_20_01_all_pca_40_f1_01op.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3169f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "1. load\n",
    "2. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a55e2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#data[\"Segment\"]=data[\"Segment\"].apply(lambda x: 1 if x==\"B\" else 0)\n",
    "led={}\n",
    "for i in data.columns:\n",
    "    le = LabelEncoder()\n",
    "    if data[i].dtype=='O':\n",
    "        data[i]=le.fit_transform(data[i])\n",
    "        led[i]=le\n",
    "\n",
    "\n",
    "y=data[\"Segment\"]\n",
    "x=data.drop([\"ID\",\"Segment\"],axis=1)\n",
    "\n",
    "#x=x.fillna(method=\"mean\",axis=1)\n",
    "fid={}\n",
    "for i in x.columns:\n",
    "    if x[i].isnull().sum():\n",
    "        x[i]=x[i].fillna(x[i].mean())\n",
    "        fid[i]=x[i].mean()\n",
    "\n",
    "pca = PCA(n_components=40)\n",
    "x = pd.DataFrame(pca.fit_transform(x))\n",
    "mi=x.min()\n",
    "ma=x.max()\n",
    "x=((x-mi)/(ma-mi))\n",
    "x=x.fillna(0)\n",
    "\n",
    "# led \n",
    "# fid \n",
    "# pca \n",
    "# mi \n",
    "# ma \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a272dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca6f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "\n",
    "path1=os.listdir(\"ppp/open/train/\")\n",
    "data=1\n",
    "for j in path1:\n",
    "    \n",
    "    a=os.listdir(f\"ppp/open/train/{j}\")\n",
    "    p=[]\n",
    "    \n",
    "    for i in a[:1]:\n",
    "        p=pd.read_parquet(f\"ppp/open/train/{j}/{i}\").drop(\"기준년월\",axis=1)\n",
    "        data=pd.merge(data,p,on=\"ID\",how=\"inner\") if j!=\"1.회원정보\" else p\n",
    "        \n",
    "        print(j,i)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d4e3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb335fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13da6e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa152500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49765227011289914"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tr=np.vstack(xaep)#.shape\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=20, random_state = 312,tree_method=\"hist\", device=\"cuda\")\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(tr, yaep)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "\n",
    "y_pred = model.predict(x_te) # 예측 라벨(0과 1로 예측)\n",
    "\n",
    "# 예측 라벨과 실제 라벨 사이의 정확도 측정\n",
    "\n",
    "f1_score(y_pred, y_te,average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4eafba42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35157546, 0.38461538, 0.47861668, 0.51685039, 0.75660344])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_te,y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c81381ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_te' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12768/740527252.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#f1_score(y,y_pred, average=None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_te' is not defined"
     ]
    }
   ],
   "source": [
    "#f1_score(y,y_pred, average=None)\n",
    "confusion_matrix(y_te,y_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ff3d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efc27ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "579d25ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    70000\n",
       "3    28000\n",
       "2    14000\n",
       "0      113\n",
       "1       17\n",
       "Name: Segment, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33b97692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 250000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h1),len(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a49cf3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:23:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"early_stoppings\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.07097\teval-merror:0.08888\n",
      "[1]\ttrain-merror:0.06134\teval-merror:0.07920\n",
      "[2]\ttrain-merror:0.05754\teval-merror:0.07568\n",
      "[3]\ttrain-merror:0.05323\teval-merror:0.07108\n",
      "[4]\ttrain-merror:0.05094\teval-merror:0.06876\n",
      "[5]\ttrain-merror:0.04886\teval-merror:0.06704\n",
      "[6]\ttrain-merror:0.04648\teval-merror:0.06488\n",
      "[7]\ttrain-merror:0.04473\teval-merror:0.06308\n",
      "[8]\ttrain-merror:0.04258\teval-merror:0.06008\n",
      "[9]\ttrain-merror:0.04086\teval-merror:0.05904\n",
      "[10]\ttrain-merror:0.03960\teval-merror:0.05796\n",
      "[11]\ttrain-merror:0.03775\teval-merror:0.05636\n",
      "[12]\ttrain-merror:0.03635\teval-merror:0.05500\n",
      "[13]\ttrain-merror:0.03459\teval-merror:0.05372\n",
      "[14]\ttrain-merror:0.03349\teval-merror:0.05188\n",
      "[15]\ttrain-merror:0.03180\teval-merror:0.05104\n",
      "[16]\ttrain-merror:0.03032\teval-merror:0.04956\n",
      "[17]\ttrain-merror:0.02883\teval-merror:0.04772\n",
      "[18]\ttrain-merror:0.02761\teval-merror:0.04616\n",
      "[19]\ttrain-merror:0.02636\teval-merror:0.04448\n",
      "[20]\ttrain-merror:0.02525\teval-merror:0.04352\n",
      "[21]\ttrain-merror:0.02417\teval-merror:0.04260\n",
      "[22]\ttrain-merror:0.02315\teval-merror:0.04188\n",
      "[23]\ttrain-merror:0.02223\teval-merror:0.04120\n",
      "[24]\ttrain-merror:0.02142\teval-merror:0.04008\n",
      "[25]\ttrain-merror:0.02039\teval-merror:0.03904\n",
      "[26]\ttrain-merror:0.01966\teval-merror:0.03816\n",
      "[27]\ttrain-merror:0.01889\teval-merror:0.03700\n",
      "[28]\ttrain-merror:0.01811\teval-merror:0.03592\n",
      "[29]\ttrain-merror:0.01719\teval-merror:0.03492\n",
      "[30]\ttrain-merror:0.01662\teval-merror:0.03416\n",
      "[31]\ttrain-merror:0.01595\teval-merror:0.03328\n",
      "[32]\ttrain-merror:0.01511\teval-merror:0.03256\n",
      "[33]\ttrain-merror:0.01445\teval-merror:0.03216\n",
      "[34]\ttrain-merror:0.01363\teval-merror:0.03128\n",
      "[35]\ttrain-merror:0.01298\teval-merror:0.03084\n",
      "[36]\ttrain-merror:0.01242\teval-merror:0.03036\n",
      "[37]\ttrain-merror:0.01175\teval-merror:0.02944\n",
      "[38]\ttrain-merror:0.01111\teval-merror:0.02872\n",
      "[39]\ttrain-merror:0.01060\teval-merror:0.02816\n",
      "[40]\ttrain-merror:0.01012\teval-merror:0.02752\n",
      "[41]\ttrain-merror:0.00967\teval-merror:0.02720\n",
      "[42]\ttrain-merror:0.00915\teval-merror:0.02676\n",
      "[43]\ttrain-merror:0.00877\teval-merror:0.02644\n",
      "[44]\ttrain-merror:0.00817\teval-merror:0.02584\n",
      "[45]\ttrain-merror:0.00777\teval-merror:0.02532\n",
      "[46]\ttrain-merror:0.00733\teval-merror:0.02456\n",
      "[47]\ttrain-merror:0.00693\teval-merror:0.02396\n",
      "[48]\ttrain-merror:0.00658\teval-merror:0.02392\n",
      "[49]\ttrain-merror:0.00617\teval-merror:0.02352\n",
      "[50]\ttrain-merror:0.00588\teval-merror:0.02316\n",
      "[51]\ttrain-merror:0.00549\teval-merror:0.02300\n",
      "[52]\ttrain-merror:0.00524\teval-merror:0.02280\n",
      "[53]\ttrain-merror:0.00494\teval-merror:0.02248\n",
      "[54]\ttrain-merror:0.00466\teval-merror:0.02204\n",
      "[55]\ttrain-merror:0.00447\teval-merror:0.02168\n",
      "[56]\ttrain-merror:0.00426\teval-merror:0.02124\n",
      "[57]\ttrain-merror:0.00403\teval-merror:0.02104\n",
      "[58]\ttrain-merror:0.00386\teval-merror:0.02060\n",
      "[59]\ttrain-merror:0.00367\teval-merror:0.02012\n",
      "[60]\ttrain-merror:0.00350\teval-merror:0.02000\n",
      "[61]\ttrain-merror:0.00330\teval-merror:0.01960\n",
      "[62]\ttrain-merror:0.00312\teval-merror:0.01948\n",
      "[63]\ttrain-merror:0.00298\teval-merror:0.01920\n",
      "[64]\ttrain-merror:0.00291\teval-merror:0.01892\n",
      "[65]\ttrain-merror:0.00265\teval-merror:0.01848\n",
      "[66]\ttrain-merror:0.00252\teval-merror:0.01828\n",
      "[67]\ttrain-merror:0.00232\teval-merror:0.01808\n",
      "[68]\ttrain-merror:0.00224\teval-merror:0.01772\n",
      "[69]\ttrain-merror:0.00207\teval-merror:0.01732\n",
      "[70]\ttrain-merror:0.00194\teval-merror:0.01712\n",
      "[71]\ttrain-merror:0.00184\teval-merror:0.01692\n",
      "[72]\ttrain-merror:0.00168\teval-merror:0.01688\n",
      "[73]\ttrain-merror:0.00160\teval-merror:0.01664\n",
      "[74]\ttrain-merror:0.00145\teval-merror:0.01632\n",
      "[75]\ttrain-merror:0.00139\teval-merror:0.01624\n",
      "[76]\ttrain-merror:0.00130\teval-merror:0.01588\n",
      "[77]\ttrain-merror:0.00122\teval-merror:0.01560\n",
      "[78]\ttrain-merror:0.00110\teval-merror:0.01560\n",
      "[79]\ttrain-merror:0.00103\teval-merror:0.01564\n",
      "[80]\ttrain-merror:0.00094\teval-merror:0.01532\n",
      "[81]\ttrain-merror:0.00085\teval-merror:0.01496\n",
      "[82]\ttrain-merror:0.00079\teval-merror:0.01480\n",
      "[83]\ttrain-merror:0.00075\teval-merror:0.01464\n",
      "[84]\ttrain-merror:0.00069\teval-merror:0.01452\n",
      "[85]\ttrain-merror:0.00068\teval-merror:0.01440\n",
      "[86]\ttrain-merror:0.00061\teval-merror:0.01432\n",
      "[87]\ttrain-merror:0.00059\teval-merror:0.01424\n",
      "[88]\ttrain-merror:0.00055\teval-merror:0.01412\n",
      "[89]\ttrain-merror:0.00051\teval-merror:0.01372\n",
      "[90]\ttrain-merror:0.00047\teval-merror:0.01360\n",
      "[91]\ttrain-merror:0.00042\teval-merror:0.01344\n",
      "[92]\ttrain-merror:0.00040\teval-merror:0.01340\n",
      "[93]\ttrain-merror:0.00038\teval-merror:0.01328\n",
      "[94]\ttrain-merror:0.00036\teval-merror:0.01308\n",
      "[95]\ttrain-merror:0.00033\teval-merror:0.01320\n",
      "[96]\ttrain-merror:0.00030\teval-merror:0.01312\n",
      "[97]\ttrain-merror:0.00029\teval-merror:0.01304\n",
      "[98]\ttrain-merror:0.00026\teval-merror:0.01300\n",
      "[99]\ttrain-merror:0.00025\teval-merror:0.01296\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xtr, x_te, ytr, y_te = train_test_split(tr, h1,test_size=0.2,shuffle=True,stratify =h1)\n",
    "xel, x_te1, yel, y_te1=train_test_split(x_te,y_te,test_size=0.5,shuffle=True,stratify =y_te)\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(data=xtr, label=ytr)\n",
    "dval = xgb.DMatrix(data=xel, label=yel)\n",
    "dtest = xgb.DMatrix(data=x_te1)\n",
    "\n",
    "params = {'max_depth' : 10,\n",
    "         'eta' : 0.1, \n",
    "         'objective' : 'multi:softmax',\n",
    "         'eval_metric' : 'merror',\n",
    "         'early_stoppings' : 100,\n",
    "         'n_estimators' : 100,\n",
    "         'num_class':5}\n",
    "         \n",
    " #훈련 set은 train, 평가set은 eval로 명기\n",
    "xgb_model = xgb.train(params = params, dtrain = dtrain, num_boost_round = 100, \n",
    "                        early_stopping_rounds = 100, evals=[(dtrain,'train'),(dval,'eval')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6866b84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5000    0    0    0    0]\n",
      " [   0 5000    0    0    0]\n",
      " [  23 4977    0    0    0]\n",
      " [   1 4999    0    0    0]\n",
      " [   0 5000    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# 예측하기, 확률값으로 반환됨\n",
    "y_pred_probs = xgb_model.predict(dtest)\n",
    "\n",
    "# 0또는 1로 변경\n",
    "y_preds = [1 if x>0.5 else 0 for x in y_pred_probs]\n",
    "\n",
    "#성능 평가\n",
    "print(confusion_matrix(y_te1, y_preds))\n",
    "#print(classification_report(y_te1, y_preds))\n",
    "#print(roc_auc_score(y_te1, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c024c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed49d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b74d95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "117\n",
      "521\n",
      "565\n",
      "645\n",
      "748\n",
      "810\n",
      "857\n",
      "160186\n",
      "77 961116\n",
      "117 961116\n",
      "521 961116\n",
      "565 961116\n",
      "645 961116\n",
      "748 961116\n",
      "810 961116\n",
      "857 961116\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "\n",
    "path1=os.listdir(\"ppp/open/train/\")\n",
    "data=1\n",
    "\n",
    "aaa=0\n",
    "for j in path1:    \n",
    "    a=os.listdir(f\"ppp/open/train/{j}\")\n",
    "    p=[]\n",
    "    \n",
    "    pp=[]\n",
    "    for i in a[:1]:\n",
    "        p=pd.read_parquet(f\"ppp/open/train/{j}/{i}\").drop(\"기준년월\",axis=1)\n",
    "        data=pd.merge(data,p,on=\"ID\",how=\"inner\") if j!=\"1.회원정보\" else p\n",
    "        \n",
    "        print(len(data.columns))\n",
    "del p\n",
    "idx=data[data[\"Segment\"].apply(lambda x: x==\"A\" or x==\"B\")].index\n",
    "#idx=data[data[\"Segment\"].apply(lambda x: x!=\"E\")].index\n",
    "idx2=data[data[\"Segment\"].apply(lambda x: x==\"E\" )].index\n",
    "idx2=np.random.choice(idx2,size=100000,replace=False)\n",
    "idx3=data[data[\"Segment\"].apply(lambda x: x==\"D\" )].index\n",
    "idx3=np.random.choice(idx3,size=40000,replace=False)\n",
    "idx4=data[data[\"Segment\"].apply(lambda x: x==\"C\" )].index\n",
    "idx4=np.random.choice(idx4,size=20000,replace=False)\n",
    "idx=np.concatenate([idx,idx2,idx3,idx4])\n",
    "data=data.iloc[idx]\n",
    "print(len(idx))\n",
    "path1=os.listdir(\"ppp/open/train/\")\n",
    "#data=1\n",
    "data2=10\n",
    "aaa=0\n",
    "for j in path1:    \n",
    "    a=os.listdir(f\"ppp/open/train/{j}\")\n",
    "    p=[]\n",
    "    \n",
    "    pp=[]\n",
    "    for i in a:\n",
    "        \n",
    "        p=(pd.read_parquet(f\"ppp/open/train/{j}/{i}\").drop(\"기준년월\",axis=1))\n",
    "        p=p.iloc[idx]\n",
    "        #print(len(p))\n",
    "        pp.append(p)\n",
    "    #print(len(pd.concat(pp).columns))\n",
    "    pd.concat(pp)\n",
    "    data2=pd.concat([data2,pd.concat(pp).drop(\"ID\",axis=1)],axis=1) if aaa==1 else pd.concat(pp)\n",
    "    print(len(data2.columns),len(pd.concat(pp)))\n",
    "    aaa=1\n",
    "    pp=[]\n",
    "    #print(len(data2))\n",
    "    #print(i,j)  \n",
    "del p \n",
    "del pp\n",
    "data=pd.concat([data,data2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38905a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>남녀구분코드</th>\n",
       "      <th>연령</th>\n",
       "      <th>Segment</th>\n",
       "      <th>회원여부_이용가능</th>\n",
       "      <th>회원여부_이용가능_CA</th>\n",
       "      <th>회원여부_이용가능_카드론</th>\n",
       "      <th>소지여부_신용</th>\n",
       "      <th>소지카드수_유효_신용</th>\n",
       "      <th>소지카드수_이용가능_신용</th>\n",
       "      <th>...</th>\n",
       "      <th>변동률_RV일시불평잔</th>\n",
       "      <th>변동률_할부평잔</th>\n",
       "      <th>변동률_CA평잔</th>\n",
       "      <th>변동률_RVCA평잔</th>\n",
       "      <th>변동률_카드론평잔</th>\n",
       "      <th>변동률_잔액_B1M</th>\n",
       "      <th>변동률_잔액_일시불_B1M</th>\n",
       "      <th>변동률_잔액_CA_B1M</th>\n",
       "      <th>혜택수혜율_R3M</th>\n",
       "      <th>혜택수혜율_B0M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_002898</td>\n",
       "      <td>1</td>\n",
       "      <td>40대</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.141876</td>\n",
       "      <td>1.061523</td>\n",
       "      <td>0.852816</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.926784</td>\n",
       "      <td>-0.129833</td>\n",
       "      <td>-0.004090</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.858735</td>\n",
       "      <td>1.699488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_005253</td>\n",
       "      <td>2</td>\n",
       "      <td>50대</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.045397</td>\n",
       "      <td>0.855324</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>0.042504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.363363</td>\n",
       "      <td>-0.056497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_008128</td>\n",
       "      <td>2</td>\n",
       "      <td>40대</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.058149</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.231152</td>\n",
       "      <td>0.455868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.077981</td>\n",
       "      <td>0.773759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_010808</td>\n",
       "      <td>1</td>\n",
       "      <td>40대</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.987825</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.090059</td>\n",
       "      <td>-0.120669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.397872</td>\n",
       "      <td>1.349127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_014951</td>\n",
       "      <td>2</td>\n",
       "      <td>30대</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.533585</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.404796</td>\n",
       "      <td>-0.201554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.221645</td>\n",
       "      <td>2.409092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121297</th>\n",
       "      <td>TRAIN_392791</td>\n",
       "      <td>2</td>\n",
       "      <td>50대</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.907413</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.023180</td>\n",
       "      <td>0.168979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121298</th>\n",
       "      <td>TRAIN_110226</td>\n",
       "      <td>2</td>\n",
       "      <td>30대</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.013834</td>\n",
       "      <td>-0.015433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.259055</td>\n",
       "      <td>2.719115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121299</th>\n",
       "      <td>TRAIN_277555</td>\n",
       "      <td>2</td>\n",
       "      <td>30대</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.042696</td>\n",
       "      <td>-0.116437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.190866</td>\n",
       "      <td>1.748552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121300</th>\n",
       "      <td>TRAIN_374128</td>\n",
       "      <td>1</td>\n",
       "      <td>40대</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000638</td>\n",
       "      <td>1.032500</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.211860</td>\n",
       "      <td>0.084388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121301</th>\n",
       "      <td>TRAIN_056924</td>\n",
       "      <td>2</td>\n",
       "      <td>60대</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.603394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.200839</td>\n",
       "      <td>0.177865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.077349</td>\n",
       "      <td>1.766832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1121302 rows × 857 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  남녀구분코드   연령 Segment  회원여부_이용가능  회원여부_이용가능_CA  \\\n",
       "0        TRAIN_002898       1  40대       A          1             1   \n",
       "1        TRAIN_005253       2  50대       A          1             1   \n",
       "2        TRAIN_008128       2  40대       A          1             1   \n",
       "3        TRAIN_010808       1  40대       A          1             1   \n",
       "4        TRAIN_014951       2  30대       A          1             1   \n",
       "...               ...     ...  ...     ...        ...           ...   \n",
       "1121297  TRAIN_392791       2  50대       C          1             1   \n",
       "1121298  TRAIN_110226       2  30대       C          1             1   \n",
       "1121299  TRAIN_277555       2  30대       C          1             1   \n",
       "1121300  TRAIN_374128       1  40대       C          1             1   \n",
       "1121301  TRAIN_056924       2  60대       C          1             1   \n",
       "\n",
       "         회원여부_이용가능_카드론  소지여부_신용  소지카드수_유효_신용  소지카드수_이용가능_신용  ...  변동률_RV일시불평잔  \\\n",
       "0                    0        1            1              1  ...     1.141876   \n",
       "1                    1        1            2              2  ...     0.999998   \n",
       "2                    1        1            3              3  ...     0.999998   \n",
       "3                    1        1            3              3  ...     0.999998   \n",
       "4                    0        1            1              1  ...     0.999998   \n",
       "...                ...      ...          ...            ...  ...          ...   \n",
       "1121297              1        1            1              1  ...     0.999998   \n",
       "1121298              0        1            1              1  ...     0.999998   \n",
       "1121299              1        1            2              2  ...     0.999998   \n",
       "1121300              1        1            3              3  ...     1.000638   \n",
       "1121301              1        1            2              2  ...     0.999998   \n",
       "\n",
       "         변동률_할부평잔  변동률_CA평잔  변동률_RVCA평잔  변동률_카드론평잔  변동률_잔액_B1M  \\\n",
       "0        1.061523  0.852816    0.999998   0.926784   -0.129833   \n",
       "1        1.045397  0.855324    0.999998   0.999998    0.001441   \n",
       "2        1.058149  0.999998    0.999998   0.999998    0.231152   \n",
       "3        1.987825  0.999998    0.999998   0.999998   -0.090059   \n",
       "4        1.533585  0.999998    0.999998   0.999998   -0.404796   \n",
       "...           ...       ...         ...        ...         ...   \n",
       "1121297  0.907413  0.999998    0.999998   0.999998    0.023180   \n",
       "1121298  0.000000  0.999998    0.999998   0.999998    0.013834   \n",
       "1121299  0.000000  0.999998    0.999998   0.999998    0.042696   \n",
       "1121300  1.032500  0.999998    0.999998   0.999998    0.211860   \n",
       "1121301  0.603394  0.000000    0.999998   0.999998    0.200839   \n",
       "\n",
       "         변동률_잔액_일시불_B1M  변동률_잔액_CA_B1M  혜택수혜율_R3M 혜택수혜율_B0M  \n",
       "0             -0.004090       0.001787   0.858735  1.699488  \n",
       "1              0.042504       0.000000  -0.363363 -0.056497  \n",
       "2              0.455868       0.000000   1.077981  0.773759  \n",
       "3             -0.120669       0.000000   1.397872  1.349127  \n",
       "4             -0.201554       0.000000   1.221645  2.409092  \n",
       "...                 ...            ...        ...       ...  \n",
       "1121297        0.168979       0.000000   0.000000  0.000000  \n",
       "1121298       -0.015433       0.000000   1.259055  2.719115  \n",
       "1121299       -0.116437       0.000000   1.190866  1.748552  \n",
       "1121300        0.084388       0.000000   0.000000  0.000000  \n",
       "1121301        0.177865       0.000000   2.077349  1.766832  \n",
       "\n",
       "[1121302 rows x 857 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247befef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E    700000\n",
       "D    280000\n",
       "C    140000\n",
       "A      1134\n",
       "B       168\n",
       "Name: Segment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Segment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16aa99eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00059778, -0.05506461, -0.06621681,  0.04424021, -0.07442275,\n",
       "       -0.04182273,  0.0064056 ,  0.0065974 , -0.04699891,  0.06958978])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.normal(0, 0.05, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ea2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d509cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a9785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103c87b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a8c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b6df33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7311672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66698283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3271a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba76bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e016fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5e21bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1e533f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6c701eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp=[]\n",
    "ypyp=[]\n",
    "for i in range(5):\n",
    "    pp.append(x.iloc[y[y==i].index][:10000])\n",
    "    ypyp+=([i]*len(x.iloc[y[y==i].index][:10000]))\n",
    "x123=pd.concat(pp)\n",
    "ypyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3ded67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30186, 30186)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x123),len(ypyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14571f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4591849664508037"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_rt,x_te,y_tr,y_te=train_test_split(x123,ypyp,test_size=0.5,shuffle=True,stratify =ypyp)\n",
    "model.fit(x_rt, y_tr)\n",
    "y_pred = model.predict(x_te) # 예측 라벨(0과 1로 예측)\n",
    "\n",
    "# 예측 라벨과 실제 라벨 사이의 정확도 측정\n",
    "\n",
    "f1_score(y_te,y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30fe912b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   9,    0,   70,    1,    1],\n",
       "       [   0,    0,   12,    0,    0],\n",
       "       [   9,    2, 3611, 1159,  219],\n",
       "       [   1,    1, 1286, 3017,  695],\n",
       "       [   0,    0,  197,  832, 3971]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_te,y_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "faa04d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.168531</td>\n",
       "      <td>0.149061</td>\n",
       "      <td>0.169859</td>\n",
       "      <td>0.301675</td>\n",
       "      <td>0.196885</td>\n",
       "      <td>0.007448</td>\n",
       "      <td>0.790847</td>\n",
       "      <td>0.075297</td>\n",
       "      <td>0.537282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444616</td>\n",
       "      <td>0.350243</td>\n",
       "      <td>0.443707</td>\n",
       "      <td>0.616378</td>\n",
       "      <td>0.341417</td>\n",
       "      <td>0.497486</td>\n",
       "      <td>0.432200</td>\n",
       "      <td>0.553240</td>\n",
       "      <td>0.515729</td>\n",
       "      <td>0.476257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.184246</td>\n",
       "      <td>0.154516</td>\n",
       "      <td>0.171928</td>\n",
       "      <td>0.312609</td>\n",
       "      <td>0.219721</td>\n",
       "      <td>0.009232</td>\n",
       "      <td>0.805572</td>\n",
       "      <td>0.079049</td>\n",
       "      <td>0.556938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469215</td>\n",
       "      <td>0.367072</td>\n",
       "      <td>0.446296</td>\n",
       "      <td>0.616064</td>\n",
       "      <td>0.358595</td>\n",
       "      <td>0.500063</td>\n",
       "      <td>0.424957</td>\n",
       "      <td>0.562429</td>\n",
       "      <td>0.489255</td>\n",
       "      <td>0.472213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.181629</td>\n",
       "      <td>0.149952</td>\n",
       "      <td>0.177013</td>\n",
       "      <td>0.310047</td>\n",
       "      <td>0.212230</td>\n",
       "      <td>0.009101</td>\n",
       "      <td>0.785672</td>\n",
       "      <td>0.079629</td>\n",
       "      <td>0.541104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465825</td>\n",
       "      <td>0.361935</td>\n",
       "      <td>0.454099</td>\n",
       "      <td>0.606499</td>\n",
       "      <td>0.355193</td>\n",
       "      <td>0.498823</td>\n",
       "      <td>0.420072</td>\n",
       "      <td>0.565861</td>\n",
       "      <td>0.513738</td>\n",
       "      <td>0.475407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.165531</td>\n",
       "      <td>0.166965</td>\n",
       "      <td>0.180710</td>\n",
       "      <td>0.306612</td>\n",
       "      <td>0.204727</td>\n",
       "      <td>0.007918</td>\n",
       "      <td>0.827561</td>\n",
       "      <td>0.076524</td>\n",
       "      <td>0.533101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445952</td>\n",
       "      <td>0.346730</td>\n",
       "      <td>0.427406</td>\n",
       "      <td>0.626626</td>\n",
       "      <td>0.348612</td>\n",
       "      <td>0.494909</td>\n",
       "      <td>0.421537</td>\n",
       "      <td>0.536674</td>\n",
       "      <td>0.498761</td>\n",
       "      <td>0.468239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.182584</td>\n",
       "      <td>0.151897</td>\n",
       "      <td>0.181413</td>\n",
       "      <td>0.307000</td>\n",
       "      <td>0.215713</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.811728</td>\n",
       "      <td>0.083123</td>\n",
       "      <td>0.551256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465534</td>\n",
       "      <td>0.361433</td>\n",
       "      <td>0.440155</td>\n",
       "      <td>0.614434</td>\n",
       "      <td>0.356603</td>\n",
       "      <td>0.500161</td>\n",
       "      <td>0.423872</td>\n",
       "      <td>0.558747</td>\n",
       "      <td>0.503921</td>\n",
       "      <td>0.473958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.998715</td>\n",
       "      <td>0.171372</td>\n",
       "      <td>0.825958</td>\n",
       "      <td>0.197120</td>\n",
       "      <td>0.253609</td>\n",
       "      <td>0.415818</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>0.057736</td>\n",
       "      <td>0.796622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396948</td>\n",
       "      <td>0.353163</td>\n",
       "      <td>0.479162</td>\n",
       "      <td>0.299465</td>\n",
       "      <td>0.206678</td>\n",
       "      <td>0.472435</td>\n",
       "      <td>0.413154</td>\n",
       "      <td>0.194626</td>\n",
       "      <td>0.496428</td>\n",
       "      <td>0.314435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.998735</td>\n",
       "      <td>0.165486</td>\n",
       "      <td>0.811787</td>\n",
       "      <td>0.212240</td>\n",
       "      <td>0.254939</td>\n",
       "      <td>0.423003</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.059119</td>\n",
       "      <td>0.778316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407284</td>\n",
       "      <td>0.354649</td>\n",
       "      <td>0.487504</td>\n",
       "      <td>0.304194</td>\n",
       "      <td>0.205597</td>\n",
       "      <td>0.476717</td>\n",
       "      <td>0.416213</td>\n",
       "      <td>0.198058</td>\n",
       "      <td>0.501667</td>\n",
       "      <td>0.315074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.998768</td>\n",
       "      <td>0.156027</td>\n",
       "      <td>0.826743</td>\n",
       "      <td>0.220617</td>\n",
       "      <td>0.246367</td>\n",
       "      <td>0.427960</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.057178</td>\n",
       "      <td>0.774354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407628</td>\n",
       "      <td>0.347698</td>\n",
       "      <td>0.484770</td>\n",
       "      <td>0.304016</td>\n",
       "      <td>0.202081</td>\n",
       "      <td>0.471642</td>\n",
       "      <td>0.416932</td>\n",
       "      <td>0.193687</td>\n",
       "      <td>0.504878</td>\n",
       "      <td>0.319641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.998769</td>\n",
       "      <td>0.157015</td>\n",
       "      <td>0.822498</td>\n",
       "      <td>0.201135</td>\n",
       "      <td>0.249234</td>\n",
       "      <td>0.416299</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.053117</td>\n",
       "      <td>0.785013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402169</td>\n",
       "      <td>0.343681</td>\n",
       "      <td>0.482802</td>\n",
       "      <td>0.299650</td>\n",
       "      <td>0.195920</td>\n",
       "      <td>0.475458</td>\n",
       "      <td>0.419561</td>\n",
       "      <td>0.186777</td>\n",
       "      <td>0.506176</td>\n",
       "      <td>0.316610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.998848</td>\n",
       "      <td>0.168066</td>\n",
       "      <td>0.830248</td>\n",
       "      <td>0.206882</td>\n",
       "      <td>0.252257</td>\n",
       "      <td>0.417055</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.057903</td>\n",
       "      <td>0.795329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407484</td>\n",
       "      <td>0.350309</td>\n",
       "      <td>0.483041</td>\n",
       "      <td>0.295442</td>\n",
       "      <td>0.208871</td>\n",
       "      <td>0.469437</td>\n",
       "      <td>0.416789</td>\n",
       "      <td>0.199907</td>\n",
       "      <td>0.505437</td>\n",
       "      <td>0.312185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.000720  0.168531  0.149061  0.169859  0.301675  0.196885  0.007448   \n",
       "1     0.000826  0.184246  0.154516  0.171928  0.312609  0.219721  0.009232   \n",
       "2     0.000859  0.181629  0.149952  0.177013  0.310047  0.212230  0.009101   \n",
       "3     0.000870  0.165531  0.166965  0.180710  0.306612  0.204727  0.007918   \n",
       "4     0.000878  0.182584  0.151897  0.181413  0.307000  0.215713  0.009952   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  0.998715  0.171372  0.825958  0.197120  0.253609  0.415818  0.003805   \n",
       "9996  0.998735  0.165486  0.811787  0.212240  0.254939  0.423003  0.004046   \n",
       "9997  0.998768  0.156027  0.826743  0.220617  0.246367  0.427960  0.003841   \n",
       "9998  0.998769  0.157015  0.822498  0.201135  0.249234  0.416299  0.003280   \n",
       "9999  0.998848  0.168066  0.830248  0.206882  0.252257  0.417055  0.003807   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "0     0.790847  0.075297  0.537282  ...  0.444616  0.350243  0.443707   \n",
       "1     0.805572  0.079049  0.556938  ...  0.469215  0.367072  0.446296   \n",
       "2     0.785672  0.079629  0.541104  ...  0.465825  0.361935  0.454099   \n",
       "3     0.827561  0.076524  0.533101  ...  0.445952  0.346730  0.427406   \n",
       "4     0.811728  0.083123  0.551256  ...  0.465534  0.361433  0.440155   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9995  0.003192  0.057736  0.796622  ...  0.396948  0.353163  0.479162   \n",
       "9996  0.003249  0.059119  0.778316  ...  0.407284  0.354649  0.487504   \n",
       "9997  0.003330  0.057178  0.774354  ...  0.407628  0.347698  0.484770   \n",
       "9998  0.002894  0.053117  0.785013  ...  0.402169  0.343681  0.482802   \n",
       "9999  0.003079  0.057903  0.795329  ...  0.407484  0.350309  0.483041   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "0     0.616378  0.341417  0.497486  0.432200  0.553240  0.515729  0.476257  \n",
       "1     0.616064  0.358595  0.500063  0.424957  0.562429  0.489255  0.472213  \n",
       "2     0.606499  0.355193  0.498823  0.420072  0.565861  0.513738  0.475407  \n",
       "3     0.626626  0.348612  0.494909  0.421537  0.536674  0.498761  0.468239  \n",
       "4     0.614434  0.356603  0.500161  0.423872  0.558747  0.503921  0.473958  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "9995  0.299465  0.206678  0.472435  0.413154  0.194626  0.496428  0.314435  \n",
       "9996  0.304194  0.205597  0.476717  0.416213  0.198058  0.501667  0.315074  \n",
       "9997  0.304016  0.202081  0.471642  0.416932  0.193687  0.504878  0.319641  \n",
       "9998  0.299650  0.195920  0.475458  0.419561  0.186777  0.506176  0.316610  \n",
       "9999  0.295442  0.208871  0.469437  0.416789  0.199907  0.505437  0.312185  \n",
       "\n",
       "[10000 rows x 100 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(augmented_data_unique)#.duplicated().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
