{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6edf0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_pca_40_AE_01_0_x.npy\n",
      "all_pca_40_AE_01_0_y.npy\n",
      "[0.19428881 0.24609734 0.41065531 0.30852978 0.90617732]\n",
      "[[   1075       4      54       1       0]\n",
      " [     18     134      14       2       0]\n",
      " [   7319     664   93629   23447   23796]\n",
      " [   1106      80  131947  104570  169746]\n",
      " [    414      39   81499  142391 2018051]]\n",
      " num : 2, f1_score : 41, time : 2025-04-10 20:22:13.418645\n",
      "\n",
      "all_pca_40_AE_01_10_x.npy\n",
      "all_pca_40_AE_01_10_y.npy\n",
      "[0.18946081 0.52985075 0.40934192 0.33025941 0.90424674]\n",
      "[[   1084       1      43       6       0]\n",
      " [      8     142      16       2       0]\n",
      " [   7444     203   89730   25862   25616]\n",
      " [   1362      12  118613  114709  172753]\n",
      " [    411      10   81154  146632 2014187]]\n",
      " num : 3, f1_score : 47, time : 2025-04-10 20:24:00.696094\n",
      "\n",
      "all_pca_40_AE_01_11_x.npy\n",
      "all_pca_40_AE_01_11_y.npy\n",
      "[0.22100032 0.74796748 0.39478228 0.33289002 0.90203965]\n",
      "[[   1045       0      45      44       0]\n",
      " [      5     138      16       9       0]\n",
      " [   5880      54   87344   30261   25316]\n",
      " [   1059       2  118785  117768  169835]\n",
      " [    334       7   87447  152018 2002588]]\n",
      " num : 4, f1_score : 51, time : 2025-04-10 20:25:59.557974\n",
      "\n",
      "all_pca_40_AE_01_12_x.npy\n",
      "all_pca_40_AE_01_12_y.npy\n",
      "[0.17433558 0.01126171 0.2075571  0.22271509 0.75553021]\n",
      "[[    879      26     229       0       0]\n",
      " [     10     113      43       2       0]\n",
      " [   6225    1002  103096   16356   22176]\n",
      " [   1270    5136  184478   79882  136683]\n",
      " [    566   13623  556722  213658 1457825]]\n",
      " num : 5, f1_score : 27, time : 2025-04-10 20:28:10.346329\n",
      "\n",
      "all_pca_40_AE_01_13_x.npy\n",
      "all_pca_40_AE_01_13_y.npy\n",
      "[0.16911019 0.10819009 0.4025449  0.28047961 0.90247303]\n",
      "[[    917      12     190       3      12]\n",
      " [     17     107      39       5       0]\n",
      " [   6120     478   89275   20304   32678]\n",
      " [   1519     599  116145   88692  200494]\n",
      " [   1138     614   89049  115978 2035615]]\n",
      " num : 6, f1_score : 37, time : 2025-04-10 20:30:41.690514\n",
      "\n",
      "all_pca_40_AE_01_14_x.npy\n",
      "all_pca_40_AE_01_14_y.npy\n",
      "[0.18203427 0.1251462  0.39630778 0.31317957 0.89965378]\n",
      "[[    919      14     161      37       3]\n",
      " [     15     107      37       9       0]\n",
      " [   5878     479   86663   26908   28927]\n",
      " [   1385     467  114006  107795  183796]\n",
      " [    766     475   87630  146193 2007330]]\n",
      " num : 7, f1_score : 38, time : 2025-04-10 20:33:29.143771\n",
      "\n",
      "all_pca_40_AE_01_15_x.npy\n",
      "all_pca_40_AE_01_15_y.npy\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "#from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "import datetime \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# x , y, 데이터 가져오기 \n",
    "x = pd.DataFrame(np.load('ppp/open/datas/data_6/all_pca_40_x.npy'))\n",
    "y = pd.read_csv('ppp/open/datas/data_6/all_pca_40_y.csv')[\"Segment\"]\n",
    "x11, x_te1, y11, y_te1 = train_test_split(x,y,test_size=0.05,shuffle=True,stratify =y)\n",
    "# x,y 가져오기 \n",
    "\n",
    "#model = LGBMClassifier(n_estimators=200, learning_rate=0.1, max_depth=20, random_state = 312,tree_method=\"hist\", device=\"cuda\")#verbosity=2, verbosity\n",
    "\n",
    "x_file = os.listdir(f'ppp/open/AE_data_01/AE_x/')\n",
    "y_file = os.listdir(f'ppp/open/AE_data_01/AE_y/')\n",
    "\n",
    "su=1\n",
    "for xx, yy in zip(x_file, y_file):\n",
    "    a_x = np.load(f'ppp/open/AE_data_01/AE_x/{xx}')\n",
    "    a_y = np.load(f'ppp/open/AE_data_01/AE_y/{yy}')\n",
    "    print(xx)\n",
    "    print(yy)\n",
    "    '''\n",
    "    if su==1:\n",
    "        \n",
    "        model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=20, random_state = 312,tree_method=\"hist\", device=\"cuda\",)#verbosity=2, verbosity\n",
    "    else:\n",
    "        model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=20, random_state = 312,tree_method=\"hist\", device=\"cuda\",xgb_model=model)#verbosity=2, verbosity\n",
    "    '''\n",
    "    if su==1:\n",
    "        \n",
    "        model = LGBMClassifier(n_estimators=50, learning_rate=0.2, max_depth=5, random_state = 312, n_jobs=-1,subsample=0.5, force_col_wise=True ,verbose= -1)#verbosity=2, verbosity\n",
    "        model.fit(a_x, a_y,eval_set = [(a_x,a_y),(x_te1,y_te1)])\n",
    "    else:\n",
    "        #model = XGBClassifier(n_estimators=100, learning_te=0.1, max_depth=10, random_state = 312,tree_method=\"hist\", device=\"cuda\")#verbosity=2, verbosity\n",
    "        model.fit(a_x, a_y,eval_set = [(a_x, a_y),(x_te1,y_te1)],init_model=model)\n",
    "        \n",
    "    #model.fit(a_x, a_y)\n",
    "    y_pred = model.predict(x) \n",
    "    gp=int(f1_score(y, y_pred,average='macro')*100)\n",
    "    print(f1_score(y,y_pred, average=None))\n",
    "    print(confusion_matrix(y,y_pred ))\n",
    "    \n",
    "    model.booster_.save_model(f\"ppp/open/AE_data_01/AE_model/lgm_123_5_all_pca_40_f1_{gp}_op_{su}.txt\")\n",
    "    su+=1\n",
    "    print(f\" num : {su}, f1_score : {gp}, time : {datetime.datetime.now()}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c6570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea87e7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\607-14\\anaconda3\\envs\\qwe1\\lib\\site-packages\\lightgbm\\basic.py:374: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning(\"Converting column-vector to 1d array\")\n",
      "C:\\Users\\607-14\\anaconda3\\envs\\qwe1\\lib\\site-packages\\lightgbm\\basic.py:1238: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning(\"Converting data to scipy sparse matrix.\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m  y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_te)\n\u001b[0;32m     70\u001b[0m  y_pred_classes \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m  \u001b[38;5;28mprint\u001b[39m(\u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_te\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m     73\u001b[0m  \u001b[38;5;28mprint\u001b[39m(confusion_matrix(y_te,y_pred ))\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# print(\"\\nClassification Report:\\n\", classification_report(y_te, y_pred_classes))\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qwe1\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qwe1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1324\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1145\u001b[0m     {\n\u001b[0;32m   1146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1172\u001b[0m ):\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1174\u001b[0m \n\u001b[0;32m   1175\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qwe1\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qwe1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1337\u001b[0m     {\n\u001b[0;32m   1338\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1366\u001b[0m ):\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1368\u001b[0m \n\u001b[0;32m   1369\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m \u001b[38;5;124;03m    0.12...\u001b[39;00m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1517\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1518\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1519\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1525\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qwe1\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qwe1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1830\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1661\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1662\u001b[0m \n\u001b[0;32m   1663\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1827\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1828\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1829\u001b[0m _check_zero_division(zero_division)\n\u001b[1;32m-> 1830\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1832\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1833\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qwe1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1596\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[0;32m   1595\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[1;32m-> 1596\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1598\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m _tolist(unique_labels(y_true, y_pred))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qwe1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:107\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    104\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    109\u001b[0m             type_true, type_pred\n\u001b[0;32m    110\u001b[0m         )\n\u001b[0;32m    111\u001b[0m     )\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    114\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import os\n",
    "def f1_macro_score(preds, data):\n",
    "    y_true = data.get_label()\n",
    "    y_pred = np.argmax(preds.reshape(len(np.unique(y_true)), -1), axis=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return 'f1_macro', f1, True  # 마지막 True는 \"높을수록 좋다\"는 의미\n",
    "\n",
    "\n",
    "x = pd.DataFrame(np.load('ppp/open/datas/data_6/all_pca_40_x.npy'))\n",
    "y = np.array(pd.read_csv('ppp/open/datas/data_6/all_pca_40_y.csv')[\"Segment\"]).reshape(-1,1)\n",
    "\n",
    "\n",
    "x_file = os.listdir(f'ppp/open/AE_data_01/AE_x/')\n",
    "y_file = os.listdir(f'ppp/open/AE_data_01/AE_y/')\n",
    "params = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 5,\n",
    "        'metric': 'multi_logloss',\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 6,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'lambda_l1': 1.0,\n",
    "        'lambda_l2': 1.0,\n",
    "        'verbose': -1\n",
    "    }\n",
    "su=1\n",
    "x_el, X_te, y_el, y_te = train_test_split(x, y, test_size=0.9, random_state=42)\n",
    "\n",
    "for xx, yy in zip(x_file, y_file):\n",
    "    a_x = np.load(f'ppp/open/AE_data_01/AE_x/{xx}')\n",
    "    a_y = np.load(f'ppp/open/AE_data_01/AE_y/{yy}')\n",
    "    \n",
    "\n",
    "    # 3. LightGBM용 데이터셋으로 변환\n",
    "    train_data = lgb.Dataset(a_x, label=a_y)\n",
    "    val_data = lgb.Dataset(x_el, label=y_el, reference=train_data)\n",
    "\n",
    "    if su==1:\n",
    "        model = lgb.train(params,\n",
    "                          train_data,\n",
    "                          valid_sets=[val_data],\n",
    "                          feval=f1_macro_score,  \n",
    "                          num_boost_round=100,\n",
    "                          )\n",
    "\n",
    "   \n",
    "    else:\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=100,\n",
    "            feval=f1_macro_score,  \n",
    "            init_model=model,\n",
    "            keep_training_booster=True\n",
    "        )\n",
    "    su+=1\n",
    "    \n",
    "    y_pred = model.predict(X_te)\n",
    "    y_pred_classes = y_pred.argmax(axis=1)\n",
    "    \n",
    "    print(f1_score(y_te,y_pred, average=None))\n",
    "    print(confusion_matrix(y_te,y_pred ))\n",
    "   # print(\"\\nClassification Report:\\n\", classification_report(y_te, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35fdbde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwe1",
   "language": "python",
   "name": "qwe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
